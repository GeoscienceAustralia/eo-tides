{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv==0.5.0\n",
    "!pip install -e .. --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e /home/jovyan/Robbi/pyTMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pystac_client\n",
    "\n",
    "from pyTMD.compute import tide_elevations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]  # simplified for tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_satellite_ds():\n",
    "    \"\"\"\n",
    "    Load a sample timeseries of Landsat 8 data using odc-stac\n",
    "    \"\"\"\n",
    "    # Connect to stac catalogue\n",
    "    catalog = pystac_client.Client.open(\"https://explorer.dea.ga.gov.au/stac\")\n",
    "\n",
    "    # Set cloud defaults\n",
    "    odc.stac.configure_rio(\n",
    "        cloud_defaults=True,\n",
    "        aws={\"aws_unsigned\": True},\n",
    "    )\n",
    "\n",
    "    # Build a query with the parameters above\n",
    "    buffer = 0.08\n",
    "    # buffer = 0.5\n",
    "    bbox = [GAUGE_X - buffer, GAUGE_Y - buffer, GAUGE_X + buffer, GAUGE_Y + buffer]\n",
    "    query = catalog.search(\n",
    "        bbox=bbox,\n",
    "        collections=[\"ga_ls8c_ard_3\"],\n",
    "        datetime=\"2020-01/2020-02\",\n",
    "    )\n",
    "\n",
    "    # Search the STAC catalog for all items matching the query\n",
    "    ds = odc.stac.load(\n",
    "        list(query.items()),\n",
    "        bands=[\"nbart_red\"],\n",
    "        crs=\"epsg:3577\",\n",
    "        resolution=30,\n",
    "        groupby=\"solar_day\",\n",
    "        bbox=bbox,\n",
    "        fail_on_error=False,\n",
    "        chunks={\"x\": 100, \"y\": 200},\n",
    "    )\n",
    "\n",
    "    return ds\n",
    "\n",
    "satellite_ds = load_satellite_ds()\n",
    "\n",
    "\n",
    "def load_measured_tides_ds():\n",
    "    \"\"\"\n",
    "    Load measured sea level data from the Broome ABSLMP tidal station:\n",
    "    http://www.bom.gov.au/oceanography/projects/abslmp/data/data.shtml\n",
    "    \"\"\"\n",
    "    # Metadata for Broome ABSLMP tidal station:\n",
    "    # http://www.bom.gov.au/oceanography/projects/abslmp/data/data.shtml\n",
    "    ahd_offset = -5.322\n",
    "\n",
    "    # Load measured tides from ABSLMP tide gauge data\n",
    "    measured_tides_df = pd.read_csv(\n",
    "        \"../tests/data/IDO71013_2020.csv\",\n",
    "        index_col=0,\n",
    "        parse_dates=True,\n",
    "        na_values=-9999,\n",
    "    )[[\"Sea Level\"]]\n",
    "\n",
    "    # Update index and column names\n",
    "    measured_tides_df.index.name = \"time\"\n",
    "    measured_tides_df.columns = [\"tide_height\"]\n",
    "\n",
    "    # Apply station AHD offset\n",
    "    measured_tides_df += ahd_offset\n",
    "\n",
    "    # Return as xarray dataset\n",
    "    return measured_tides_df.to_xarray()\n",
    "\n",
    "\n",
    "def create_synthetic_model(base_dir=\"data/tide_models_synthetic\"):\n",
    "    \"\"\"\n",
    "    Generates and exports synthetic HAMTIDE11 model data\n",
    "    to test clipping functionality.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)  # Ensure base_dir is a Path object\n",
    "    \n",
    "    # Create coordinate arrays\n",
    "    lon = np.arange(0, 360.125, 0.125)  # 2881 points\n",
    "    lat = np.arange(-90, 90.125, 0.125)  # 1441 points\n",
    "    \n",
    "    # List of hamtide tidal constituents\n",
    "    constituents = ['2n', 'k1', 'k2', 'm2', 'n2', 'o1', 'p1', 'q1', 's2']\n",
    "    \n",
    "    # Create hamtide output directory\n",
    "    hamtide_dir = base_dir / \"hamtide\"\n",
    "    hamtide_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create and save a NetCDF for each constituent\n",
    "    for constituent in constituents:\n",
    "\n",
    "        # Create synthetic hamtide dataset with random data\n",
    "        shape = (len(lat), len(lon))  # 1441, 2881\n",
    "        data = np.random.random(shape).astype(np.float32)\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                'RE': (('LAT', 'LON'), data),\n",
    "                'IM': (('LAT', 'LON'), data),\n",
    "                'AMPL': (('LAT', 'LON'), data),\n",
    "                'PHAS': (('LAT', 'LON'), data)\n",
    "            },\n",
    "            coords={\n",
    "                'LON': lon,\n",
    "                'LAT': lat\n",
    "            },\n",
    "            attrs={\"title\": f'HAMTIDE11a: {constituent} ocean tide'}\n",
    "        )\n",
    "\n",
    "        # Export\n",
    "        filename = hamtide_dir / f'{constituent}.hamtide11a.nc'\n",
    "        ds.to_netcdf(filename)\n",
    "\n",
    "\n",
    "satellite_ds = load_satellite_ds()\n",
    "measured_tides_ds = load_measured_tides_ds()\n",
    "create_synthetic_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Robbi/eo-tides\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_model_tides_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_parallel_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_eo.py --verbose -k test_tag_tides_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_utils.py --verbose -k test_clip_models_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to clip suitable NetCDF models: ['HAMTIDE11']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping HAMTIDE11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ… Clipped model exported and verified\n",
      "\n",
      "Outputs exported to tests/data/tide_models_synthetic_aus\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " ó € ðŸŒŠ  | Model                | Expected path                                                           \n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " âœ…  â”‚ HAMTIDE11            â”‚ tests/data/tide_models_synthetic_aus/hamtide                            \n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Summary:\n",
      "Available models: 1/52\n",
      "Modelling tides with HAMTIDE11\n",
      "Modelling tides with HAMTIDE11\n"
     ]
    }
   ],
   "source": [
    "from eo_tides.utils import clip_models\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "# @pytest.mark.parametrize(\"bbox, name\", [\n",
    "#     ((-166, 14, -151, 29), \"hawaii\"),\n",
    "#     ((-123.530273, 36.949892, -121.376953, 38.479395), \"sanfran\"),\n",
    "#     ((-17.753906, -36.031332, 60.996094, 37.857507), \"africa\"),\n",
    "#     ((-13, 49, 6, 60), \"uk\"),\n",
    "#     ((105.292969, -47.872144, 160.312500, -5.266008), \"aus\"),\n",
    "#     ((-256.640625, 7.013668, -119.794922, 63.391522), \"pacific\"),\n",
    "# ])\n",
    "\n",
    "bbox, name = (105.292969, -47.872144, 160.312500, -5.266008), \"aus\"\n",
    "\n",
    "def test_clip_models_bboxes(bbox, name):\n",
    "\n",
    "    # Set input and output paths\n",
    "    in_dir = \"tests/data/tide_models_synthetic/\"\n",
    "    out_dir = f\"tests/data/tide_models_synthetic_{name}/\"\n",
    "\n",
    "    # Clip models to input bbox\n",
    "    clip_models(\n",
    "        input_directory=in_dir,\n",
    "        output_directory=out_dir,\n",
    "        bbox=bbox,\n",
    "        model=\"HAMTIDE11\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Set modelling location based on bbox centroid\n",
    "    x, y = odc.geo.geom.BoundingBox(*bbox, crs=\"EPSG:4326\").polygon.centroid.xy\n",
    "    time = pd.date_range(start=\"2000-01\", end=\"2001-03\", freq=\"5h\")\n",
    "\n",
    "    # Model using unclipped vs clipped files\n",
    "    df_unclipped = model_tides(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        time=time,\n",
    "        model=\"HAMTIDE11\",\n",
    "        directory=in_dir,\n",
    "        crop=False,\n",
    "    )\n",
    "    df_clipped = model_tides(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        time=time,\n",
    "        model=\"HAMTIDE11\",\n",
    "        directory=out_dir,\n",
    "        crop=False,\n",
    "    )\n",
    "\n",
    "    # Verify both produce the same results\n",
    "    assert np.allclose(df_unclipped.tide_height, df_clipped.tide_height)\n",
    "\n",
    "test_clip_models_bboxes(bbox, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add tide phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.eo import tag_tides\n",
    "import xarray as xr\n",
    "\n",
    "# Use tag_tides to model both phases and tide heights\n",
    "tagged_tides_ds = tag_tides(\n",
    "    satellite_ds,\n",
    "    return_phases=True,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Verify output is an xarray.Dataset\n",
    "assert isinstance(tagged_tides_ds, xr.Dataset)\n",
    "\n",
    "# Verify vars are as expected\n",
    "expected_vars = [\"tide_height\", \"tide_phase\"]\n",
    "assert set(expected_vars) == set(tagged_tides_ds.data_vars)\n",
    "\n",
    "# Verify tide_phase values\n",
    "expected_phases = [\"low-flow\", \"high-flow\", \"low-ebb\", \"low-flow\", \"low-ebb\", \"low-flow\", \"high-flow\"]\n",
    "assert tagged_tides_ds.tide_phase.values.tolist() == expected_phases\n",
    "\n",
    "# Assert tide_model dim has been squeezed out\n",
    "assert \"tide_model\" not in tagged_tides_ds.dims\n",
    "\n",
    "# Model two models at once\n",
    "tagged_tides_ds = tag_tides(\n",
    "    satellite_ds,\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    return_phases=True,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Assert that output now has a tide_model dimension\n",
    "assert \"tide_model\" in tagged_tides_ds.dims\n",
    "assert len(tagged_tides_ds[\"tide_model\"]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update `tide_stats`\n",
    "\n",
    "\n",
    "Aim: internal `_tide_statistics` function that takes a stack of input observed and modelled tides in _both_ pandas and xarray format, and returns statistics in corresponding format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "from eo_tides.stats import pixel_stats, tide_stats\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EOT20\", \"GOT5.5\"]\n",
    "\n",
    "# Calculate tidal stats\n",
    "tidal_stats_df = tide_stats(\n",
    "    satellite_ds,\n",
    "    model=models,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# assert isinstance(tidal_stats_df, pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds = pixel_stats(\n",
    "    satellite_ds,\n",
    "    model=models,\n",
    "    resample=False,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stats_ds.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./tests/data/tide_models\"\n",
    "\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "# Input params\n",
    "good_hamtide11 = -17.58549, 123.59414\n",
    "good_eot20 = -17.1611, 123.3406\n",
    "y = [good_eot20[0], good_hamtide11[0]]\n",
    "x = [good_eot20[1], good_hamtide11[1]]\n",
    "\n",
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]\n",
    "\n",
    "# times = pd.date_range(\"2020\", \"2021\", periods=2)\n",
    "\n",
    "# # Default, only ensemble requested\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=\"ensemble\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert all(modelled_tides_df.tide_model == \"ensemble\")\n",
    "\n",
    "# Default, ensemble + other models requested\n",
    "models = [\"EOT20\", \"HAMTIDE11\", \"ensemble\"]\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert set(modelled_tides_df.tide_model) == set(models)\n",
    "# assert np.allclose(\n",
    "#     modelled_tides_df.tide_height.values,\n",
    "#     [\n",
    "#         0.094,\n",
    "#         -3.202,\n",
    "#         0.409,\n",
    "#         -3.098,\n",
    "#         0.803,\n",
    "#         0.664,\n",
    "#         0.989,\n",
    "#         1.011,\n",
    "#         0.449,\n",
    "#         -1.269,\n",
    "#         0.699,\n",
    "#         -1.043,\n",
    "#     ],\n",
    "#     atol=0.02,\n",
    "# )\n",
    "\n",
    "# # One-to-one mode\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     mode=\"one-to-one\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert set(modelled_tides_df.tide_model) == set(models)\n",
    "\n",
    "# # Wide mode, default\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist, and that ensemble is approx average\n",
    "# # of other two models\n",
    "# assert set(modelled_tides_df.columns) == set(models)\n",
    "# assert np.allclose(\n",
    "#     0.5 * (modelled_tides_df.EOT20 + modelled_tides_df.HAMTIDE11),\n",
    "#     modelled_tides_df.ensemble,\n",
    "# )\n",
    "\n",
    "# # Wide mode, top n == 1\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     ensemble_top_n=1,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# Check that expected models exist, and that ensemble is equal to at\n",
    "# least one of the other models\n",
    "assert set(modelled_tides_df.columns) == set(models)\n",
    "assert all(\n",
    "    (modelled_tides_df.EOT20 == modelled_tides_df.ensemble)\n",
    "    | (modelled_tides_df.HAMTIDE11 == modelled_tides_df.ensemble)\n",
    ")\n",
    "\n",
    "# Check that correct model is the closest at each row\n",
    "closer_model = modelled_tides_df.apply(\n",
    "    lambda row: (\n",
    "        \"EOT20\" if abs(row[\"ensemble\"] - row[\"EOT20\"]) < abs(row[\"ensemble\"] - row[\"HAMTIDE11\"]) else \"HAMTIDE11\"\n",
    "    ),\n",
    "    axis=1,\n",
    ").tolist()\n",
    "assert closer_model == [\"EOT20\", \"HAMTIDE11\", \"EOT20\", \"HAMTIDE11\"]\n",
    "\n",
    "# # Check values are expected\n",
    "# assert np.allclose(modelled_tides_df.ensemble, [0.09, 0.98, -3.20, 1.01], atol=0.02)\n",
    "\n",
    "# # Wide mode, custom functions\n",
    "# ensemble_funcs = {\n",
    "#     \"ensemble-best\": lambda x: x[\"rank\"] == 1,\n",
    "#     \"ensemble-worst\": lambda x: x[\"rank\"] == 2,\n",
    "#     \"ensemble-mean-top2\": lambda x: x[\"rank\"].isin([1, 2]),\n",
    "#     \"ensemble-mean-weighted\": lambda x: 3 - x[\"rank\"],\n",
    "#     \"ensemble-mean\": lambda x: x[\"rank\"] <= 2,\n",
    "# }\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     ensemble_func=ensemble_funcs,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist, and that valid data is produced\n",
    "# assert set(modelled_tides_df.columns) == set([\n",
    "#     \"EOT20\",\n",
    "#     \"HAMTIDE11\",\n",
    "#     \"ensemble-best\",\n",
    "#     \"ensemble-worst\",\n",
    "#     \"ensemble-mean-top2\",\n",
    "#     \"ensemble-mean-weighted\",\n",
    "#     \"ensemble-mean\",\n",
    "# ])\n",
    "# assert all(modelled_tides_df.notnull())\n",
    "\n",
    "# # Long mode, custom functions\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"long\",\n",
    "#     ensemble_func=ensemble_funcs,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist in \"tide_model\" column\n",
    "# assert set(modelled_tides_df.tide_model) == set([\n",
    "#     \"EOT20\",\n",
    "#     \"HAMTIDE11\",\n",
    "#     \"ensemble-best\",\n",
    "#     \"ensemble-worst\",\n",
    "#     \"ensemble-mean-top2\",\n",
    "#     \"ensemble-mean-weighted\",\n",
    "#     \"ensemble-mean\",\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]\n",
    "ensemble_models = ENSEMBLE_MODELS\n",
    "\n",
    "x = tide_df.index.get_level_values(level=\"x\")\n",
    "y = tide_df.index.get_level_values(level=\"y\")\n",
    "model_ranking_cols = [f\"rank_{m}\" for m in ensemble_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranks_gdf.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "ranking_points=\"https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/derivative/dea_intertidal/supplementary/rankings_ensemble_2017-2019.fgb\"\n",
    "crs = \"EPSG:4326\"\n",
    "ranking_valid_perc=0.02\n",
    "\n",
    "try:\n",
    "    model_ranks_gdf = (\n",
    "        gpd.read_file(ranking_points, engine=\"pyogrio\")\n",
    "        .to_crs(crs)\n",
    "        .query(f\"valid_perc > {ranking_valid_perc}\")\n",
    "        .dropna(how=\"all\")[model_ranking_cols + [\"geometry\"]]\n",
    "    )\n",
    "except KeyError:\n",
    "    error_msg = f\"\"\"\n",
    "    Not all of the expected \"rank_\" columns {model_ranking_cols} were\n",
    "    found in the columns of the ranking points file ({ranking_points}).\n",
    "    Consider passing a custom list of models using `ensemble_models`.\n",
    "    \"\"\"\n",
    "    raise Exception(textwrap.dedent(error_msg).strip()) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import idw\n",
    "\n",
    "idw_kwargs = {}\n",
    "\n",
    "# Use points to interpolate model rankings into requested x and y\n",
    "id_kwargs_str = \"\" if idw_kwargs == {} else idw_kwargs\n",
    "print(f\"Interpolating model rankings using IDW interpolation {id_kwargs_str}\")\n",
    "ensemble_ranks_df = (\n",
    "    # Run IDW interpolation on subset of ranking columns\n",
    "    pd.DataFrame(\n",
    "        idw(\n",
    "            input_z=model_ranks_gdf[model_ranking_cols],\n",
    "            input_x=model_ranks_gdf.geometry.x,\n",
    "            input_y=model_ranks_gdf.geometry.y,\n",
    "            output_x=x,\n",
    "            output_y=y,\n",
    "            **idw_kwargs,\n",
    "        ),\n",
    "        columns=model_ranking_cols,\n",
    "    )\n",
    "    .assign(x=x, y=y)\n",
    "    # Drop any duplicates then melt columns into long format\n",
    "    .drop_duplicates()\n",
    "    .melt(id_vars=[\"x\", \"y\"], var_name=\"tide_model\", value_name=\"rank\")\n",
    "    # Remore \"rank_\" prefix to get plain model names\n",
    "    .replace({\"^rank_\": \"\"}, regex=True)\n",
    "    # Set index columns and rank across groups\n",
    "    .set_index([\"tide_model\", \"x\", \"y\"])\n",
    "    .groupby([\"x\", \"y\"])\n",
    "    .rank()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranks_gdf[model_ranking_cols].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_ranks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "df = model_tides(x= 123.73412090186251, \n",
    "            y=-16.997767837915056, \n",
    "            model=\"ensemble\",\n",
    "            time=pd.date_range(start=\"2000\", end=\"2001\", freq=\"5h\"),\n",
    "            ranking_points=\"/home/jovyan/Robbi/dea-intertidal/data/raw/tide_correlation_points_test.geojson\",\n",
    "            k=5,\n",
    "            output_format=\"wide\",\n",
    "            directory=\"/var/share/tide_models/\")\n",
    "\n",
    "with pd.option_context('display.max_rows', 5, 'display.max_columns', None): \n",
    "    display(df)\n",
    "\n",
    "# u, c = np.unique(a, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "df = model_tides(\n",
    "    x=145.372051,\n",
    "    y=-38.260667,\n",
    "    model=[\n",
    "        \"EOT20\",\n",
    "        \"FES2012\",\n",
    "        \"FES2014_extrapolated\",\n",
    "        \"FES2022_extrapolated\",\n",
    "        \"HAMTIDE11\",\n",
    "        \"GOT4.10\",\n",
    "        \"GOT5.6_extrapolated\",\n",
    "        \"TPXO10-atlas-v2-nc\",\n",
    "        \"TPXO8-atlas-nc\",\n",
    "        \"TPXO9-atlas-v5-nc\",\n",
    "        \"ensemble\",\n",
    "    ],\n",
    "    time=pd.date_range(start=\"2018-01-01\", end=\"2020-12-31\", freq=\"1h\"),\n",
    "    output_format=\"wide\",\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    ensemble_models=[\n",
    "        \"EOT20\",\n",
    "        \"FES2012\",\n",
    "        \"FES2014_extrapolated\",\n",
    "        \"FES2022_extrapolated\",\n",
    "        # \"HAMTIDE11\",\n",
    "        # \"GOT4.10\",\n",
    "        \"GOT5.6_extrapolated\",\n",
    "        \"TPXO10-atlas-v2-nc\",\n",
    "        # \"TPXO8-atlas-nc\",\n",
    "        \"TPXO9-atlas-v5-nc\",\n",
    "    ]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.droplevel([\"x\", \"y\"]).head(50).drop(\"ensemble\", axis=1).plot(linewidth=0.8, figsize=(10, 6))\n",
    "df.droplevel([\"x\", \"y\"]).head(50).ensemble.plot(linewidth=3, c=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.droplevel([\"x\", \"y\"]).head(50).drop(\"ensemble\", axis=1).plot(linewidth=0.8, figsize=(10, 6))\n",
    "df.droplevel([\"x\", \"y\"]).head(50).ensemble.plot(linewidth=3, c=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_standardise_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import _set_directory, list_models\n",
    "\n",
    "directory = \"/home/jovyan/Robbi/eo-tides/tests/data/tide_models/\"\n",
    "directory = _set_directory(directory)\n",
    "\n",
    "\n",
    "# def _standardise_models(model, directory, ensemble_models=None):\n",
    "\n",
    "#     # Turn inputs into arrays for consistent handling\n",
    "#     models_requested = list(np.atleast_1d(model))\n",
    "\n",
    "#     # Get full list of supported models from pyTMD database\n",
    "#     available_models, valid_models = list_models(\n",
    "#         directory, show_available=False, show_supported=False, raise_error=True\n",
    "#     )\n",
    "#     custom_options = [\"ensemble\", \"all\"]\n",
    "\n",
    "#     # Error if any models are not supported\n",
    "#     if not all(m in valid_models + custom_options for m in models_requested):\n",
    "#         error_text = (\n",
    "#             f\"One or more of the requested models are not valid:\\n\"\n",
    "#             f\"{models_requested}\\n\\n\"\n",
    "#             \"The following models are supported:\\n\"\n",
    "#             f\"{valid_models}\"\n",
    "#         )\n",
    "#         raise ValueError(error_text)\n",
    "\n",
    "#     # Error if any models are not available in `directory`\n",
    "#     if not all(m in available_models + custom_options for m in models_requested):\n",
    "#         error_text = (\n",
    "#             f\"One or more of the requested models are valid, but not available in `{directory}`:\\n\"\n",
    "#             f\"{models_requested}\\n\\n\"\n",
    "#             f\"The following models are available in `{directory}`:\\n\"\n",
    "#             f\"{available_models}\"\n",
    "#         )\n",
    "#         raise ValueError(error_text)\n",
    "\n",
    "#     # If \"all\" models are requested, update requested list to include available models\n",
    "#     if \"all\" in models_requested:\n",
    "#         models_requested = available_models + [\n",
    "#             m for m in models_requested if m != \"all\"\n",
    "#         ]\n",
    "\n",
    "#     # If \"ensemble\" modeling is requested, use custom list of ensemble models\n",
    "#     if \"ensemble\" in models_requested:\n",
    "#         print(\"Running ensemble tide modelling\")\n",
    "#         ensemble_models = (\n",
    "#             ensemble_models\n",
    "#             if ensemble_models is not None\n",
    "#             else [\n",
    "#                 \"FES2014\",\n",
    "#                 \"TPXO9-atlas-v5\",\n",
    "#                 \"EOT20\",\n",
    "#                 \"HAMTIDE11\",\n",
    "#                 \"GOT4.10\",\n",
    "#                 \"FES2012\",\n",
    "#                 \"TPXO8-atlas-v1\",\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         # Error if any ensemble models are not available in `directory`\n",
    "#         if not all(m in available_models for m in ensemble_models):\n",
    "#             error_text = (\n",
    "#                 f\"One or more of the requested ensemble models are not available in `{directory}`:\\n\"\n",
    "#                 f\"{ensemble_models}\\n\\n\"\n",
    "#                 f\"The following models are available in `{directory}`:\\n\"\n",
    "#                 f\"{available_models}\"\n",
    "#             )\n",
    "#             raise ValueError(error_text)\n",
    "\n",
    "#         # Return set of all ensemble plus any other requested models\n",
    "#         models_to_process = ensemble_models + [\n",
    "#             m for m in models_requested if m != \"ensemble\"\n",
    "#         ]\n",
    "\n",
    "#     # Otherwise, models to process are the same as those requested\n",
    "#     else:\n",
    "#         models_to_process = models_requested\n",
    "\n",
    "#     # Remove duplicates\n",
    "#     models_to_process = list(set(models_to_process))\n",
    "#     models_requested = list(set(models_requested))\n",
    "\n",
    "#     return models_to_process, models_requested, ensemble_models\n",
    "\n",
    "\n",
    "# model = \"EOT20\"\n",
    "# # model = [\"EOT20\", \"HAMTIDE11\"]  # = [\"EOT20\", \"FES2014\"]\n",
    "# # model = \"all\"  # = [list all available]\n",
    "# # model = \"ensemble\" # = [list all ensemble]\n",
    "# # model = [\"ensemble\", \"GOT5.5\"]  # = [list all ensemble]\n",
    "# # model = [\"all\", \"ensemble\"]\n",
    "\n",
    "\n",
    "from eo_tides.utils import _standardise_models\n",
    "\n",
    "\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    "    [\"EOT20\"],\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"EOT20\",\n",
    "    None,\n",
    "    [\"EOT20\"],\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"all\",\n",
    "    None,\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"all\"],\n",
    "    None,\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"ensemble\",\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"ensemble\", \"GOT5.5\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"],\n",
    "    [\"GOT5.5\", \"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "# model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "#     [\"all\", \"ensemble\"],\n",
    "#     [\"EOT20\", \"HAMTIDE11\"],\n",
    "#     [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"],\n",
    "#     [\"GOT5.5\", \"HAMTIDE11\", \"ensemble\", \"EOT20\"],\n",
    "#     [\"EOT20\", \"HAMTIDE11\"],\n",
    "# )\n",
    "\n",
    "\n",
    "models_to_process, models_requested, ensemble_models = _standardise_models(\n",
    "    model=model,\n",
    "    directory=directory,\n",
    "    ensemble_models=ensemble_models,\n",
    ")\n",
    "\n",
    "print(\"Models to process: \", models_to_process)\n",
    "print(\"Models requested: \", models_requested)\n",
    "print(\"Ensemble models: \", ensemble_models)\n",
    "\n",
    "assert models_to_process == exp_process\n",
    "assert models_requested == exp_request\n",
    "assert ensemble_models == exp_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(models_requested + ensemble_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models\n",
    "\n",
    "models_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate interpolation functions\n",
    "\n",
    "crop=True, bounds=None: \n",
    "crop=False, bounds=None:\n",
    "crop=True, bounds="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "x=np.linspace(122.2183, 122.219, 10)\n",
    "y=np.linspace(-18.0008, -18.01, 10)\n",
    "time=pd.date_range(\"2020\", \"2021\", periods=10)\n",
    "crs=\"EPSG:4326\"\n",
    "method=\"spline\"\n",
    "model=\"FES2022\"\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        delta_time=time,\n",
    "        DIRECTORY=\"/gdata1/data/tide_models/\",\n",
    "        MODEL=model,\n",
    "        EPSG=int(crs[-4:]),\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=method,\n",
    "        CROP=True,\n",
    "        # CROP=False,\n",
    "        # BOUNDS=bounds,\n",
    "        )\n",
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"spline\", CROP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"linear\", CROP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"spline\", CROP=True, BOUNDS=[121.218, 123.218, -19.000, -17.000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function, annotations\n",
    "\n",
    "import logging\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from io import IOBase\n",
    "import scipy.interpolate\n",
    "import pyTMD.crs\n",
    "import pyTMD.io\n",
    "import pyTMD.io.model\n",
    "import pyTMD.predict\n",
    "import pyTMD.spatial\n",
    "import pyTMD.utilities\n",
    "import timescale.eop\n",
    "import timescale.time\n",
    "# attempt imports\n",
    "pyproj = pyTMD.utilities.import_dependency('pyproj')\n",
    "\n",
    "\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "x=x\n",
    "y=y\n",
    "delta_time=measured_tides_ds.time\n",
    "DIRECTORY=\"/var/share/tide_models/\"\n",
    "MODEL=model\n",
    "EPSG=int(crs[-4:])\n",
    "TIME=\"datetime\"\n",
    "EXTRAPOLATE=True\n",
    "CUTOFF=np.inf\n",
    "CROP=True\n",
    "METHOD=method\n",
    "\n",
    "GZIP=False\n",
    "DEFINITION_FILE=None\n",
    "BOUNDS=None\n",
    "EPOCH=(2000, 1, 1, 0, 0, 0)\n",
    "TYPE='drift'\n",
    "CORRECTIONS = None\n",
    "INFER_MINOR = True\n",
    "MINOR_CONSTITUENTS = None\n",
    "APPEND_NODE = False\n",
    "APPLY_FLEXURE= False\n",
    "FILL_VALUE=np.nan\n",
    "\n",
    "\n",
    "\n",
    "# check that tide directory is accessible\n",
    "if DIRECTORY is not None:\n",
    "    DIRECTORY = pathlib.Path(DIRECTORY).expanduser()\n",
    "    if not DIRECTORY.exists():\n",
    "        raise FileNotFoundError(\"Invalid tide directory\")\n",
    "\n",
    "# validate input arguments\n",
    "assert TIME.lower() in ('gps', 'loran', 'tai', 'utc', 'datetime')\n",
    "assert METHOD.lower() in ('bilinear', 'spline', 'linear', 'nearest')\n",
    "\n",
    "# get parameters for tide model\n",
    "if DEFINITION_FILE is not None:\n",
    "    model = pyTMD.io.model(DIRECTORY).from_file(DEFINITION_FILE)\n",
    "else:\n",
    "    model = pyTMD.io.model(DIRECTORY, compressed=GZIP).elevation(MODEL)\n",
    "\n",
    "# determine input data type based on variable dimensions\n",
    "if not TYPE:\n",
    "    TYPE = pyTMD.spatial.data_type(x, y, delta_time)\n",
    "assert TYPE.lower() in ('grid', 'drift', 'time series')\n",
    "# reform coordinate dimensions for input grids\n",
    "# or verify coordinate dimension shapes\n",
    "if (TYPE.lower() == 'grid') and (np.size(x) != np.size(y)):\n",
    "    x,y = np.meshgrid(np.copy(x),np.copy(y))\n",
    "elif (TYPE.lower() == 'grid'):\n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "elif TYPE.lower() in ('time series', 'drift'):\n",
    "    x = np.atleast_1d(x)\n",
    "    y = np.atleast_1d(y)\n",
    "\n",
    "# converting x,y from EPSG to latitude/longitude\n",
    "crs1 = pyTMD.crs().from_input(EPSG)\n",
    "crs2 = pyproj.CRS.from_epsg(4326)\n",
    "transformer = pyproj.Transformer.from_crs(crs1, crs2, always_xy=True)\n",
    "lon, lat = transformer.transform(x.flatten(), y.flatten())\n",
    "\n",
    "# verify that delta time is an array\n",
    "delta_time = np.atleast_1d(delta_time)\n",
    "# convert delta times or datetimes objects to timescale\n",
    "if (TIME.lower() == 'datetime'):\n",
    "    ts = timescale.time.Timescale().from_datetime(\n",
    "        delta_time.flatten())\n",
    "else:\n",
    "    ts = timescale.time.Timescale().from_deltatime(delta_time,\n",
    "        epoch=EPOCH, standard=TIME)\n",
    "# number of time points\n",
    "nt = len(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tidal constants and interpolate to grid points\n",
    "amp, ph, c = model.extract_constants(lon, lat, type=model.type,\n",
    "    crop=CROP, bounds=BOUNDS, method=METHOD,\n",
    "    extrapolate=EXTRAPOLATE, cutoff=CUTOFF,\n",
    "    append_node=APPEND_NODE, apply_flexure=APPLY_FLEXURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust dimensions of input coordinates to be iterable\n",
    "ilon = np.atleast_1d(np.copy(lon))\n",
    "ilat = np.atleast_1d(np.copy(lat))\n",
    "# set default bounds if cropping\n",
    "xmin, xmax = np.min(ilon), np.max(ilon)\n",
    "ymin, ymax = np.min(ilat), np.max(ilat)\n",
    "bounds=[xmin-1, xmax+1, ymin-1, ymax+1]\n",
    "\n",
    "\n",
    "# read tidal constants and interpolate to grid points\n",
    "c = model.read_constants(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.read_constants(crop=False, bounds=bounds)\n",
    "plt.imshow(c.m2.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.read_constants(crop=True, bounds=bounds)\n",
    "plt.imshow(c.m2.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c.m2.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate complex phase in radians for Euler's\n",
    "cph = -1j*ph*np.pi/180.0\n",
    "# calculate constituent oscillation\n",
    "hc = amp*np.exp(cph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "n = 2000\n",
    "x = np.random.uniform(112.715430, 154.727149, n)\n",
    "y = np.random.uniform(-44.199061, -10.035282, n)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "model = \"FES2014\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models/\"\n",
    "\n",
    "# Time the spline method\n",
    "start_time = time.time()\n",
    "modelled_tides_df_spline = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"spline\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=False, \n",
    ")\n",
    "spline_time = time.time() - start_time\n",
    "\n",
    "# Time the linear method  \n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"linear\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=False,\n",
    ")\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "print(f\"Spline method time: {spline_time:.6f} seconds\")\n",
    "print(f\"Linear method time: {linear_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "n = 2000\n",
    "x = np.random.uniform(112.715430, 154.727149, n)\n",
    "y = np.random.uniform(-44.199061, -10.035282, n)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "model = \"FES2014\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models/\"\n",
    "\n",
    "# # Time the spline method\n",
    "# start_time = time.time()\n",
    "# modelled_tides_df_spline = model_tides(\n",
    "#    x=x,\n",
    "#    y=y,\n",
    "#    time=times,\n",
    "#    model=model,\n",
    "#    method=\"spline\",\n",
    "#    directory=directory,\n",
    "#    parallel=False,\n",
    "#    crop=True, \n",
    "# )\n",
    "# spline_time = time.time() - start_time\n",
    "\n",
    "# Time the linear method  \n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"linear\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=True,\n",
    ")\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "# print(f\"Spline method time: {spline_time:.6f} seconds\")\n",
    "print(f\"Linear method time: {linear_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "x = np.random.uniform(112.715430, 154.727149, 100000)\n",
    "y = np.random.uniform(-44.199061, -10.035282, 100000)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "# model = \"EOT20\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models_clipped/\"\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for model in [[\"EOT20\", \"GOT5.5\"], \"EOT20\"]:\n",
    "\n",
    "    for n in [100, 1000, 10000, 100000]:\n",
    "    \n",
    "        # Select a subset of x and y\n",
    "        x_sub = x[0:n]\n",
    "        y_sub = y[0:n]\n",
    "    \n",
    "        for parallel_max in [2, 4, 8, 16]:\n",
    "        \n",
    "            for parallel_split in [1, 2, 3, 4, 5, 6, 8, 10, 12, 16, 20]:\n",
    "        \n",
    "                # Time the linear method\n",
    "                start_time = time.time()\n",
    "                modelled_tides_df_linear = model_tides(\n",
    "                    x=x_sub,\n",
    "                    y=y_sub,\n",
    "                    time=times,\n",
    "                    model=model,\n",
    "                    method=\"linear\",\n",
    "                    directory=directory,\n",
    "                    parallel=True,\n",
    "                    parallel_splits=parallel_split,\n",
    "                    parallel_max=parallel_max,\n",
    "                    crop=True,\n",
    "                )\n",
    "                split_time = time.time() - start_time\n",
    "        \n",
    "                output_dict = {\n",
    "                    \"split\": parallel_split,\n",
    "                    \"parallel_max\": parallel_max,\n",
    "                    \"time\": split_time,\n",
    "                    \"points\": n,\n",
    "                    \"points_per_split\": int(n / parallel_split),\n",
    "                    \"split_per_parallel\": parallel_split / parallel_max,\n",
    "                    \"directory\": directory,\n",
    "                    \"model\": model,\n",
    "                }\n",
    "                output_list.append(output_dict)\n",
    "                print(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and export\n",
    "data = pd.DataFrame(output_list)\n",
    "data[\"time_per_point\"] = data[\"time\"] / data[\"points\"]\n",
    "data[\"model_multiple\"] = data[\"model\"].apply(lambda x: x == ['EOT20', 'GOT5.5'])\n",
    "data.to_csv(\"test_timings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"test_timings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='points_per_split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[1], linewidth=3)\n",
    "lineplot.invert_xaxis()\n",
    "axes[1].set_title('Time by Points per split')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model_multiple\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='points_per_split', y='time', hue='parallel_max', data=data.query(\"model_multiple\"), ax=axes[1], linewidth=3)\n",
    "lineplot.invert_xaxis()\n",
    "axes[1].set_title('Time by Points per split')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"split_per_parallel\"] = data[\"split\"] / data[\"parallel_max\"]\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='split_per_parallel', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[1], linewidth=3)\n",
    "axes[1].set_title('Time by Splits per parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"model == 'EOT20'\").query(\"parallel_max == 2\").query(\"points == 10000\").set_index(\"points_per_split\").time_per_point.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parallel_max = 16\n",
    "parallel_split=\"auto\"\n",
    "\n",
    "n = 200000\n",
    "models = [\"EOT20\"]  # [\"EOT20\", \"GOT5.5\"]\n",
    "# models = [\"EOT20\", \"GOT5.5\"]\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.process_cpu_count()\n",
    "\n",
    "parallel_split = int(max(1, min(n / 1000, parallel_max) / len(models)))\n",
    "print(parallel_split, n/parallel_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parallel_splits(\n",
    "    total_points,\n",
    "    model_count,\n",
    "    parallel_max=None,\n",
    "    min_points_per_split=1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the optimal number of parallel splits for data\n",
    "    processing based on system resources and processing constraints.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    total_points : int\n",
    "        Total number of data points to process\n",
    "    model_count : int\n",
    "        Number of models that will be run in parallel\n",
    "    parallel_max : int, optional\n",
    "        Maximum number of parallel processes to use. If None, uses CPU core count\n",
    "    min_points_per_split : int, default=1000\n",
    "        Minimum number of points that should be processed in each split\n",
    "    \"\"\"\n",
    "    # Available CPUs\n",
    "    if parallel_max is None:\n",
    "        try:\n",
    "            import psutil\n",
    "\n",
    "            parallel_max = psutil.cpu_count(logical=False)\n",
    "        except ImportError:\n",
    "            parallel_max = os.cpu_count()\n",
    "\n",
    "    # Calculate optimal number of splits based on constraints\n",
    "    splits_by_size = total_points / min_points_per_split\n",
    "    splits_by_cpu = parallel_max / model_count\n",
    "    optimal_splits = min(splits_by_size, splits_by_cpu)\n",
    "\n",
    "    # Convert to integer and ensure at least 1 split\n",
    "    final_split_count = int(max(1, optimal_splits))\n",
    "    return final_split_count\n",
    "\n",
    "\n",
    "_parallel_splits(total_points=1, model_count=1, parallel_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(10.6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count(affinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.cpu_count()\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=None) as executor:\n",
    "    executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "n = 10000\n",
    "directory = \"/gdata1/data/tide_models_clipped/\"\n",
    "directory = \"./tests/data/tide_models/\"\n",
    "# models = [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"]\n",
    "models = [\"EOT20\"]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "    x = np.random.uniform(112.715430, 154.727149, n),\n",
    "    y = np.random.uniform(-44.199061, -10.035282, n),\n",
    "    time = pd.date_range(\"2020\", \"2021\", periods=100),\n",
    "    model=models,\n",
    "    method=\"linear\",\n",
    "    directory=directory,\n",
    "    parallel=True,\n",
    "    parallel_splits=\"auto\",\n",
    "    parallel_max=16,\n",
    "    crop=False,\n",
    ")\n",
    "split_time = time.time() - start_time\n",
    "print(split_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 10000\n",
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (~model_multiple)\").style.background_gradient(cmap=\"YlOrRd\", subset=\"time_per_point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pivot(columns=\"model_multiple\", values=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (model_multiple)\").time.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (~model_multiple)\").time.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(modelled_tides_df_spline.droplevel([\"x\", \"y\"]).tide_height, modelled_tides_df_linear.droplevel([\"x\", \"y\"]).tide_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run equivalent pyTMD code to verify same results\n",
    "# pytmd_tides_spline = tide_elevations(\n",
    "#         x=np.repeat(149.722622, len(measured_tides_ds.time)), \n",
    "#         y=np.repeat(-22.132984, len(measured_tides_ds.time)), \n",
    "#         delta_time=measured_tides_ds.time,\n",
    "#         DIRECTORY=\"/var/share/tide_models/\",\n",
    "#         MODEL=\"FES2012\",\n",
    "#         EPSG=4326,\n",
    "#         TIME=\"datetime\",\n",
    "#         EXTRAPOLATE=True,\n",
    "#         CUTOFF=np.inf,\n",
    "#         METHOD=\"spline\",\n",
    "#         CROP=True,\n",
    "#         # BOUNDS=[148.722622, 149.722622, -22.132984, -23.132984],\n",
    "#         )\n",
    "\n",
    "pytmd_tides_linear = tide_elevations(\n",
    "        x=np.repeat(149.722622, len(measured_tides_ds.time)), \n",
    "        y=np.repeat(-22.132984, len(measured_tides_ds.time)), \n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"/var/share/tide_models/\",\n",
    "        MODEL=\"TPXO9-atlas-v5-nc\",\n",
    "        EPSG=4326,\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=\"linear\",\n",
    "        CROP=True,\n",
    "        # BOUNDS=[140.002622, 149.722622, -23.132984, -22.132984],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(pytmd_tides_spline.data, pytmd_tides_linear.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_df = phase_tides(\n",
    "    x=[122.14],\n",
    "    y=[-17.91],\n",
    "    time=pd.date_range(\"2020-01-01\", \"2020-01-02\", freq=\"h\"),\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    model=[\"EOT20\"],\n",
    "    delta = \"15 min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.date_range(start=\"2000-01-01\", end=\"2000-01-02\", periods=3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pyTMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"spline\", \"EOT20\"\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\"\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "\n",
    "# # Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    time=measured_tides_ds.time,\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    "    # crop=False,\n",
    ")\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"./tests/data/tide_models\",\n",
    "        MODEL=model,\n",
    "        EPSG=int(crs[-4:]),\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=method,\n",
    "        # CORRECTIONS: str | None = None,\n",
    "        # INFER_MINOR: bool = True,\n",
    "        # MINOR_CONSTITUENTS: list | None = None,\n",
    "        # APPLY_FLEXURE: bool = False,\n",
    "        # FILL_VALUE: float = np.nan\n",
    "        # APPEND_NODE=True,\n",
    "        )\n",
    "\n",
    "np.allclose(modelled_tides_df.tide_height.values, pytmd_tides.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"spline\", \"EOT20\"\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\"\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "\n",
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=\"FES2014\",\n",
    "    time=pd.date_range(\"1980\", \"2020\", freq=\"9h\"),\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"/var/share/tide_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df2 = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=\"FES2014\",\n",
    "    time=pd.date_range(\"1980\", \"2020\", freq=\"9h\"),\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"/var/share/tide_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df.tide_height.plot(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df2.tide_height - modelled_tides_df.tide_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error for out of bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y = 180, -50\n",
    "\n",
    "\n",
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    time=measured_tides_ds.time,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import list_models\n",
    "list_models(directory=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stats import pixel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EOT20\"]\n",
    "resample = False\n",
    "\n",
    "stats_ds = pixel_stats(\n",
    "    ds=satellite_ds,\n",
    "    model=models,\n",
    "    resample=resample,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling ebb and flow tidal phases\n",
    "The `tag_tides` function also allows us to determine whether each satellite observation was taken while the tide was rising/incoming (flow tide) or falling/outgoing (ebb tide) by setting `ebb_flow=True`. This is achieved by comparing tide heights 15 minutes before and after the observed satellite observation.\n",
    "\n",
    "Ebb and flow data can provide valuable contextual information for interpreting satellite imagery, particularly in tidal flat or mangrove forest environments where water may remain in the landscape for considerable time after the tidal peak.\n",
    "\n",
    "Once you run the cell below, our data will now also contain a new `ebb_flow` variable under **Data variables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "ds = dc.load(product=\"ga_s2ls_intertidal_cyear_3\", limit=1, measurements=\"elevation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.geo.geobox import GeoBox\n",
    "import xarray as xr\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def _standardise_time(\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Accept a datetime64 ndarray, pandas.DatetimeIndex\n",
    "    or pandas.Timestamp, and return a datetime64 ndarray.\n",
    "    \"\"\"\n",
    "    # Return time as-is if none\n",
    "    if time is None:\n",
    "        return time\n",
    "\n",
    "    # Convert to a 1D datetime64 array\n",
    "    time = np.atleast_1d(time).astype(\"datetime64[ns]\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "def _standardise_inputs(\n",
    "    ds: xr.DataArray | xr.Dataset | GeoBox,\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> (GeoBox, np.ndarray):\n",
    "    \"\"\"\n",
    "    Takes an xarray or GeoBox input and an optional custom times,\n",
    "    and returns a standardised GeoBox and  \n",
    "    \"\"\"\n",
    "\n",
    "    # If `ds` is an xarray object, extract its GeoBox and time\n",
    "    if isinstance(ds, (xr.DataArray, xr.Dataset)):\n",
    "\n",
    "        # Try to extract GeoBox\n",
    "        try:\n",
    "            gbox = ds.odc.geobox\n",
    "        except AttributeError:\n",
    "            error_msg = \"\"\"\n",
    "            Cannot extract a valid GeoBox for `ds`. This is required for\n",
    "            extracting details about `ds`'s CRS and spatial location.\n",
    "            \n",
    "            Import `odc.geo.xr` then run `ds = ds.odc.assign_crs(crs=...)`\n",
    "            to prepare your data before passing it to this function.\n",
    "            \"\"\"\n",
    "            raise Exception(textwrap.dedent(error_msg).strip())\n",
    "\n",
    "        # Use custom time by default if provided; otherwise try and extract from `ds`\n",
    "        if time is not None:\n",
    "            time = _standardise_time(time)\n",
    "        elif \"time\" in ds.coords:\n",
    "            time = ds.coords[\"time\"].values\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`ds` does not have a time dimension, and no custom times were provided via `time`.\"\n",
    "            )\n",
    "\n",
    "    # If `ds` is a GeoBox, use it directly; raise an error if no time was provided\n",
    "    elif isinstance(ds, GeoBox):\n",
    "        gbox = ds\n",
    "        if time is not None:\n",
    "            time = _standardise_time(time)\n",
    "        else:\n",
    "            raise ValueError(\"If `ds` is a GeoBox, `time` must be provided.\")\n",
    "\n",
    "    # Raise error if no valid inputs were provided\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"`ds` must be an xarray.DataArray, xarray.Dataset, or odc.geo.geobox.GeoBox.\"\n",
    "        )\n",
    "\n",
    "    return gbox, time\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "time = pd.date_range(\"2021\", \"2022\")\n",
    "time = pd.Timestamp(\"2022-02-01\")\n",
    "# time = satellite_ds.time\n",
    "# time = [\"a\", \"b\"]\n",
    "\n",
    "\n",
    "gbox, time = _standardise_inputs(ds=ds.drop_dims(\"time\").odc.geobox, time=time)\n",
    "gbox, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds.chunks[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "# time = pd.date_range(\"2021\", \"2022\")\n",
    "# time = pd.Timestamp(\"2022-02-01\")\n",
    "time = satellite_ds.time\n",
    "\n",
    "\n",
    "def _standardise_time(\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Accept a datetime64 ndarray, pandas.DatetimeIndex\n",
    "    or pandas.Timestamp, and return a datetime64 ndarray.\n",
    "    \"\"\"\n",
    "    # Return time as-is if none\n",
    "    if time is None:\n",
    "        return time\n",
    "\n",
    "    # Convert to a 1D datetime64 array\n",
    "    time = np.atleast_1d(time).astype(\"datetime64[ns]\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "# time = pd.date_range(\"2021\", \"2022\")\n",
    "# time = pd.Timestamp(\"2022-02-01\")\n",
    "# time = satellite_ds.time\n",
    "# time = [pd.Timestamp(\"2022-02-01\"), pd.Timestamp(\"2022-02-01\")]\n",
    "# time = None\n",
    "_standardise_time(time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.atleast_1d(time).astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.odc.assign_crs(\"EPSG:3577\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = satellite_ds.nbart_red.drop_attrs(deep=True).drop_vars(\"spatial_ref\").odc.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  #odc.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tide heights\n",
    "ds = tag_tides(\n",
    "    ds, \n",
    "    ebb_flow=True,     \n",
    "    directory=\"../../tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Print output data\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have data giving us the both the tide height and tidal phase (\"ebb\" or \"flow\") for every satellite image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[[\"time\", \"tide_height\", \"ebb_flow\"]].drop_vars(\"spatial_ref\").to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could for example use this data to filter our observations to keep ebbing phase observations only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ebb = ds.where(ds.ebb_flow == \"Ebb\", drop=True)\n",
    "print(ds_ebb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odc.stac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "# Connect to STAC catalog\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "# Set cloud access defaults\n",
    "odc.stac.configure_rio(\n",
    "    cloud_defaults=True,\n",
    "    aws={\"aws_unsigned\": True},\n",
    ")\n",
    "\n",
    "# Build a query and search the STAC catalog for all matching items\n",
    "bbox = [122.160, -18.05, 122.260, -17.95]\n",
    "query = catalog.search(\n",
    "    bbox=bbox,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    datetime=\"2021/2023\",\n",
    ")\n",
    "\n",
    "# Load data into xarray format\n",
    "ds_s2 = odc.stac.load(\n",
    "    items=list(query.items()),\n",
    "    bands=[\"red\"],\n",
    "    crs=\"utm\",\n",
    "    resolution=30,\n",
    "    groupby=\"solar_day\",\n",
    "    bbox=bbox,\n",
    "    fail_on_error=False,\n",
    "    chunks={},\n",
    ")\n",
    "\n",
    "print(ds_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stats_ds.data_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stats import pixel_stats\n",
    "\n",
    "models = [\"EOT20\"]\n",
    "resample = True\n",
    "\n",
    "stats_ds = pixel_stats(\n",
    "    ds=satellite_ds,\n",
    "    model=models,\n",
    "    resample=resample,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Verify dims are correct\n",
    "assert stats_ds.odc.spatial_dims == satellite_ds.odc.spatial_dims\n",
    "\n",
    "# Verify vars are as expected\n",
    "expected_vars = ['hat',  'hot',  'lat',  'lot',  'otr',  'tr',  'spread',  'offset_low',  'offset_high']\n",
    "assert set(expected_vars) == set(stats_ds.data_vars)\n",
    "\n",
    "# Verify tide models are correct\n",
    "assert all(stats_ds[\"tide_model\"].values == models)\n",
    "if len(models) > 1:\n",
    "    assert \"tide_model\" in stats_ds.dims\n",
    "\n",
    "# If resample, assert that statistics have the same shape and dims\n",
    "# as `satellite_ds`\n",
    "if resample:\n",
    "    assert satellite_ds.odc.geobox.shape == stats_ds.odc.geobox.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify values are roughly expected\n",
    "assert np.allclose(stats_ds.offset_high.mean().item, 0.30, atol=0.02)\n",
    "assert np.allclose(stats_ds.offset_low.mean().item, 0.27, atol=0.02)\n",
    "assert np.allclose(stats_ds.spread.mean().item, 0.43, atol=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.offset_high.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.spread.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds[\"tide_model\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds[\"tide_model\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(['hat',  'hot',  'lat',  'lot',  'otr',  'tr',  'spread',  'offset_low',  'offset_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stats_ds.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import pixel_tides\n",
    "\n",
    "pixel_tides(\n",
    "    ds=satellite_ds,\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    directory=\"../tests/data/tide_models\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
