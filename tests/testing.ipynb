{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install uv==0.5.0\n",
    "%pip install -e .. --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyTMD==2.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e /home/jovyan/Robbi/pyTMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pystac_client\n",
    "\n",
    "from pyTMD.compute import tide_elevations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]  # simplified for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_satellite_ds():\n",
    "    \"\"\"\n",
    "    Load a sample timeseries of Landsat 8 data using odc-stac\n",
    "    \"\"\"\n",
    "    # Connect to stac catalogue\n",
    "    catalog = pystac_client.Client.open(\"https://explorer.dea.ga.gov.au/stac\")\n",
    "\n",
    "    # Set cloud defaults\n",
    "    odc.stac.configure_rio(\n",
    "        cloud_defaults=True,\n",
    "        aws={\"aws_unsigned\": True},\n",
    "    )\n",
    "\n",
    "    # Build a query with the parameters above\n",
    "    buffer = 0.08\n",
    "    # buffer = 0.5\n",
    "    bbox = [GAUGE_X - buffer, GAUGE_Y - buffer, GAUGE_X + buffer, GAUGE_Y + buffer]\n",
    "    query = catalog.search(\n",
    "        bbox=bbox,\n",
    "        collections=[\"ga_ls8c_ard_3\"],\n",
    "        datetime=\"2020-01/2020-02\",\n",
    "    )\n",
    "\n",
    "    # Search the STAC catalog for all items matching the query\n",
    "    ds = odc.stac.load(\n",
    "        list(query.items()),\n",
    "        bands=[\"nbart_red\"],\n",
    "        crs=\"epsg:3577\",\n",
    "        resolution=30,\n",
    "        groupby=\"solar_day\",\n",
    "        bbox=bbox,\n",
    "        fail_on_error=False,\n",
    "        chunks={\"x\": 100, \"y\": 200},\n",
    "    )\n",
    "\n",
    "    return ds\n",
    "\n",
    "satellite_ds = load_satellite_ds()\n",
    "\n",
    "\n",
    "def load_measured_tides_ds():\n",
    "    \"\"\"\n",
    "    Load measured sea level data from the Broome ABSLMP tidal station:\n",
    "    http://www.bom.gov.au/oceanography/projects/abslmp/data/data.shtml\n",
    "    \"\"\"\n",
    "    # Metadata for Broome ABSLMP tidal station:\n",
    "    # http://www.bom.gov.au/oceanography/projects/abslmp/data/data.shtml\n",
    "    ahd_offset = -5.322\n",
    "\n",
    "    # Load measured tides from ABSLMP tide gauge data\n",
    "    measured_tides_df = pd.read_csv(\n",
    "        \"tests/data/IDO71013_2020.csv\",\n",
    "        index_col=0,\n",
    "        parse_dates=True,\n",
    "        na_values=-9999,\n",
    "    )[[\"Sea Level\"]]\n",
    "\n",
    "    # Update index and column names\n",
    "    measured_tides_df.index.name = \"time\"\n",
    "    measured_tides_df.columns = [\"tide_height\"]\n",
    "\n",
    "    # Apply station AHD offset\n",
    "    measured_tides_df += ahd_offset\n",
    "\n",
    "    # Return as xarray dataset\n",
    "    return measured_tides_df.to_xarray()\n",
    "\n",
    "\n",
    "def create_synthetic_hamtide11(base_dir=\"tests/data/tide_models_synthetic\"):\n",
    "    \"\"\"\n",
    "    Generates and exports synthetic HAMTIDE11 model data\n",
    "    to test clipping functionality.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)  # Ensure base_dir is a Path object\n",
    "\n",
    "    # Create coordinate arrays\n",
    "    lon = np.arange(0, 360.125, 0.125)  # 2881 points\n",
    "    lat = np.arange(-90, 90.125, 0.125)  # 1441 points\n",
    "\n",
    "    # List of HAMTIDE11 tidal constituents\n",
    "    constituents = [\"2n\", \"k1\", \"k2\", \"m2\", \"n2\", \"o1\", \"p1\", \"q1\", \"s2\"]\n",
    "\n",
    "    # Create HAMTIDE11 output directory\n",
    "    hamtide_dir = base_dir / \"hamtide\"\n",
    "    hamtide_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create and save a NetCDF for each constituent\n",
    "    for constituent in constituents:\n",
    "\n",
    "        # Create synthetic HAMTIDE11 dataset with random data\n",
    "        shape = (len(lat), len(lon))  # 1441, 2881\n",
    "        data = np.random.random(shape).astype(np.float32)\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"RE\": ((\"LAT\", \"LON\"), data),\n",
    "                \"IM\": ((\"LAT\", \"LON\"), data),\n",
    "                \"AMPL\": ((\"LAT\", \"LON\"), data),\n",
    "                \"PHAS\": ((\"LAT\", \"LON\"), data),\n",
    "            },\n",
    "            coords={\"LON\": lon, \"LAT\": lat},\n",
    "            attrs={\"title\": f\"HAMTIDE11a: {constituent} ocean tide\"},\n",
    "        )\n",
    "\n",
    "        # Export\n",
    "        filename = hamtide_dir / f\"{constituent}.hamtide11a.nc\"\n",
    "        ds.to_netcdf(filename)\n",
    "\n",
    "\n",
    "def create_synthetic_eot20(base_dir=\"tests/data/tide_models_synthetic\"):\n",
    "    \"\"\"\n",
    "    Generates and exports synthetic EOT20 model data\n",
    "    to test clipping functionality.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)  # Ensure base_dir is a Path object\n",
    "\n",
    "    # Create coordinate arrays\n",
    "    lon = np.arange(0, 360.125, 0.125)  # 2881 points\n",
    "    lat = np.arange(-90, 90.125, 0.125)  # 1441 points\n",
    "\n",
    "    # List of EOT20 tidal constituents\n",
    "    constituents = [\n",
    "        \"2N2\", \"J1\", \"K1\", \"K2\", \"M2\", \"M4\", \"MF\", \"MM\", \"N2\",\n",
    "        \"O1\", \"P1\", \"Q1\", \"S1\", \"S2\", \"SA\", \"SSA\", \"T2\",\n",
    "    ]\n",
    "\n",
    "    # Create EOT20 output directory\n",
    "    eot20_dir = base_dir / \"EOT20/ocean_tides\"\n",
    "    eot20_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create and save a NetCDF for each constituent\n",
    "    for constituent in constituents:\n",
    "\n",
    "        # Create synthetic EOT20 dataset with random data\n",
    "        shape = (len(lat), len(lon))  # 1441, 2881\n",
    "        data = np.random.random(shape).astype(np.float64)\n",
    "\n",
    "        # Add NaN values to match original\n",
    "        mask = np.random.random(shape) < 0.2\n",
    "        data[mask] = np.nan\n",
    "\n",
    "        # Create the dataset\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"amplitude\": ((\"lat\", \"lon\"), data),\n",
    "                \"phase\": ((\"lat\", \"lon\"), data),\n",
    "                \"imag\": ((\"lat\", \"lon\"), data),\n",
    "                \"real\": ((\"lat\", \"lon\"), data),\n",
    "            },\n",
    "            coords={\"lat\": lat, \"lon\": lon},\n",
    "            attrs={\"title\": f\"DGFI-TUM global empirical ocean tide model\"},\n",
    "        )\n",
    "\n",
    "        # Export\n",
    "        filename = eot20_dir / f\"{constituent}_ocean_eot20.nc\"\n",
    "        ds.to_netcdf(filename)\n",
    "\n",
    "\n",
    "satellite_ds = load_satellite_ds()\n",
    "measured_tides_ds = load_measured_tides_ds()\n",
    "# create_synthetic_eot20()\n",
    "# create_synthetic_hamtide11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_model_tides_ensemble_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_model_tides_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_model_tides_constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_eo.py --verbose -k test_tag_tides_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_stats.py --verbose -k test_tide_aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_utils.py --verbose -k test_clip_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_utils.py --verbose -k test_list_models_extra_databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updates to STAC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 STAC items for landsat-c2-l2\n",
      "Found 13 STAC items for sentinel-2-l2a\n",
      "Setting tide modelling location from dataset centroid: 123.61, -17.00\n",
      "Modelling tides with EOT20, GOT5.5, HAMTIDE11 in parallel (models: 3, splits: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 20.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from odc.geo.geom import point\n",
    "\n",
    "from eo_tides.validation import load_gauge_gesla, ndwi_tide_corr\n",
    "\n",
    "# Sample point in King Sound with variable model performance\n",
    "y, x = -16.99636, 123.61017\n",
    "\n",
    "# Calculate NDWI-tide correlations\n",
    "corr_df, corr_da = ndwi_tide_corr(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    time=(\"2024-09\", \"2024-12\"),\n",
    "    cloud_cover=30,\n",
    "    directory=\"../tests/data/tide_models/\",\n",
    ")\n",
    "\n",
    "# Verify HAMTIDE11 comes out with lowest rank\n",
    "assert corr_df.loc[\"HAMTIDE11\", \"rank\"] == 3\n",
    "\n",
    "# Verify correlations are approximately correct\n",
    "assert np.allclose(corr_df.correlation, [0.77, 0.77, -0.12], atol=0.02)\n",
    "\n",
    "# Verify valid percentages are between 0 and 1\n",
    "assert corr_df[\"valid_perc\"].between(0, 1).all()\n",
    "\n",
    "# Verify data array contains expected dimensions and values\n",
    "assert \"tide_model\" in corr_da.dims\n",
    "assert \"time\" not in corr_da.dims\n",
    "assert set(corr_da.tide_model.values) == set([\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"])\n",
    "\n",
    "# Assert that data envelops original point\n",
    "corr_da.odc.geobox.extent.intersects(point(x, y, crs=\"EPSG:4326\").to_crs(corr_da.odc.crs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = -16.99636, 123.61017\n",
    "directory = \"../../tests/data/tide_models/\"\n",
    "\n",
    "corr_df, corr_da = ndwi_tide_corr(x=x, y=y, directory=directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stac import stac_load\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "crs, res = \"EPSG:3577\", 30\n",
    "\n",
    "\n",
    "\n",
    "# ds, _ = stac_load(\n",
    "#     product=\"landsat-c2-l2\",\n",
    "#     bands=[\"red\"],\n",
    "#     time=(\"2020-01\", \"2020-02\"),\n",
    "#     x=(bbox[0], bbox[2]),\n",
    "#     y=(bbox[1], bbox[3]),\n",
    "#     crs=crs,\n",
    "#     resolution=res,\n",
    "#     groupby=\"solar_day\",\n",
    "#     stac_query={\n",
    "#         \"platform\": {\"in\": [\"landsat-8\"]},\n",
    "#     },\n",
    "#     fail_on_error=False,\n",
    "#     chunks={},\n",
    "# )\n",
    "\n",
    "# ds[\"nbart_red\"] = ds.red\n",
    "# ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.geo.geom import BoundingBox\n",
    "from odc.geo import geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.stac._mdtools import output_geobox, _normalize_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geopolygon = geom_3577\n",
    "geopolygon = None\n",
    "bbox = None\n",
    "lon = (GAUGE_X - 0.08, GAUGE_X + 0.08)\n",
    "lat = (GAUGE_Y - 0.08, GAUGE_Y + 0.08)\n",
    "\n",
    "if geopolygon is not None:\n",
    "    geopolygon = _normalize_geometry(geopolygon)\n",
    "elif bbox is not None:\n",
    "    geopolygon = geom.box(*bbox, crs=\"EPSG:4326\") if isinstance(bbox, list | tuple) else bbox.polygon\n",
    "elif lat is not None and lon is not None:\n",
    "    #     # lon=(x0, x1), lat=(y0, y1)\n",
    "    #     report_extra_args(\"lon,lat\", \"lon\", \"lat\", *grid_params)\n",
    "    #     x0, x1 = sorted(lon)\n",
    "    #     y0, y1 = sorted(lat)\n",
    "    #     geopolygon = geom.box(x0, y0, x1, y1, EPSG4326)\n",
    "    # elif x is not None and y is not None:\n",
    "    #     if crs is None:\n",
    "    #         raise ValueError(\"Need to supply `crs=` when using `x=`, `y=`.\")\n",
    "    #     report_extra_args(\"x,y\", \"x\", \"y\", *grid_params)\n",
    "    #     x0, x1 = sorted(x)\n",
    "    #     y0, y1 = sorted(y)\n",
    "    #     geopolygon = geom.box(x0, y0, x1, y1, crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_list = [GAUGE_X - 0.08, GAUGE_Y - 0.08, GAUGE_X + 0.08, GAUGE_Y + 0.08]\n",
    "\n",
    "bbox_4326 = BoundingBox(*bbox_list, crs=\"EPSG:4326\")\n",
    "geom_4326 = bbox_4326.polygon\n",
    "\n",
    "bbox_3577 = bbox_4326.to_crs(\"EPSG:3577\")\n",
    "geom_3577 = bbox_3577.polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    POLYGON ((122.1383 -18.0808, 122.1383 -17.9208...\n",
       "dtype: geometry"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "gpd.GeoSeries(geom_4326.geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(122.1383, -18.0808),\n",
       " (122.1383, -17.920800000000003),\n",
       " (122.2983, -17.920800000000003),\n",
       " (122.2983, -18.0808),\n",
       " (122.1383, -18.0808)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom_4326.exterior.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"122.1336 -18.086399999999998 0.17279999999999518 0.17279999999999518\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,-36.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.0034559999999999036\" opacity=\"0.6\" d=\"M 122.14,-18.08 L 122.14,-17.92 L 122.3,-17.92 L 122.3,-18.08 L 122.14,-18.08 z\" /></g></svg>"
      ],
      "text/plain": [
       "Geometry(POLYGON ((122.14 -18.08, 122.14 -17.92, 122.3 -17.92, 122.3 -18.08, 122.14 -18.08)), EPSG:4326)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from odc.geo.geom import polygon\n",
    "\n",
    "geopolygon_4326 = polygon(\n",
    "    outer=[\n",
    "        (122.14, -18.08),\n",
    "        (122.14, -17.92),\n",
    "        (122.30, -17.92),\n",
    "        (122.30, -18.08),\n",
    "        (122.14, -18.08),\n",
    "    ],\n",
    "    crs=\"EPSG:4326\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopolygon_4326 = polygon(\n",
    "    outer=[\n",
    "        (122.14, -18.08),\n",
    "        (122.14, -17.92),\n",
    "        (122.30, -17.92),\n",
    "        (122.30, -18.08),\n",
    "        (122.14, -18.08),\n",
    "    ],\n",
    "    crs=\"EPSG:4326\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[122.14, -18.08, 122.3, -17.92]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(geopolygon_4326.boundingbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(left=122.14, bottom=-18.08, right=122.3, top=-17.92, crs=CRS('EPSG:4326'))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from odc.geo.geom import polygon\n",
    "\n",
    "geopolygon_4326 = polygon(\n",
    "    outer=[\n",
    "        (122.14, -18.08),\n",
    "        (122.14, -17.92),\n",
    "        (122.30, -17.92),\n",
    "        (122.30, -18.08),\n",
    "        (122.14, -18.08),\n",
    "    ],\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "\n",
    "bbox = geopolygon_4326.boundingbox\n",
    "bbox = tuple(geopolygon_4326.boundingbox)\n",
    "bbox = list(geopolygon_4326.boundingbox)\n",
    "geopolygon = gpd.GeoDataFrame(geometry=[geopolygon_4326.geom], crs=\"EPSG:4326\")\n",
    "geopolygon = gpd.GeoDataFrame(geometry=[geopolygon_4326.geom], crs=\"EPSG:4326\").to_crs(\"EPSG:3577\")\n",
    "geopolygon = gpd.GeoSeries(geopolygon_4326.geom)\n",
    "geopolygon = geopolygon_4326.geom\n",
    "geopolygon = geopolygon_4326\n",
    "lon, lat = (122.14, 122.30), (-18.08, -17.92)\n",
    "\n",
    "\n",
    "def _get_bbox(bbox=None, geopolygon=None, lon=None, lat=None):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    # If provided as a bounding box, either convert to `odc-geo`\n",
    "    # bounding box or return as-is\n",
    "    if bbox is not None:\n",
    "        bbox_extracted = (\n",
    "            BoundingBox(*bbox, crs=\"EPSG:4326\")\n",
    "            if isinstance(bbox, list | tuple)\n",
    "            else bbox\n",
    "        )\n",
    "    \n",
    "    # If data is provided as a geopolygon, normalise to `odc-geo`\n",
    "    # geometry and extract bounding box\n",
    "    elif geopolygon is not None:\n",
    "        geopolygon_normalised = _normalize_geometry(geopolygon)\n",
    "        bbox_extracted = geopolygon_normalised.boundingbox\n",
    "\n",
    "    # If provided as lon/lat ranges, convert to an `odc-geo` bounding box\n",
    "    elif (lon is not None) and (lat is not None):\n",
    "        bbox_extracted = BoundingBox.from_xy(lon, lat, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Raise error if no valid inputs are provided\n",
    "    else:\n",
    "        err_msg = \"Must provide both `lon` and `lat`, or `geopolygon`, or `bbox`.\"\n",
    "        raise Exception(err_msg)\n",
    "\n",
    "    # Convert bounding box to EPSG:4326 if required\n",
    "    if not bbox_extracted.crs.geographic:\n",
    "        bbox_extracted = bbox_extracted.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    return bbox_extracted\n",
    "\n",
    "\n",
    "bbox_4326 = _get_bbox(bbox=bbox, geopolygon=geopolygon, lon=lon, lat=lat)\n",
    "\n",
    "assert bbox_4326.crs.geographic\n",
    "assert isinstance(bbox_4326, odc.geo.geom.BoundingBox)\n",
    "assert bbox_4326.polygon.intersects(geopolygon_4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bbox_4326.crs.geographic\n",
    "assert isinstance(bbox_4326, odc.geo.geom.BoundingBox)\n",
    "assert bbox_4326.polygon.intersects(geopolygon_4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geopolygon_4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 STAC items for landsat-c2-l2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import odc.stac\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "\n",
    "\n",
    "product=\"landsat-c2-l2\"\n",
    "time=(\"2020-01\", \"2020-02\")\n",
    "stac_url = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "\n",
    "# Connect to client\n",
    "catalog = pystac_client.Client.open(\n",
    "   stac_url,\n",
    "    modifier=(planetary_computer.sign_inplace if \"planetarycomputer\" in stac_url else None),\n",
    ")\n",
    "\n",
    "# Find matching items\n",
    "search = catalog.search(\n",
    "    collections=product,\n",
    "    bbox=(bbox_4326.left, bbox_4326.bottom, bbox_4326.right, bbox_4326.top),\n",
    "    datetime=time,\n",
    "    # query=stac_query if stac_query is not None else None,\n",
    ")\n",
    "\n",
    "# Check how many items were returned\n",
    "items = search.item_collection()\n",
    "print(f\"Found {len(items)} STAC items for {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_params = {\"chunks\": {}}\n",
    "\n",
    "# Load with ODC STAC\n",
    "ds = odc.stac.load(\n",
    "    items=items,\n",
    "    bands=[\"red\"],\n",
    "    bbox=bbox,\n",
    "    geopolygon=geopolygon,\n",
    "    lon=lon,\n",
    "    lat=lat,\n",
    "    **load_params,\n",
    ")\n",
    "\n",
    "# return ds, items\n",
    "\n",
    "    \n",
    "# bbox_4326.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_d72697f9ba8a07beb4e56aa6c7faaef6 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;style&gt;html, body {\n",
       "                width: 100%;\n",
       "                height: 100%;\n",
       "                margin: 0;\n",
       "                padding: 0;\n",
       "            }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;style&gt;#map {\n",
       "                position:absolute;\n",
       "                top:0;\n",
       "                bottom:0;\n",
       "                right:0;\n",
       "                left:0;\n",
       "                }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;script&gt;\n",
       "                L_NO_TOUCH = false;\n",
       "                L_DISABLE_3D = false;\n",
       "            &lt;/script&gt;\n",
       "\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_d72697f9ba8a07beb4e56aa6c7faaef6&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_d72697f9ba8a07beb4e56aa6c7faaef6 = L.map(\n",
       "                &quot;map_d72697f9ba8a07beb4e56aa6c7faaef6&quot;,\n",
       "                {\n",
       "                    center: [0.0, 0.0],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    ...{\n",
       "  &quot;zoom&quot;: 1,\n",
       "  &quot;zoomControl&quot;: true,\n",
       "  &quot;preferCanvas&quot;: false,\n",
       "}\n",
       "\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_763928c2b26c912ce51eb96fae709095 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 19,\n",
       "  &quot;maxNativeZoom&quot;: 19,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_763928c2b26c912ce51eb96fae709095.addTo(map_d72697f9ba8a07beb4e56aa6c7faaef6);\n",
       "        \n",
       "    \n",
       "\n",
       "        function geo_json_6c615a28df5d4c60536318dd1014e442_onEachFeature(feature, layer) {\n",
       "\n",
       "            layer.on({\n",
       "            });\n",
       "        };\n",
       "        var geo_json_6c615a28df5d4c60536318dd1014e442 = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_6c615a28df5d4c60536318dd1014e442_onEachFeature,\n",
       "            \n",
       "            ...{\n",
       "}\n",
       "        });\n",
       "\n",
       "        function geo_json_6c615a28df5d4c60536318dd1014e442_add (data) {\n",
       "            geo_json_6c615a28df5d4c60536318dd1014e442\n",
       "                .addData(data);\n",
       "        }\n",
       "            geo_json_6c615a28df5d4c60536318dd1014e442_add({&quot;features&quot;: [{&quot;geometry&quot;: {&quot;coordinates&quot;: [[122.13830640091412, -17.919992202554848], [122.29918253989422, -17.920638381307995], [122.29854596926073, -18.081694795353133], [122.13752374232995, -18.081042421283314], [122.13830640091412, -17.919992202554848]], &quot;type&quot;: &quot;LineString&quot;}, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;geometry&quot;: {&quot;coordinates&quot;: [122.13830640091412, -17.919992202554848], &quot;type&quot;: &quot;Point&quot;}, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "        geo_json_6c615a28df5d4c60536318dd1014e442.setStyle(function(feature) {return feature.properties.style;});\n",
       "\n",
       "        \n",
       "    \n",
       "            geo_json_6c615a28df5d4c60536318dd1014e442.addTo(map_d72697f9ba8a07beb4e56aa6c7faaef6);\n",
       "        \n",
       "    \n",
       "            map_d72697f9ba8a07beb4e56aa6c7faaef6.fitBounds(\n",
       "                [[-18.081694795353133, 122.13752374232995], [-17.919992202554848, 122.29918253989422]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "        function geo_json_751873cbc8d57490a5f119ae5c05bd5c_styler(feature) {\n",
       "            switch(feature.id) {\n",
       "                default:\n",
       "                    return {&quot;fillOpacity&quot;: 0.3, &quot;weight&quot;: 1};\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function geo_json_751873cbc8d57490a5f119ae5c05bd5c_onEachFeature(feature, layer) {\n",
       "\n",
       "            layer.on({\n",
       "            });\n",
       "        };\n",
       "        var geo_json_751873cbc8d57490a5f119ae5c05bd5c = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_751873cbc8d57490a5f119ae5c05bd5c_onEachFeature,\n",
       "            \n",
       "                style: geo_json_751873cbc8d57490a5f119ae5c05bd5c_styler,\n",
       "            ...{\n",
       "}\n",
       "        });\n",
       "\n",
       "        function geo_json_751873cbc8d57490a5f119ae5c05bd5c_add (data) {\n",
       "            geo_json_751873cbc8d57490a5f119ae5c05bd5c\n",
       "                .addData(data);\n",
       "        }\n",
       "            geo_json_751873cbc8d57490a5f119ae5c05bd5c_add({&quot;features&quot;: [{&quot;geometry&quot;: {&quot;coordinates&quot;: [[[122.16662916236392, -17.920115614963034], [122.16650228556072, -17.94722883476079], [122.16637518453675, -17.974341978104896], [122.16624785913346, -18.00145504489516], [122.16612030919211, -18.028568035031455], [122.16599253455352, -18.055680948413737], [122.16587222137177, -18.08116701691941]], [[122.19495214787635, -17.920234904230202], [122.1948295819596, -17.947348316429704], [122.19470679943987, -17.97446165223212], [122.19458380016404, -18.00157491153738], [122.1944605839787, -18.02868809424545], [122.1943371507301, -18.055801200256415], [122.1942209254205, -18.081287449885032]], [[122.22327534983893, -17.92035007021611], [122.22315709496138, -17.94746366816715], [122.223038631099, -17.97457718977572], [122.22291995810406, -18.001690634941856], [122.22280107582849, -18.028804003565636], [122.222681984124, -18.055917295547232], [122.22256984683163, -18.08140372003843]], [[122.2515987606389, -17.920461112785375], [122.25148481694798, -17.947574889837504], [122.25137067189068, -17.974688590599833], [122.25125632532459, -18.001802214972482], [122.25114177710715, -18.02891576285564], [122.25102702709542, -18.056029234149587], [122.25091897796034, -18.08151582724278]], [[122.27992237266322, -17.92056803180746], [122.27981274030094, -17.947681981309998], [122.27970291419102, -17.97479585457344], [122.27959289419648, -18.001909651498007], [122.27948268018011, -18.029023371983993], [122.27937227200434, -18.05613701593176], [122.27926831116143, -18.081623771366132]], [[122.13817521338262, -17.947105223300905], [122.16650228556072, -17.94722883476079], [122.1948295819596, -17.947348316429704], [122.22315709496138, -17.94746366816715], [122.25148481694798, -17.947574889837504], [122.27981274030094, -17.947681981309998], [122.29907583931382, -17.94775244427782]], [[122.13804379401286, -17.974218167534787], [122.16637518453675, -17.974341978104896], [122.19470679943987, -17.97446165223212], [122.223038631099, -17.97457718977572], [122.25137067189068, -17.974688590599833], [122.27970291419102, -17.97479585457344], [122.29896895016665, -17.974866431041914]], [[122.13791214264096, -18.001331035156195], [122.16624785913346, -18.00145504489516], [122.19458380016404, -18.00157491153738], [122.22291995810406, -18.001690634941856], [122.25125632532459, -18.001802214972482], [122.27959289419648, -18.001909651498007], [122.29886187231949, -18.001980341500573]], [[122.13778025910273, -18.028443826064883], [122.16612030919211, -18.028568035031455], [122.1944605839787, -18.02868809424545], [122.22280107582849, -18.028804003565636], [122.25114177710715, -18.02891576285564], [122.27948268018011, -18.029023371983993], [122.29875460563869, -18.029094175554132]], [[122.1376481432336, -18.055556540160687], [122.16599253455352, -18.055680948413737], [122.1943371507301, -18.055801200256415], [122.222681984124, -18.055917295547232], [122.25102702709542, -18.056029234149587], [122.27937227200434, -18.05613701593176], [122.29864714999044, -18.056207933103032]]], &quot;type&quot;: &quot;MultiLineString&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "\n",
       "        \n",
       "    \n",
       "            geo_json_751873cbc8d57490a5f119ae5c05bd5c.addTo(map_d72697f9ba8a07beb4e56aa6c7faaef6);\n",
       "        \n",
       "    \n",
       "            map_d72697f9ba8a07beb4e56aa6c7faaef6.fitBounds(\n",
       "                [[-18.081623771366132, 122.1376481432336], [-17.920115614963034, 122.29907583931382]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f9008b021a0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.odc.geobox.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox = bbox_3577\n",
    "isinstance(bbox, list | tuple)\n",
    "# BoundingBox(*bbox, crs=\"EPSG:4326\") if isinstance(bbox, list | tuple) else bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(left=inf, bottom=inf, right=inf, top=inf, crs=CRS('EPSG:3577'))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "[{'type': 'value_error', 'loc': ('body', 'bbox'), 'msg': 'Value error, Bounding box must be within (-180, -90, 180, 90)', 'input': [-1044042.196467346, -1971394.0240652247, -1025792.5875763459, -1952440.9012696152], 'ctx': {'error': ValueError('Bounding box must be within (-180, -90, 180, 90)')}}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds, _ \u001b[38;5;241m=\u001b[39m \u001b[43mstac_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlandsat-c2-l2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2020-01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2020-02\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# x=(bbox[0], bbox[2]),\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# y=(bbox[1], bbox[3]),\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_ob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolygon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msolar_day\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstac_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplatform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43min\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlandsat-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfail_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Robbi/eo-tides/eo_tides/stac.py:117\u001b[0m, in \u001b[0;36mstac_load\u001b[0;34m(product, bands, time, x, y, geom, stac_query, stac_url, **load_params)\u001b[0m\n\u001b[1;32m    109\u001b[0m search \u001b[38;5;241m=\u001b[39m catalog\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m    110\u001b[0m     collections\u001b[38;5;241m=\u001b[39mproduct,\n\u001b[1;32m    111\u001b[0m     bbox\u001b[38;5;241m=\u001b[39m(bbox\u001b[38;5;241m.\u001b[39mleft, bbox\u001b[38;5;241m.\u001b[39mbottom, bbox\u001b[38;5;241m.\u001b[39mright, bbox\u001b[38;5;241m.\u001b[39mtop),\n\u001b[1;32m    112\u001b[0m     datetime\u001b[38;5;241m=\u001b[39mtime,\n\u001b[1;32m    113\u001b[0m     query\u001b[38;5;241m=\u001b[39mstac_query \u001b[38;5;28;01mif\u001b[39;00m stac_query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Check how many items were returned\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m items \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(items)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m STAC items for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Load with ODC STAC\u001b[39;00m\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pystac_client/item_search.py:855\u001b[0m, in \u001b[0;36mItemSearch.item_collection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;124;03mGet the matching items as a :py:class:`pystac.ItemCollection`.\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \n\u001b[1;32m    850\u001b[0m \u001b[38;5;124;03mReturn:\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m    ItemCollection: The item collection\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# Bypass the cache here, so that we can pass __preserve_dict__\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# without mutating what's in the cache.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m feature_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_collection_as_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# already signed in item_collection_as_dict\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ItemCollection\u001b[38;5;241m.\u001b[39mfrom_dict(\n\u001b[1;32m    858\u001b[0m     feature_collection, preserve_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\n\u001b[1;32m    859\u001b[0m )\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pystac_client/item_search.py:876\u001b[0m, in \u001b[0;36mItemSearch.item_collection_as_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03mGet the matching items as an item-collection-like dict.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;124;03m    Dict : A GeoJSON FeatureCollection\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    875\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 876\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpages_as_dicts():\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m page[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    878\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(feature)\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pystac_client/item_search.py:826\u001b[0m, in \u001b[0;36mItemSearch.pages_as_dicts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stac_io, StacApiIO):\n\u001b[1;32m    825\u001b[0m     num_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stac_io\u001b[38;5;241m.\u001b[39mget_pages(\n\u001b[1;32m    827\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parameters()\n\u001b[1;32m    828\u001b[0m     ):\n\u001b[1;32m    829\u001b[0m         call_modifier(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodifier, page)\n\u001b[1;32m    830\u001b[0m         features \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pystac_client/stac_api_io.py:304\u001b[0m, in \u001b[0;36mStacApiIO.get_pages\u001b[0;34m(self, url, method, parameters)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_pages\u001b[39m(\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    294\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    295\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     parameters: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    298\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Iterator that yields dictionaries for each page at a STAC paging\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    endpoint, e.g., /collections, /search\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m    Return:\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m        Dict[str, Any] : JSON content from a single page\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m     page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (page\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m page\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollections\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pystac/stac_io.py:206\u001b[0m, in \u001b[0;36mStacIO.read_json\u001b[0;34m(self, source, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, source: HREF, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    190\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read a dict from the given source.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    See :func:`StacIO.read_text <pystac.StacIO.read_text>` for usage of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m        given source.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjson_loads(txt)\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pystac_client/stac_api_io.py:167\u001b[0m, in \u001b[0;36mStacApiIO.read_text\u001b[0;34m(self, source, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m href \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(source)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_url(href):\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(href) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pystac_client/stac_api_io.py:219\u001b[0m, in \u001b[0;36mStacApiIO.request\u001b[0;34m(self, href, method, headers, parameters)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIError(\u001b[38;5;28mstr\u001b[39m(err))\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIError\u001b[38;5;241m.\u001b[39mfrom_response(resp)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAPIError\u001b[0m: [{'type': 'value_error', 'loc': ('body', 'bbox'), 'msg': 'Value error, Bounding box must be within (-180, -90, 180, 90)', 'input': [-1044042.196467346, -1971394.0240652247, -1025792.5875763459, -1952440.9012696152], 'ctx': {'error': ValueError('Bounding box must be within (-180, -90, 180, 90)')}}]"
     ]
    }
   ],
   "source": [
    "ds, _ = stac_load(\n",
    "    product=\"landsat-c2-l2\",\n",
    "    bands=[\"red\"],\n",
    "    time=(\"2020-01\", \"2020-02\"),\n",
    "    # x=(bbox[0], bbox[2]),\n",
    "    # y=(bbox[1], bbox[3]),\n",
    "    geom=bbox_ob.polygon,\n",
    "    crs=crs,\n",
    "    resolution=res,\n",
    "    groupby=\"solar_day\",\n",
    "    stac_query={\n",
    "        \"platform\": {\"in\": [\"landsat-8\"]},\n",
    "    },\n",
    "    fail_on_error=False,\n",
    "    chunks={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base rgba(0, 0, 0, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, white)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 15))\n",
       "  );\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, #111111)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 15))\n",
       "  );\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "  border: 2px solid transparent !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0) !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  border-color: var(--xr-background-color-row-odd);\n",
       "  margin-bottom: 0;\n",
       "  padding-top: 2px;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "  border-color: var(--xr-background-color-row-even);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  border-top: 2px dotted var(--xr-background-color);\n",
       "  padding-bottom: 20px !important;\n",
       "  padding-top: 10px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in + label,\n",
       ".xr-var-data-in + label,\n",
       ".xr-index-data-in + label {\n",
       "  padding: 0 1px;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-data > pre,\n",
       ".xr-index-data > pre,\n",
       ".xr-var-data > table > tbody > tr {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked + label > .xr-icon-file-text2,\n",
       ".xr-var-data-in:checked + label > .xr-icon-database,\n",
       ".xr-index-data-in:checked + label > .xr-icon-database {\n",
       "  color: var(--xr-font-color0);\n",
       "  filter: drop-shadow(1px 1px 5px var(--xr-font-color2));\n",
       "  stroke-width: 0.8px;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 5MB\n",
       "Dimensions:      (y: 633, x: 609, time: 7)\n",
       "Coordinates:\n",
       "  * y            (y) float64 5kB -1.952e+06 -1.952e+06 ... -1.971e+06 -1.971e+06\n",
       "  * x            (x) float64 5kB -1.044e+06 -1.044e+06 ... -1.026e+06 -1.026e+06\n",
       "    spatial_ref  int32 4B 3577\n",
       "  * time         (time) datetime64[ns] 56B 2020-01-04T01:55:30.147982 ... 202...\n",
       "Data variables:\n",
       "    red          (time, y, x) uint16 5MB dask.array&lt;chunksize=(1, 633, 609), meta=np.ndarray&gt;</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-57c14151-fbc2-4db3-9515-c8a32c4f002a' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-57c14151-fbc2-4db3-9515-c8a32c4f002a' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>y</span>: 633</li><li><span class='xr-has-index'>x</span>: 609</li><li><span class='xr-has-index'>time</span>: 7</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-a796f53f-5a7b-4014-84d3-d975a88c4821' class='xr-section-summary-in' type='checkbox'  checked><label for='section-a796f53f-5a7b-4014-84d3-d975a88c4821' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y</span></div><div class='xr-var-dims'>(y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-1.952e+06 ... -1.971e+06</div><input id='attrs-cc5dee87-3ecd-4ede-95d7-749da7d94433' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-cc5dee87-3ecd-4ede-95d7-749da7d94433' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a9a0dffa-4900-4b9f-843e-9465b366dd42' class='xr-var-data-in' type='checkbox'><label for='data-a9a0dffa-4900-4b9f-843e-9465b366dd42' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>metre</dd><dt><span>resolution :</span></dt><dd>-30.0</dd><dt><span>crs :</span></dt><dd>EPSG:3577</dd></dl></div><div class='xr-var-data'><pre>array([-1952445., -1952475., -1952505., ..., -1971345., -1971375., -1971405.],\n",
       "      shape=(633,))</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-1.044e+06 ... -1.026e+06</div><input id='attrs-a87be1ad-c9f9-483f-ac21-69ce943495a7' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a87be1ad-c9f9-483f-ac21-69ce943495a7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2b8538bb-53bb-4aa0-bc6d-527323536e44' class='xr-var-data-in' type='checkbox'><label for='data-2b8538bb-53bb-4aa0-bc6d-527323536e44' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>metre</dd><dt><span>resolution :</span></dt><dd>30.0</dd><dt><span>crs :</span></dt><dd>EPSG:3577</dd></dl></div><div class='xr-var-data'><pre>array([-1044045., -1044015., -1043985., ..., -1025865., -1025835., -1025805.],\n",
       "      shape=(609,))</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>spatial_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>3577</div><input id='attrs-bd488085-1d18-42b1-bb61-1aca9b8fbcf3' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-bd488085-1d18-42b1-bb61-1aca9b8fbcf3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7ab52b7c-2808-4528-9993-52c84c737309' class='xr-var-data-in' type='checkbox'><label for='data-7ab52b7c-2808-4528-9993-52c84c737309' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>spatial_ref :</span></dt><dd>PROJCRS[&quot;GDA94 / Australian Albers&quot;,BASEGEOGCRS[&quot;GDA94&quot;,DATUM[&quot;Geocentric Datum of Australia 1994&quot;,ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101,LENGTHUNIT[&quot;metre&quot;,1]]],PRIMEM[&quot;Greenwich&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],ID[&quot;EPSG&quot;,4283]],CONVERSION[&quot;Australian Albers&quot;,METHOD[&quot;Albers Equal Area&quot;,ID[&quot;EPSG&quot;,9822]],PARAMETER[&quot;Latitude of false origin&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433],ID[&quot;EPSG&quot;,8821]],PARAMETER[&quot;Longitude of false origin&quot;,132,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433],ID[&quot;EPSG&quot;,8822]],PARAMETER[&quot;Latitude of 1st standard parallel&quot;,-18,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433],ID[&quot;EPSG&quot;,8823]],PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,-36,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433],ID[&quot;EPSG&quot;,8824]],PARAMETER[&quot;Easting at false origin&quot;,0,LENGTHUNIT[&quot;metre&quot;,1],ID[&quot;EPSG&quot;,8826]],PARAMETER[&quot;Northing at false origin&quot;,0,LENGTHUNIT[&quot;metre&quot;,1],ID[&quot;EPSG&quot;,8827]]],CS[Cartesian,2],AXIS[&quot;(E)&quot;,east,ORDER[1],LENGTHUNIT[&quot;metre&quot;,1]],AXIS[&quot;(N)&quot;,north,ORDER[2],LENGTHUNIT[&quot;metre&quot;,1]],USAGE[SCOPE[&quot;Statistical analysis.&quot;],AREA[&quot;Australia - Australian Capital Territory; New South Wales; Northern Territory; Queensland; South Australia; Tasmania; Western Australia; Victoria.&quot;],BBOX[-43.7,112.85,-9.86,153.69]],ID[&quot;EPSG&quot;,3577]]</dd><dt><span>crs_wkt :</span></dt><dd>PROJCRS[&quot;GDA94 / Australian Albers&quot;,BASEGEOGCRS[&quot;GDA94&quot;,DATUM[&quot;Geocentric Datum of Australia 1994&quot;,ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101,LENGTHUNIT[&quot;metre&quot;,1]]],PRIMEM[&quot;Greenwich&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],ID[&quot;EPSG&quot;,4283]],CONVERSION[&quot;Australian Albers&quot;,METHOD[&quot;Albers Equal Area&quot;,ID[&quot;EPSG&quot;,9822]],PARAMETER[&quot;Latitude of false origin&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433],ID[&quot;EPSG&quot;,8821]],PARAMETER[&quot;Longitude of false origin&quot;,132,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433],ID[&quot;EPSG&quot;,8822]],PARAMETER[&quot;Latitude of 1st standard parallel&quot;,-18,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433],ID[&quot;EPSG&quot;,8823]],PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,-36,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433],ID[&quot;EPSG&quot;,8824]],PARAMETER[&quot;Easting at false origin&quot;,0,LENGTHUNIT[&quot;metre&quot;,1],ID[&quot;EPSG&quot;,8826]],PARAMETER[&quot;Northing at false origin&quot;,0,LENGTHUNIT[&quot;metre&quot;,1],ID[&quot;EPSG&quot;,8827]]],CS[Cartesian,2],AXIS[&quot;(E)&quot;,east,ORDER[1],LENGTHUNIT[&quot;metre&quot;,1]],AXIS[&quot;(N)&quot;,north,ORDER[2],LENGTHUNIT[&quot;metre&quot;,1]],USAGE[SCOPE[&quot;Statistical analysis.&quot;],AREA[&quot;Australia - Australian Capital Territory; New South Wales; Northern Territory; Queensland; South Australia; Tasmania; Western Australia; Victoria.&quot;],BBOX[-43.7,112.85,-9.86,153.69]],ID[&quot;EPSG&quot;,3577]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314140356</dd><dt><span>inverse_flattening :</span></dt><dd>298.257222101</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>GRS 1980</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>GDA94</dd><dt><span>horizontal_datum_name :</span></dt><dd>Geocentric Datum of Australia 1994</dd><dt><span>projected_crs_name :</span></dt><dd>GDA94 / Australian Albers</dd><dt><span>grid_mapping_name :</span></dt><dd>albers_conical_equal_area</dd><dt><span>standard_parallel :</span></dt><dd>(-18.0, -36.0)</dd><dt><span>latitude_of_projection_origin :</span></dt><dd>0.0</dd><dt><span>longitude_of_central_meridian :</span></dt><dd>132.0</dd><dt><span>false_easting :</span></dt><dd>0.0</dd><dt><span>false_northing :</span></dt><dd>0.0</dd><dt><span>GeoTransform :</span></dt><dd>-1044060 30 0 -1952430 0 -30</dd></dl></div><div class='xr-var-data'><pre>array(3577, dtype=int32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2020-01-04T01:55:30.147982 ... 2...</div><input id='attrs-5a371f43-0711-4e35-a998-09a198e06330' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-5a371f43-0711-4e35-a998-09a198e06330' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-57887b6e-970d-4135-ae61-05c2b17d5bc8' class='xr-var-data-in' type='checkbox'><label for='data-57887b6e-970d-4135-ae61-05c2b17d5bc8' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2020-01-04T01:55:30.147982000&#x27;, &#x27;2020-01-13T01:49:17.893353000&#x27;,\n",
       "       &#x27;2020-01-20T01:55:26.970307000&#x27;, &#x27;2020-01-29T01:49:13.246426000&#x27;,\n",
       "       &#x27;2020-02-05T01:55:21.341069000&#x27;, &#x27;2020-02-14T01:49:09.082804000&#x27;,\n",
       "       &#x27;2020-02-21T01:55:18.253401000&#x27;], dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-e4ef7862-56e8-4180-86ff-fe12a506607d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-e4ef7862-56e8-4180-86ff-fe12a506607d' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>red</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 633, 609), meta=np.ndarray&gt;</div><input id='attrs-887a1350-df50-44a5-9c9d-5dec761b6d29' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-887a1350-df50-44a5-9c9d-5dec761b6d29' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-71dbcb07-0e7a-4e02-9374-2b67010aa8ff' class='xr-var-data-in' type='checkbox'><label for='data-71dbcb07-0e7a-4e02-9374-2b67010aa8ff' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>nodata :</span></dt><dd>0</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 5.15 MiB </td>\n",
       "                        <td> 752.92 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (7, 633, 609) </td>\n",
       "                        <td> (1, 633, 609) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 7 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"190\" height=\"185\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"25\" y2=\"15\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"25\" y2=\"135\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"122\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"124\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"126\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"128\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"130\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"133\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"135\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 25.235759051223276,15.235759051223278 25.235759051223276,135.23575905122328 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"125\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"127\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"129\" y2=\"4\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"131\" y2=\"6\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"134\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"136\" y2=\"10\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"138\" y2=\"13\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"140\" y2=\"15\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"25\" y2=\"15\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"125\" y1=\"0\" x2=\"140\" y2=\"15\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 125.45023696682466,0.0 140.68599601804794,15.235759051223278 25.235759051223276,15.235759051223278\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"140\" y2=\"15\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"135\" x2=\"140\" y2=\"135\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"135\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"140\" y1=\"15\" x2=\"140\" y2=\"135\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"25.235759051223276,15.235759051223278 140.68599601804794,15.235759051223278 140.68599601804794,135.23575905122328 25.235759051223276,135.23575905122328\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"82.960878\" y=\"155.235759\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >609</text>\n",
       "  <text x=\"160.685996\" y=\"75.235759\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,160.685996,75.235759)\">633</text>\n",
       "  <text x=\"7.617880\" y=\"147.617880\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.617880,147.617880)\">7</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-5886233c-58a3-4c95-bc9a-21a175e15d72' class='xr-section-summary-in' type='checkbox'  ><label for='section-5886233c-58a3-4c95-bc9a-21a175e15d72' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>y</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-6cfb8e80-a053-42c4-9363-31996a7d1640' class='xr-index-data-in' type='checkbox'/><label for='index-6cfb8e80-a053-42c4-9363-31996a7d1640' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-1952445.0, -1952475.0, -1952505.0, -1952535.0, -1952565.0, -1952595.0,\n",
       "       -1952625.0, -1952655.0, -1952685.0, -1952715.0,\n",
       "       ...\n",
       "       -1971135.0, -1971165.0, -1971195.0, -1971225.0, -1971255.0, -1971285.0,\n",
       "       -1971315.0, -1971345.0, -1971375.0, -1971405.0],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;y&#x27;, length=633))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>x</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-0f931705-b83e-42db-b846-ed5474b4a683' class='xr-index-data-in' type='checkbox'/><label for='index-0f931705-b83e-42db-b846-ed5474b4a683' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-1044045.0, -1044015.0, -1043985.0, -1043955.0, -1043925.0, -1043895.0,\n",
       "       -1043865.0, -1043835.0, -1043805.0, -1043775.0,\n",
       "       ...\n",
       "       -1026075.0, -1026045.0, -1026015.0, -1025985.0, -1025955.0, -1025925.0,\n",
       "       -1025895.0, -1025865.0, -1025835.0, -1025805.0],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;x&#x27;, length=609))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-cd02430f-f10c-4b1d-8fe8-ae7d4be45efe' class='xr-index-data-in' type='checkbox'/><label for='index-cd02430f-f10c-4b1d-8fe8-ae7d4be45efe' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2020-01-04 01:55:30.147982&#x27;, &#x27;2020-01-13 01:49:17.893353&#x27;,\n",
       "               &#x27;2020-01-20 01:55:26.970307&#x27;, &#x27;2020-01-29 01:49:13.246426&#x27;,\n",
       "               &#x27;2020-02-05 01:55:21.341069&#x27;, &#x27;2020-02-14 01:49:09.082804&#x27;,\n",
       "               &#x27;2020-02-21 01:55:18.253401&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-8fe5d226-e6df-4fff-85e5-9b36d6c7ab4d' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-8fe5d226-e6df-4fff-85e5-9b36d6c7ab4d' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 5MB\n",
       "Dimensions:      (y: 633, x: 609, time: 7)\n",
       "Coordinates:\n",
       "  * y            (y) float64 5kB -1.952e+06 -1.952e+06 ... -1.971e+06 -1.971e+06\n",
       "  * x            (x) float64 5kB -1.044e+06 -1.044e+06 ... -1.026e+06 -1.026e+06\n",
       "    spatial_ref  int32 4B 3577\n",
       "  * time         (time) datetime64[ns] 56B 2020-01-04T01:55:30.147982 ... 202...\n",
       "Data variables:\n",
       "    red          (time, y, x) uint16 5MB dask.array<chunksize=(1, 633, 609), meta=np.ndarray>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import pytest\n",
    "\n",
    "# Connect to STAC catalog\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "# Set cloud access defaults\n",
    "odc.stac.configure_rio(\n",
    "    cloud_defaults=True,\n",
    "    aws={\"aws_unsigned\": True},\n",
    ")\n",
    "\n",
    "# Build a query with the parameters above\n",
    "query = catalog.search(\n",
    "    bbox=bbox,\n",
    "    collections=[\"landsat-c2-l2\"],\n",
    "    datetime=\"2020-01/2020-02\",\n",
    "    query={\n",
    "        \"platform\": {\"in\": [\"landsat-8\"]},\n",
    "    },\n",
    ")\n",
    "\n",
    "# Search the STAC catalog for all items matching the query\n",
    "ds_old = odc.stac.load(\n",
    "    list(query.items()),\n",
    "    bands=[\"red\"],\n",
    "    crs=crs,\n",
    "    resolution=res,\n",
    "    groupby=\"solar_day\",\n",
    "    bbox=bbox,\n",
    "    fail_on_error=False,\n",
    "    chunks={},\n",
    ")\n",
    "\n",
    "# Rename for compatibility with original DEA tests\n",
    "ds_old[\"nbart_red\"] = ds_old.red\n",
    "ds_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DE Africa testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "model_tides(\n",
    "    x=(-17.334229, -17.314229),\n",
    "    y=(14.717859, 14.737859),\n",
    "    time=[\"2020-09-01\"],\n",
    "    model=\"FES2014\",\n",
    "    # directory=\"/gdata1/data/tide_models/\",\n",
    "    # directory=\"/var/share/tide_models/\",\n",
    "    directory=\"/home/jovyan/tide_models_africa\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import clip_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clip_models(input_directory=\"/gdata1/data/tide_models/\",\n",
    "            output_directory=\"/home/jovyan/tide_models_africa\",\n",
    "            model=\"FES2014\",\n",
    "            bbox=(-25.36055496,-42.96972610,63.49575409,41.34040909),\n",
    "           overwrite=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constituents bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eo_tides\n",
    "\n",
    "eo_tides.model.model_tides(\n",
    "    x=122.2183,\n",
    "    y=-18.0008,\n",
    "    time=pd.date_range(\"2020-01-01\", \"2020-01-07\", freq=\"1h\"),\n",
    "    constituents=['m2', 's2'],   # works with `None`\n",
    "    model=\"EOT20\",  # also fails with `FES2022`\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ").tide_height.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import pandas as pd\n",
    "from eo_tides.stats import tide_aliasing \n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"satellites, c, units, style, expect_error\",\n",
    "    [\n",
    "        ([\"landsat\"], [\"m2\", \"k1\"], \"days\", False, None),\n",
    "        ([\"sentinel-2\"], None, \"hours\", True, None),\n",
    "        ([\"swot\", \"landsat\"], [\"k1\"], \"years\", False, None),\n",
    "        ([\"landsat\"], [\"mm\"], \"days\", False, None),\n",
    "        ([\"invalid-sat\"], [\"m2\"], \"days\", False, ValueError),\n",
    "        ([\"landsat\"], [\"m2\"], \"centuries\", False, ValueError),\n",
    "    ],\n",
    ")\n",
    "def test_tide_aliasing(satellites, c, units, style, expect_error):\n",
    "    if expect_error:\n",
    "        with pytest.raises(expect_error):\n",
    "            tide_aliasing(satellites, c=c, units=units, style=style)\n",
    "    else:\n",
    "        result = tide_aliasing(satellites, c=c, units=units, style=style)\n",
    "\n",
    "        # Verify output is a dataframe\n",
    "        if style:\n",
    "            assert isinstance(result, pd.io.formats.style.Styler)\n",
    "        else:\n",
    "            assert isinstance(result, pd.DataFrame)\n",
    "\n",
    "        # Verify\n",
    "        assert \"name\" in result.columns\n",
    "        assert \"type\" in result.columns\n",
    "        assert \"period\" in result.columns\n",
    "\n",
    "        for sat in satellites:\n",
    "            assert (\"aliasing_period\", sat) in result.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellites, c, units, style, expect_error = {\"custom-sat1\": 6, \"custom-sat2\": 10}, None, \"hours\", True, None\n",
    "test_tide_aliasing(satellites, c, units, style, expect_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tide_aliasing(satellites={\"boo\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"bad_args, expected_exception\",\n",
    "    [\n",
    "        ({\"time\": None}, ValueError),\n",
    "        ({\"method\": \"cubic\"}, ValueError),\n",
    "        ({\"output_units\": \"feet\"}, ValueError),\n",
    "        ({\"output_format\": \"stacked\"}, ValueError),\n",
    "        ({\"x\": np.array([\"a\", \"b\", \"c\"])}, TypeError),\n",
    "        ({\"y\": np.array([\"a\", \"b\", \"c\"])}, TypeError),\n",
    "        ({\"x\": np.array([1, 2])}, ValueError),\n",
    "        (\n",
    "            {\"mode\": \"one-to-one\", \"time\": np.array([\"2025-01-01\", \"2025-01-02\"])},\n",
    "            ValueError,\n",
    "        ),\n",
    "    ],\n",
    "    ids=[\n",
    "        \"missing_time\",\n",
    "        \"invalid_method\",\n",
    "        \"invalid_units\",\n",
    "        \"invalid_format\",\n",
    "        \"non_numeric_x\",\n",
    "        \"non_numeric_y\",\n",
    "        \"x_y_length_mismatch\",\n",
    "        \"time_length_mismatch\",\n",
    "    ],\n",
    ")\n",
    "def test_model_tides_validation(bad_args, expected_exception):\n",
    "\n",
    "    # Dummy valid inputs\n",
    "    args = {\n",
    "        \"x\": GAUGE_X,\n",
    "        \"y\": GAUGE_Y,\n",
    "        \"time\": np.array(\n",
    "            [\"2025-01-01\", \"2025-01-02\", \"2025-01-03\"], dtype=\"datetime64[ns]\"\n",
    "        ),\n",
    "        \"directory\": \"/var/share/tide_models/\",\n",
    "    }\n",
    "\n",
    "    # Update with bad kwargs\n",
    "    args.update(bad_args)\n",
    "\n",
    "    # Verify error is raised\n",
    "    with pytest.raises(expected_exception):\n",
    "        model_tides(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pytest\n",
    "\n",
    "from eo_tides.utils import _set_directory  # Replace with actual import\n",
    "\n",
    "\n",
    "\n",
    "# Use monkeypatch to test setting and unsetting environment var\n",
    "@pytest.mark.parametrize(\n",
    "    \"directory,env_var,expected_exception\",\n",
    "    [\n",
    "        # Case 1: No directory, no env var → Exception\n",
    "        (None, None, Exception),\n",
    "        \n",
    "        # Case 2: Directory set, but path doesn't exist → FileNotFoundError\n",
    "        (\"/some/nonexistent/path\", None, FileNotFoundError),\n",
    "\n",
    "        # Case 3: Env var set, but path doesn't exist → FileNotFoundError\n",
    "        (None, \"/some/nonexistent/path\", FileNotFoundError),\n",
    "    ],\n",
    "    ids=[\"no_directory_or_env\", \"invalid_dir\", \"invalid_env_var\"]\n",
    ")\n",
    "def test_set_directory_errors(monkeypatch, directory, env_var, expected_exception):\n",
    "    # Ensure env var is unset unless explicitly requested\n",
    "    if env_var is None:\n",
    "        monkeypatch.delenv(\"EO_TIDES_TIDE_MODELS\", raising=False)\n",
    "    else:\n",
    "        monkeypatch.setenv(\"EO_TIDES_TIDE_MODELS\", env_var)\n",
    "\n",
    "    # with pytest.raises(expected_exception):\n",
    "    _set_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from unittest.mock import patch\n",
    "\n",
    "from eo_tides.utils import _standardise_models  # Replace with actual import\n",
    "\n",
    "\n",
    "# Test expected failures during model standardisation\n",
    "@pytest.mark.parametrize(\n",
    "    \"model, ensemble_models, err_msg\",\n",
    "    [\n",
    "        # Case 1: Duplicate models\n",
    "        ([\"EOT20\", \"EOT20\"], None, \"duplicate values\"),\n",
    "\n",
    "        # Case 2: Unsupported model\n",
    "        ([\"bad_model\"], None, \"not valid\"),\n",
    "\n",
    "        # Case 3: Model valid but not available\n",
    "        ([\"FES2012\"], None, \"not available\"),\n",
    "\n",
    "        # Case 4: Ensemble requested but ensemble model not available\n",
    "        ([\"ensemble\"], [\"EOT20\", \"FES2012\"], \"ensemble models are not available\"),\n",
    "    ],\n",
    "    ids=[\"duplicate_model\", \"invalid_model\", \"unavailable_model\", \"unavailable_ensemble\"],\n",
    ")\n",
    "def test_standardise_models_errors(model, ensemble_models, err_msg):\n",
    "\n",
    "    with pytest.raises(ValueError, match=err_msg):\n",
    "        _standardise_models(\n",
    "            model=model,\n",
    "            directory=\"../tests/data/tide_models\",\n",
    "            ensemble_models=ensemble_models,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_standardise_models_validation([\"ensemble\"], [\"EOT20\", \"FES2012\"], \"ensemble models are not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTMD\n",
    "\n",
    "custom_dict = {\n",
    "    \"format\": \"FES-netcdf\",\n",
    "    \"model_file\": [\n",
    "        \"EOT20/ocean_tides/2N2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/J1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/K1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/K2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/M2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/M4_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/MF_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/MM_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/N2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/O1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/P1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/Q1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/S1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/S2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/SA_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/SSA_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/T2_ocean_eot20.nc\"\n",
    "    ],\n",
    "    \"name\": \"EOT20_custom\",\n",
    "    \"reference\": \"https://doi.org/10.17882/79489\",\n",
    "    \"scale\": 0.01,\n",
    "    \"type\": \"z\",\n",
    "    \"variable\": \"tide_ocean\",\n",
    "    \"version\": \"EOT20\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "pyTMD.io.model(\"/gdata1/data/tide_models\").from_dict(custom_dict).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model def from dict\n",
    "model = pyTMD.io.model(directory=\"/var/share/tide_models/\").from_dict(custom_dict)\n",
    "assert model.verify\n",
    "\n",
    "# Read tidal constants and interpolate to grid points\n",
    "amp, ph, c = model.extract_constants(155, -32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model def from file\n",
    "model = pyTMD.io.model(directory=\"/var/share/tide_models/\").from_file(\"tests/data/model_EOT20custom.json\")\n",
    "assert model.verify\n",
    "\n",
    "# Read tidal constants and interpolate to grid points\n",
    "amp, ph, c = model.extract_constants(155, -32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyTMD.io.model(\"/gdata1/data/tide_models\").from_file(\"/gdata1/data/tide_models/INATIDES/model_INATIDES.json\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTMD\n",
    "import pandas as pd\n",
    "from eo_tides.utils import _custom_model_definitions, list_models\n",
    "from eo_tides.model import model_tides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models, supported_models = list_models(\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    custom_models=[custom_dict],\n",
    "    show_supported=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_dict = {\n",
    "    \"format\": \"FES-netcdf\",\n",
    "    \"model_file\": [\n",
    "        \"EOT20/ocean_tides/2N2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/J1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/K1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/K2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/M2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/M4_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/MF_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/MM_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/N2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/O1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/P1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/Q1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/S1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/S2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/SA_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/SSA_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/T2_ocean_eot20.nc\"\n",
    "    ],\n",
    "    \"name\": \"EOT20_custom\",\n",
    "    \"reference\": \"https://doi.org/10.17882/79489\",\n",
    "    \"scale\": 0.01,\n",
    "    \"type\": \"z\",\n",
    "    \"variable\": \"tide_ocean\",\n",
    "    \"version\": \"EOT20\"\n",
    "}\n",
    "\n",
    "\n",
    "model_tides(\n",
    "    x=115.313154,\n",
    "    y=-8.668534,\n",
    "    time=pd.date_range(\"2022-01-01\", \"2022-01-31\", freq=\"1h\"),\n",
    "    model=\"EOT20_custom\",\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    custom_models=[custom_dict],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_tides(\n",
    "    x=115.313154,\n",
    "    y=-8.668534,\n",
    "    time=pd.date_range(\"2022-01-01\", \"2022-01-31\", freq=\"1h\"),\n",
    "    model=[\"INATIDES\", \"EOT20\", \"HAMTIDE11\"],\n",
    "    directory=\"/gdata1/data/tide_models\",\n",
    "    custom_models=[\"/gdata1/data/tide_models/INATIDES/model_INATIDES.json\"],\n",
    "    output_format=\"wide\",\n",
    "    parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test available tide models\n",
    "def test_list_models_custom():\n",
    "    # Verify that custom models are added to lists of\n",
    "    # available and supported models\n",
    "    available_models, supported_models = list_models(\n",
    "        directory=\"./tests/data/tide_models\", \n",
    "        custom_models=[\"./tests/data/model_EOT20custom.json\"],\n",
    "    )\n",
    "    assert \"EOT20_custom\" in available_models\n",
    "    assert \"EOT20_custom\" in supported_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new PyTMD version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "from eo_tides.validation import eval_metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"/var/share/tide_models/\"\n",
    "\n",
    "# Time the spline method\n",
    "modelled_tides_df = model_tides(\n",
    "   x=GAUGE_X,\n",
    "   y=GAUGE_Y,\n",
    "   time=measured_tides_ds.time,\n",
    "   model=\"all\",\n",
    "   directory=directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df.groupby(\"tide_model\").apply(lambda z: eval_metrics(x=measured_tides_ds.tide_height, y=z.tide_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df.groupby(\"tide_model\").apply(lambda z: eval_metrics(x=measured_tides_ds.tide_height, y=z.tide_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "from eo_tides.model import ensemble_tides\n",
    "\n",
    "# Set modelling location based on bbox centroid\n",
    "time = pd.date_range(start=\"2000-01\", end=\"2001-03\", freq=\"5h\")\n",
    "\n",
    "# Model using unclipped vs clipped files\n",
    "tide_df = model_tides(\n",
    "    x=GAUGE_X,\n",
    "    y=GAUGE_Y,\n",
    "    time=time,\n",
    "    model=\"all\",\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# tide_df[\"tide_height\"] = tide_df.tide_height.astype(\"float64\")\n",
    "# ensemble_df = ensemble_tides(tide_df, ensemble_models=[\"EOT20\", \"HAMTIDE11\"], crs=\"EPSG:4326\")\n",
    "\n",
    "# print(ensemble_df)\n",
    "# print(ensemble_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tide_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create data with a cross product approach\n",
    "data = pd.DataFrame({\n",
    "    'time': pd.date_range(start='2000-01-01', periods=5, freq='5h').repeat(2),\n",
    "    'x': 122.2183,\n",
    "    'y': -18.0008,\n",
    "    'tide_model': ['EOT20', 'HAMTIDE11'] * 5,\n",
    "    'tide_height': np.random.uniform(-4, 3, 10).astype(\"float32\")\n",
    "})\n",
    "\n",
    "# Set multi-index\n",
    "data = data.set_index(['time', 'x', 'y'])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import clip_models\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "# @pytest.mark.parametrize(\"bbox, name\", [\n",
    "#     ((-166, 14, -151, 29), \"hawaii\"),\n",
    "#     ((-123.530273, 36.949892, -121.376953, 38.479395), \"sanfran\"),\n",
    "#     ((-17.753906, -36.031332, 60.996094, 37.857507), \"africa\"),\n",
    "#     ((-13, 49, 6, 60), \"uk\"),\n",
    "#     ((105.292969, -47.872144, 160.312500, -5.266008), \"aus\"),\n",
    "#     ((-256.640625, 7.013668, -119.794922, 63.391522), \"pacific\"),\n",
    "# ])\n",
    "\n",
    "bbox, name = (105.292969, -47.872144, 160.312500, -5.266008), \"aus\"\n",
    "\n",
    "def test_clip_models_bboxes(bbox, name):\n",
    "\n",
    "    # Set input and output paths\n",
    "    in_dir = \"tests/data/tide_models_synthetic/\"\n",
    "    out_dir = f\"tests/data/tide_models_synthetic_{name}/\"\n",
    "\n",
    "    # Clip models to input bbox\n",
    "    clip_models(\n",
    "        input_directory=in_dir,\n",
    "        output_directory=out_dir,\n",
    "        bbox=bbox,\n",
    "        model=\"HAMTIDE11\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Set modelling location based on bbox centroid\n",
    "    x, y = odc.geo.geom.BoundingBox(*bbox, crs=\"EPSG:4326\").polygon.centroid.xy\n",
    "    time = pd.date_range(start=\"2000-01\", end=\"2001-03\", freq=\"5h\")\n",
    "\n",
    "    # Model using unclipped vs clipped files\n",
    "    df_unclipped = model_tides(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        time=time,\n",
    "        model=\"HAMTIDE11\",\n",
    "        directory=in_dir,\n",
    "        crop=False,\n",
    "    )\n",
    "    df_clipped = model_tides(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        time=time,\n",
    "        model=\"HAMTIDE11\",\n",
    "        directory=out_dir,\n",
    "        crop=False,\n",
    "    )\n",
    "\n",
    "    # Verify both produce the same results\n",
    "    assert np.allclose(df_unclipped.tide_height, df_clipped.tide_height)\n",
    "\n",
    "test_clip_models_bboxes(bbox, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add tide phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.eo import tag_tides\n",
    "import xarray as xr\n",
    "\n",
    "# Use tag_tides to model both phases and tide heights\n",
    "tagged_tides_ds = tag_tides(\n",
    "    satellite_ds,\n",
    "    return_phases=True,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Verify output is an xarray.Dataset\n",
    "assert isinstance(tagged_tides_ds, xr.Dataset)\n",
    "\n",
    "# Verify vars are as expected\n",
    "expected_vars = [\"tide_height\", \"tide_phase\"]\n",
    "assert set(expected_vars) == set(tagged_tides_ds.data_vars)\n",
    "\n",
    "# Verify tide_phase values\n",
    "expected_phases = [\"low-flow\", \"high-flow\", \"low-ebb\", \"low-flow\", \"low-ebb\", \"low-flow\", \"high-flow\"]\n",
    "assert tagged_tides_ds.tide_phase.values.tolist() == expected_phases\n",
    "\n",
    "# Assert tide_model dim has been squeezed out\n",
    "assert \"tide_model\" not in tagged_tides_ds.dims\n",
    "\n",
    "# Model two models at once\n",
    "tagged_tides_ds = tag_tides(\n",
    "    satellite_ds,\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    return_phases=True,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Assert that output now has a tide_model dimension\n",
    "assert \"tide_model\" in tagged_tides_ds.dims\n",
    "assert len(tagged_tides_ds[\"tide_model\"]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update `tide_stats`\n",
    "\n",
    "\n",
    "Aim: internal `_tide_statistics` function that takes a stack of input observed and modelled tides in _both_ pandas and xarray format, and returns statistics in corresponding format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "from eo_tides.stats import pixel_stats, tide_stats\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EOT20\", \"GOT5.5\"]\n",
    "\n",
    "# Calculate tidal stats\n",
    "tidal_stats_df = tide_stats(\n",
    "    satellite_ds,\n",
    "    model=models,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# assert isinstance(tidal_stats_df, pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds = pixel_stats(\n",
    "    satellite_ds,\n",
    "    model=models,\n",
    "    resample=False,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stats_ds.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./tests/data/tide_models\"\n",
    "\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "# Input params\n",
    "good_hamtide11 = -17.58549, 123.59414\n",
    "good_eot20 = -17.1611, 123.3406\n",
    "y = [good_eot20[0], good_hamtide11[0]]\n",
    "x = [good_eot20[1], good_hamtide11[1]]\n",
    "\n",
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]\n",
    "\n",
    "# times = pd.date_range(\"2020\", \"2021\", periods=2)\n",
    "\n",
    "# # Default, only ensemble requested\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=\"ensemble\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert all(modelled_tides_df.tide_model == \"ensemble\")\n",
    "\n",
    "# Default, ensemble + other models requested\n",
    "models = [\"EOT20\", \"HAMTIDE11\", \"ensemble\"]\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert set(modelled_tides_df.tide_model) == set(models)\n",
    "# assert np.allclose(\n",
    "#     modelled_tides_df.tide_height.values,\n",
    "#     [\n",
    "#         0.094,\n",
    "#         -3.202,\n",
    "#         0.409,\n",
    "#         -3.098,\n",
    "#         0.803,\n",
    "#         0.664,\n",
    "#         0.989,\n",
    "#         1.011,\n",
    "#         0.449,\n",
    "#         -1.269,\n",
    "#         0.699,\n",
    "#         -1.043,\n",
    "#     ],\n",
    "#     atol=0.02,\n",
    "# )\n",
    "\n",
    "# # One-to-one mode\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     mode=\"one-to-one\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert set(modelled_tides_df.tide_model) == set(models)\n",
    "\n",
    "# # Wide mode, default\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist, and that ensemble is approx average\n",
    "# # of other two models\n",
    "# assert set(modelled_tides_df.columns) == set(models)\n",
    "# assert np.allclose(\n",
    "#     0.5 * (modelled_tides_df.EOT20 + modelled_tides_df.HAMTIDE11),\n",
    "#     modelled_tides_df.ensemble,\n",
    "# )\n",
    "\n",
    "# # Wide mode, top n == 1\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     ensemble_top_n=1,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# Check that expected models exist, and that ensemble is equal to at\n",
    "# least one of the other models\n",
    "assert set(modelled_tides_df.columns) == set(models)\n",
    "assert all(\n",
    "    (modelled_tides_df.EOT20 == modelled_tides_df.ensemble)\n",
    "    | (modelled_tides_df.HAMTIDE11 == modelled_tides_df.ensemble)\n",
    ")\n",
    "\n",
    "# Check that correct model is the closest at each row\n",
    "closer_model = modelled_tides_df.apply(\n",
    "    lambda row: (\n",
    "        \"EOT20\" if abs(row[\"ensemble\"] - row[\"EOT20\"]) < abs(row[\"ensemble\"] - row[\"HAMTIDE11\"]) else \"HAMTIDE11\"\n",
    "    ),\n",
    "    axis=1,\n",
    ").tolist()\n",
    "assert closer_model == [\"EOT20\", \"HAMTIDE11\", \"EOT20\", \"HAMTIDE11\"]\n",
    "\n",
    "# # Check values are expected\n",
    "# assert np.allclose(modelled_tides_df.ensemble, [0.09, 0.98, -3.20, 1.01], atol=0.02)\n",
    "\n",
    "# # Wide mode, custom functions\n",
    "# ensemble_funcs = {\n",
    "#     \"ensemble-best\": lambda x: x[\"rank\"] == 1,\n",
    "#     \"ensemble-worst\": lambda x: x[\"rank\"] == 2,\n",
    "#     \"ensemble-mean-top2\": lambda x: x[\"rank\"].isin([1, 2]),\n",
    "#     \"ensemble-mean-weighted\": lambda x: 3 - x[\"rank\"],\n",
    "#     \"ensemble-mean\": lambda x: x[\"rank\"] <= 2,\n",
    "# }\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     ensemble_func=ensemble_funcs,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist, and that valid data is produced\n",
    "# assert set(modelled_tides_df.columns) == set([\n",
    "#     \"EOT20\",\n",
    "#     \"HAMTIDE11\",\n",
    "#     \"ensemble-best\",\n",
    "#     \"ensemble-worst\",\n",
    "#     \"ensemble-mean-top2\",\n",
    "#     \"ensemble-mean-weighted\",\n",
    "#     \"ensemble-mean\",\n",
    "# ])\n",
    "# assert all(modelled_tides_df.notnull())\n",
    "\n",
    "# # Long mode, custom functions\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"long\",\n",
    "#     ensemble_func=ensemble_funcs,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist in \"tide_model\" column\n",
    "# assert set(modelled_tides_df.tide_model) == set([\n",
    "#     \"EOT20\",\n",
    "#     \"HAMTIDE11\",\n",
    "#     \"ensemble-best\",\n",
    "#     \"ensemble-worst\",\n",
    "#     \"ensemble-mean-top2\",\n",
    "#     \"ensemble-mean-weighted\",\n",
    "#     \"ensemble-mean\",\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]\n",
    "ensemble_models = ENSEMBLE_MODELS\n",
    "\n",
    "x = tide_df.index.get_level_values(level=\"x\")\n",
    "y = tide_df.index.get_level_values(level=\"y\")\n",
    "model_ranking_cols = [f\"rank_{m}\" for m in ensemble_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranks_gdf.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "ranking_points=\"https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/derivative/dea_intertidal/supplementary/rankings_ensemble_2017-2019.fgb\"\n",
    "crs = \"EPSG:4326\"\n",
    "ranking_valid_perc=0.02\n",
    "\n",
    "try:\n",
    "    model_ranks_gdf = (\n",
    "        gpd.read_file(ranking_points, engine=\"pyogrio\")\n",
    "        .to_crs(crs)\n",
    "        .query(f\"valid_perc > {ranking_valid_perc}\")\n",
    "        .dropna(how=\"all\")[model_ranking_cols + [\"geometry\"]]\n",
    "    )\n",
    "except KeyError:\n",
    "    error_msg = f\"\"\"\n",
    "    Not all of the expected \"rank_\" columns {model_ranking_cols} were\n",
    "    found in the columns of the ranking points file ({ranking_points}).\n",
    "    Consider passing a custom list of models using `ensemble_models`.\n",
    "    \"\"\"\n",
    "    raise Exception(textwrap.dedent(error_msg).strip()) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import idw\n",
    "\n",
    "idw_kwargs = {}\n",
    "\n",
    "# Use points to interpolate model rankings into requested x and y\n",
    "id_kwargs_str = \"\" if idw_kwargs == {} else idw_kwargs\n",
    "print(f\"Interpolating model rankings using IDW interpolation {id_kwargs_str}\")\n",
    "ensemble_ranks_df = (\n",
    "    # Run IDW interpolation on subset of ranking columns\n",
    "    pd.DataFrame(\n",
    "        idw(\n",
    "            input_z=model_ranks_gdf[model_ranking_cols],\n",
    "            input_x=model_ranks_gdf.geometry.x,\n",
    "            input_y=model_ranks_gdf.geometry.y,\n",
    "            output_x=x,\n",
    "            output_y=y,\n",
    "            **idw_kwargs,\n",
    "        ),\n",
    "        columns=model_ranking_cols,\n",
    "    )\n",
    "    .assign(x=x, y=y)\n",
    "    # Drop any duplicates then melt columns into long format\n",
    "    .drop_duplicates()\n",
    "    .melt(id_vars=[\"x\", \"y\"], var_name=\"tide_model\", value_name=\"rank\")\n",
    "    # Remove \"rank_\" prefix to get plain model names\n",
    "    .replace({\"^rank_\": \"\"}, regex=True)\n",
    "    # Set index columns and rank across groups\n",
    "    .set_index([\"tide_model\", \"x\", \"y\"])\n",
    "    .groupby([\"x\", \"y\"])\n",
    "    .rank()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranks_gdf[model_ranking_cols].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_ranks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "df = model_tides(x= 123.73412090186251, \n",
    "            y=-16.997767837915056, \n",
    "            model=\"ensemble\",\n",
    "            time=pd.date_range(start=\"2000\", end=\"2001\", freq=\"5h\"),\n",
    "            ranking_points=\"/home/jovyan/Robbi/dea-intertidal/data/raw/tide_correlation_points_test.geojson\",\n",
    "            k=5,\n",
    "            output_format=\"wide\",\n",
    "            directory=\"/var/share/tide_models/\")\n",
    "\n",
    "with pd.option_context('display.max_rows', 5, 'display.max_columns', None): \n",
    "    display(df)\n",
    "\n",
    "# u, c = np.unique(a, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "df = model_tides(\n",
    "    x=145.372051,\n",
    "    y=-38.260667,\n",
    "    model=[\n",
    "        \"EOT20\",\n",
    "        \"FES2012\",\n",
    "        \"FES2014_extrapolated\",\n",
    "        \"FES2022_extrapolated\",\n",
    "        \"HAMTIDE11\",\n",
    "        \"GOT4.10\",\n",
    "        \"GOT5.6_extrapolated\",\n",
    "        \"TPXO10-atlas-v2-nc\",\n",
    "        \"TPXO8-atlas-nc\",\n",
    "        \"TPXO9-atlas-v5-nc\",\n",
    "        \"ensemble\",\n",
    "    ],\n",
    "    time=pd.date_range(start=\"2018-01-01\", end=\"2020-12-31\", freq=\"1h\"),\n",
    "    output_format=\"wide\",\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    ensemble_models=[\n",
    "        \"EOT20\",\n",
    "        \"FES2012\",\n",
    "        \"FES2014_extrapolated\",\n",
    "        \"FES2022_extrapolated\",\n",
    "        # \"HAMTIDE11\",\n",
    "        # \"GOT4.10\",\n",
    "        \"GOT5.6_extrapolated\",\n",
    "        \"TPXO10-atlas-v2-nc\",\n",
    "        # \"TPXO8-atlas-nc\",\n",
    "        \"TPXO9-atlas-v5-nc\",\n",
    "    ]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.droplevel([\"x\", \"y\"]).head(50).drop(\"ensemble\", axis=1).plot(linewidth=0.8, figsize=(10, 6))\n",
    "df.droplevel([\"x\", \"y\"]).head(50).ensemble.plot(linewidth=3, c=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.droplevel([\"x\", \"y\"]).head(50).drop(\"ensemble\", axis=1).plot(linewidth=0.8, figsize=(10, 6))\n",
    "df.droplevel([\"x\", \"y\"]).head(50).ensemble.plot(linewidth=3, c=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_standardise_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import _set_directory, list_models\n",
    "\n",
    "directory = \"/home/jovyan/Robbi/eo-tides/tests/data/tide_models/\"\n",
    "directory = _set_directory(directory)\n",
    "\n",
    "\n",
    "# def _standardise_models(model, directory, ensemble_models=None):\n",
    "\n",
    "#     # Turn inputs into arrays for consistent handling\n",
    "#     models_requested = list(np.atleast_1d(model))\n",
    "\n",
    "#     # Get full list of supported models from pyTMD database\n",
    "#     available_models, valid_models = list_models(\n",
    "#         directory, show_available=False, show_supported=False, raise_error=True\n",
    "#     )\n",
    "#     custom_options = [\"ensemble\", \"all\"]\n",
    "\n",
    "#     # Error if any models are not supported\n",
    "#     if not all(m in valid_models + custom_options for m in models_requested):\n",
    "#         error_text = (\n",
    "#             f\"One or more of the requested models are not valid:\\n\"\n",
    "#             f\"{models_requested}\\n\\n\"\n",
    "#             \"The following models are supported:\\n\"\n",
    "#             f\"{valid_models}\"\n",
    "#         )\n",
    "#         raise ValueError(error_text)\n",
    "\n",
    "#     # Error if any models are not available in `directory`\n",
    "#     if not all(m in available_models + custom_options for m in models_requested):\n",
    "#         error_text = (\n",
    "#             f\"One or more of the requested models are valid, but not available in `{directory}`:\\n\"\n",
    "#             f\"{models_requested}\\n\\n\"\n",
    "#             f\"The following models are available in `{directory}`:\\n\"\n",
    "#             f\"{available_models}\"\n",
    "#         )\n",
    "#         raise ValueError(error_text)\n",
    "\n",
    "#     # If \"all\" models are requested, update requested list to include available models\n",
    "#     if \"all\" in models_requested:\n",
    "#         models_requested = available_models + [\n",
    "#             m for m in models_requested if m != \"all\"\n",
    "#         ]\n",
    "\n",
    "#     # If \"ensemble\" modeling is requested, use custom list of ensemble models\n",
    "#     if \"ensemble\" in models_requested:\n",
    "#         print(\"Running ensemble tide modelling\")\n",
    "#         ensemble_models = (\n",
    "#             ensemble_models\n",
    "#             if ensemble_models is not None\n",
    "#             else [\n",
    "#                 \"FES2014\",\n",
    "#                 \"TPXO9-atlas-v5\",\n",
    "#                 \"EOT20\",\n",
    "#                 \"HAMTIDE11\",\n",
    "#                 \"GOT4.10\",\n",
    "#                 \"FES2012\",\n",
    "#                 \"TPXO8-atlas-v1\",\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         # Error if any ensemble models are not available in `directory`\n",
    "#         if not all(m in available_models for m in ensemble_models):\n",
    "#             error_text = (\n",
    "#                 f\"One or more of the requested ensemble models are not available in `{directory}`:\\n\"\n",
    "#                 f\"{ensemble_models}\\n\\n\"\n",
    "#                 f\"The following models are available in `{directory}`:\\n\"\n",
    "#                 f\"{available_models}\"\n",
    "#             )\n",
    "#             raise ValueError(error_text)\n",
    "\n",
    "#         # Return set of all ensemble plus any other requested models\n",
    "#         models_to_process = ensemble_models + [\n",
    "#             m for m in models_requested if m != \"ensemble\"\n",
    "#         ]\n",
    "\n",
    "#     # Otherwise, models to process are the same as those requested\n",
    "#     else:\n",
    "#         models_to_process = models_requested\n",
    "\n",
    "#     # Remove duplicates\n",
    "#     models_to_process = list(set(models_to_process))\n",
    "#     models_requested = list(set(models_requested))\n",
    "\n",
    "#     return models_to_process, models_requested, ensemble_models\n",
    "\n",
    "\n",
    "# model = \"EOT20\"\n",
    "# # model = [\"EOT20\", \"HAMTIDE11\"]  # = [\"EOT20\", \"FES2014\"]\n",
    "# # model = \"all\"  # = [list all available]\n",
    "# # model = \"ensemble\" # = [list all ensemble]\n",
    "# # model = [\"ensemble\", \"GOT5.5\"]  # = [list all ensemble]\n",
    "# # model = [\"all\", \"ensemble\"]\n",
    "\n",
    "\n",
    "from eo_tides.utils import _standardise_models\n",
    "\n",
    "\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    "    [\"EOT20\"],\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"EOT20\",\n",
    "    None,\n",
    "    [\"EOT20\"],\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"all\",\n",
    "    None,\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"all\"],\n",
    "    None,\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"ensemble\",\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"ensemble\", \"GOT5.5\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"],\n",
    "    [\"GOT5.5\", \"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "# model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "#     [\"all\", \"ensemble\"],\n",
    "#     [\"EOT20\", \"HAMTIDE11\"],\n",
    "#     [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"],\n",
    "#     [\"GOT5.5\", \"HAMTIDE11\", \"ensemble\", \"EOT20\"],\n",
    "#     [\"EOT20\", \"HAMTIDE11\"],\n",
    "# )\n",
    "\n",
    "\n",
    "models_to_process, models_requested, ensemble_models = _standardise_models(\n",
    "    model=model,\n",
    "    directory=directory,\n",
    "    ensemble_models=ensemble_models,\n",
    ")\n",
    "\n",
    "print(\"Models to process: \", models_to_process)\n",
    "print(\"Models requested: \", models_requested)\n",
    "print(\"Ensemble models: \", ensemble_models)\n",
    "\n",
    "assert models_to_process == exp_process\n",
    "assert models_requested == exp_request\n",
    "assert ensemble_models == exp_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(models_requested + ensemble_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models\n",
    "\n",
    "models_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate interpolation functions\n",
    "\n",
    "crop=True, bounds=None: \n",
    "crop=False, bounds=None:\n",
    "crop=True, bounds="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "x=np.linspace(122.2183, 122.219, 10)\n",
    "y=np.linspace(-18.0008, -18.01, 10)\n",
    "time=pd.date_range(\"2020\", \"2021\", periods=10)\n",
    "crs=\"EPSG:4326\"\n",
    "method=\"spline\"\n",
    "model=\"FES2022\"\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        delta_time=time,\n",
    "        DIRECTORY=\"/gdata1/data/tide_models/\",\n",
    "        MODEL=model,\n",
    "        EPSG=int(crs[-4:]),\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=method,\n",
    "        CROP=True,\n",
    "        # CROP=False,\n",
    "        # BOUNDS=bounds,\n",
    "        )\n",
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"spline\", CROP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"linear\", CROP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"spline\", CROP=True, BOUNDS=[121.218, 123.218, -19.000, -17.000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function, annotations\n",
    "\n",
    "import logging\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from io import IOBase\n",
    "import scipy.interpolate\n",
    "import pyTMD.crs\n",
    "import pyTMD.io\n",
    "import pyTMD.io.model\n",
    "import pyTMD.predict\n",
    "import pyTMD.spatial\n",
    "import pyTMD.utilities\n",
    "import timescale.eop\n",
    "import timescale.time\n",
    "# attempt imports\n",
    "pyproj = pyTMD.utilities.import_dependency('pyproj')\n",
    "\n",
    "\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "x=x\n",
    "y=y\n",
    "delta_time=measured_tides_ds.time\n",
    "DIRECTORY=\"/var/share/tide_models/\"\n",
    "MODEL=model\n",
    "EPSG=int(crs[-4:])\n",
    "TIME=\"datetime\"\n",
    "EXTRAPOLATE=True\n",
    "CUTOFF=np.inf\n",
    "CROP=True\n",
    "METHOD=method\n",
    "\n",
    "GZIP=False\n",
    "DEFINITION_FILE=None\n",
    "BOUNDS=None\n",
    "EPOCH=(2000, 1, 1, 0, 0, 0)\n",
    "TYPE='drift'\n",
    "CORRECTIONS = None\n",
    "INFER_MINOR = True\n",
    "MINOR_CONSTITUENTS = None\n",
    "APPEND_NODE = False\n",
    "APPLY_FLEXURE= False\n",
    "FILL_VALUE=np.nan\n",
    "\n",
    "\n",
    "\n",
    "# check that tide directory is accessible\n",
    "if DIRECTORY is not None:\n",
    "    DIRECTORY = pathlib.Path(DIRECTORY).expanduser()\n",
    "    if not DIRECTORY.exists():\n",
    "        raise FileNotFoundError(\"Invalid tide directory\")\n",
    "\n",
    "# validate input arguments\n",
    "assert TIME.lower() in ('gps', 'loran', 'tai', 'utc', 'datetime')\n",
    "assert METHOD.lower() in ('bilinear', 'spline', 'linear', 'nearest')\n",
    "\n",
    "# get parameters for tide model\n",
    "if DEFINITION_FILE is not None:\n",
    "    model = pyTMD.io.model(DIRECTORY).from_file(DEFINITION_FILE)\n",
    "else:\n",
    "    model = pyTMD.io.model(DIRECTORY, compressed=GZIP).elevation(MODEL)\n",
    "\n",
    "# determine input data type based on variable dimensions\n",
    "if not TYPE:\n",
    "    TYPE = pyTMD.spatial.data_type(x, y, delta_time)\n",
    "assert TYPE.lower() in ('grid', 'drift', 'time series')\n",
    "# reform coordinate dimensions for input grids\n",
    "# or verify coordinate dimension shapes\n",
    "if (TYPE.lower() == 'grid') and (np.size(x) != np.size(y)):\n",
    "    x,y = np.meshgrid(np.copy(x),np.copy(y))\n",
    "elif (TYPE.lower() == 'grid'):\n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "elif TYPE.lower() in ('time series', 'drift'):\n",
    "    x = np.atleast_1d(x)\n",
    "    y = np.atleast_1d(y)\n",
    "\n",
    "# converting x,y from EPSG to latitude/longitude\n",
    "crs1 = pyTMD.crs().from_input(EPSG)\n",
    "crs2 = pyproj.CRS.from_epsg(4326)\n",
    "transformer = pyproj.Transformer.from_crs(crs1, crs2, always_xy=True)\n",
    "lon, lat = transformer.transform(x.flatten(), y.flatten())\n",
    "\n",
    "# verify that delta time is an array\n",
    "delta_time = np.atleast_1d(delta_time)\n",
    "# convert delta times or datetimes objects to timescale\n",
    "if (TIME.lower() == 'datetime'):\n",
    "    ts = timescale.time.Timescale().from_datetime(\n",
    "        delta_time.flatten())\n",
    "else:\n",
    "    ts = timescale.time.Timescale().from_deltatime(delta_time,\n",
    "        epoch=EPOCH, standard=TIME)\n",
    "# number of time points\n",
    "nt = len(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tidal constants and interpolate to grid points\n",
    "amp, ph, c = model.extract_constants(lon, lat, type=model.type,\n",
    "    crop=CROP, bounds=BOUNDS, method=METHOD,\n",
    "    extrapolate=EXTRAPOLATE, cutoff=CUTOFF,\n",
    "    append_node=APPEND_NODE, apply_flexure=APPLY_FLEXURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust dimensions of input coordinates to be iterable\n",
    "ilon = np.atleast_1d(np.copy(lon))\n",
    "ilat = np.atleast_1d(np.copy(lat))\n",
    "# set default bounds if cropping\n",
    "xmin, xmax = np.min(ilon), np.max(ilon)\n",
    "ymin, ymax = np.min(ilat), np.max(ilat)\n",
    "bounds=[xmin-1, xmax+1, ymin-1, ymax+1]\n",
    "\n",
    "\n",
    "# read tidal constants and interpolate to grid points\n",
    "c = model.read_constants(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.read_constants(crop=False, bounds=bounds)\n",
    "plt.imshow(c.m2.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.read_constants(crop=True, bounds=bounds)\n",
    "plt.imshow(c.m2.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c.m2.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate complex phase in radians for Euler's\n",
    "cph = -1j*ph*np.pi/180.0\n",
    "# calculate constituent oscillation\n",
    "hc = amp*np.exp(cph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "n = 2000\n",
    "x = np.random.uniform(112.715430, 154.727149, n)\n",
    "y = np.random.uniform(-44.199061, -10.035282, n)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "model = \"FES2014\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models/\"\n",
    "\n",
    "# Time the spline method\n",
    "start_time = time.time()\n",
    "modelled_tides_df_spline = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"spline\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=False, \n",
    ")\n",
    "spline_time = time.time() - start_time\n",
    "\n",
    "# Time the linear method  \n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"linear\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=False,\n",
    ")\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "print(f\"Spline method time: {spline_time:.6f} seconds\")\n",
    "print(f\"Linear method time: {linear_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "n = 2000\n",
    "x = np.random.uniform(112.715430, 154.727149, n)\n",
    "y = np.random.uniform(-44.199061, -10.035282, n)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "model = \"FES2014\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models/\"\n",
    "\n",
    "# # Time the spline method\n",
    "# start_time = time.time()\n",
    "# modelled_tides_df_spline = model_tides(\n",
    "#    x=x,\n",
    "#    y=y,\n",
    "#    time=times,\n",
    "#    model=model,\n",
    "#    method=\"spline\",\n",
    "#    directory=directory,\n",
    "#    parallel=False,\n",
    "#    crop=True, \n",
    "# )\n",
    "# spline_time = time.time() - start_time\n",
    "\n",
    "# Time the linear method  \n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"linear\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=True,\n",
    ")\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "# print(f\"Spline method time: {spline_time:.6f} seconds\")\n",
    "print(f\"Linear method time: {linear_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "x = np.random.uniform(112.715430, 154.727149, 100000)\n",
    "y = np.random.uniform(-44.199061, -10.035282, 100000)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "# model = \"EOT20\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models_clipped/\"\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for model in [[\"EOT20\", \"GOT5.5\"], \"EOT20\"]:\n",
    "\n",
    "    for n in [100, 1000, 10000, 100000]:\n",
    "    \n",
    "        # Select a subset of x and y\n",
    "        x_sub = x[0:n]\n",
    "        y_sub = y[0:n]\n",
    "    \n",
    "        for parallel_max in [2, 4, 8, 16]:\n",
    "        \n",
    "            for parallel_split in [1, 2, 3, 4, 5, 6, 8, 10, 12, 16, 20]:\n",
    "        \n",
    "                # Time the linear method\n",
    "                start_time = time.time()\n",
    "                modelled_tides_df_linear = model_tides(\n",
    "                    x=x_sub,\n",
    "                    y=y_sub,\n",
    "                    time=times,\n",
    "                    model=model,\n",
    "                    method=\"linear\",\n",
    "                    directory=directory,\n",
    "                    parallel=True,\n",
    "                    parallel_splits=parallel_split,\n",
    "                    parallel_max=parallel_max,\n",
    "                    crop=True,\n",
    "                )\n",
    "                split_time = time.time() - start_time\n",
    "        \n",
    "                output_dict = {\n",
    "                    \"split\": parallel_split,\n",
    "                    \"parallel_max\": parallel_max,\n",
    "                    \"time\": split_time,\n",
    "                    \"points\": n,\n",
    "                    \"points_per_split\": int(n / parallel_split),\n",
    "                    \"split_per_parallel\": parallel_split / parallel_max,\n",
    "                    \"directory\": directory,\n",
    "                    \"model\": model,\n",
    "                }\n",
    "                output_list.append(output_dict)\n",
    "                print(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and export\n",
    "data = pd.DataFrame(output_list)\n",
    "data[\"time_per_point\"] = data[\"time\"] / data[\"points\"]\n",
    "data[\"model_multiple\"] = data[\"model\"].apply(lambda x: x == ['EOT20', 'GOT5.5'])\n",
    "data.to_csv(\"test_timings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"test_timings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='points_per_split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[1], linewidth=3)\n",
    "lineplot.invert_xaxis()\n",
    "axes[1].set_title('Time by Points per split')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model_multiple\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='points_per_split', y='time', hue='parallel_max', data=data.query(\"model_multiple\"), ax=axes[1], linewidth=3)\n",
    "lineplot.invert_xaxis()\n",
    "axes[1].set_title('Time by Points per split')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"split_per_parallel\"] = data[\"split\"] / data[\"parallel_max\"]\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='split_per_parallel', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[1], linewidth=3)\n",
    "axes[1].set_title('Time by Splits per parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"model == 'EOT20'\").query(\"parallel_max == 2\").query(\"points == 10000\").set_index(\"points_per_split\").time_per_point.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parallel_max = 16\n",
    "parallel_split=\"auto\"\n",
    "\n",
    "n = 200000\n",
    "models = [\"EOT20\"]  # [\"EOT20\", \"GOT5.5\"]\n",
    "# models = [\"EOT20\", \"GOT5.5\"]\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.process_cpu_count()\n",
    "\n",
    "parallel_split = int(max(1, min(n / 1000, parallel_max) / len(models)))\n",
    "print(parallel_split, n/parallel_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parallel_splits(\n",
    "    total_points,\n",
    "    model_count,\n",
    "    parallel_max=None,\n",
    "    min_points_per_split=1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the optimal number of parallel splits for data\n",
    "    processing based on system resources and processing constraints.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    total_points : int\n",
    "        Total number of data points to process\n",
    "    model_count : int\n",
    "        Number of models that will be run in parallel\n",
    "    parallel_max : int, optional\n",
    "        Maximum number of parallel processes to use. If None, uses CPU core count\n",
    "    min_points_per_split : int, default=1000\n",
    "        Minimum number of points that should be processed in each split\n",
    "    \"\"\"\n",
    "    # Available CPUs\n",
    "    if parallel_max is None:\n",
    "        try:\n",
    "            import psutil\n",
    "\n",
    "            parallel_max = psutil.cpu_count(logical=False)\n",
    "        except ImportError:\n",
    "            parallel_max = os.cpu_count()\n",
    "\n",
    "    # Calculate optimal number of splits based on constraints\n",
    "    splits_by_size = total_points / min_points_per_split\n",
    "    splits_by_cpu = parallel_max / model_count\n",
    "    optimal_splits = min(splits_by_size, splits_by_cpu)\n",
    "\n",
    "    # Convert to integer and ensure at least 1 split\n",
    "    final_split_count = int(max(1, optimal_splits))\n",
    "    return final_split_count\n",
    "\n",
    "\n",
    "_parallel_splits(total_points=1, model_count=1, parallel_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(10.6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count(affinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.cpu_count()\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=None) as executor:\n",
    "    executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "n = 10000\n",
    "directory = \"/gdata1/data/tide_models_clipped/\"\n",
    "directory = \"./tests/data/tide_models/\"\n",
    "# models = [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"]\n",
    "models = [\"EOT20\"]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "    x = np.random.uniform(112.715430, 154.727149, n),\n",
    "    y = np.random.uniform(-44.199061, -10.035282, n),\n",
    "    time = pd.date_range(\"2020\", \"2021\", periods=100),\n",
    "    model=models,\n",
    "    method=\"linear\",\n",
    "    directory=directory,\n",
    "    parallel=True,\n",
    "    parallel_splits=\"auto\",\n",
    "    parallel_max=16,\n",
    "    crop=False,\n",
    ")\n",
    "split_time = time.time() - start_time\n",
    "print(split_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 10000\n",
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (~model_multiple)\").style.background_gradient(cmap=\"YlOrRd\", subset=\"time_per_point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pivot(columns=\"model_multiple\", values=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (model_multiple)\").time.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (~model_multiple)\").time.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(modelled_tides_df_spline.droplevel([\"x\", \"y\"]).tide_height, modelled_tides_df_linear.droplevel([\"x\", \"y\"]).tide_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run equivalent pyTMD code to verify same results\n",
    "# pytmd_tides_spline = tide_elevations(\n",
    "#         x=np.repeat(149.722622, len(measured_tides_ds.time)), \n",
    "#         y=np.repeat(-22.132984, len(measured_tides_ds.time)), \n",
    "#         delta_time=measured_tides_ds.time,\n",
    "#         DIRECTORY=\"/var/share/tide_models/\",\n",
    "#         MODEL=\"FES2012\",\n",
    "#         EPSG=4326,\n",
    "#         TIME=\"datetime\",\n",
    "#         EXTRAPOLATE=True,\n",
    "#         CUTOFF=np.inf,\n",
    "#         METHOD=\"spline\",\n",
    "#         CROP=True,\n",
    "#         # BOUNDS=[148.722622, 149.722622, -22.132984, -23.132984],\n",
    "#         )\n",
    "\n",
    "pytmd_tides_linear = tide_elevations(\n",
    "        x=np.repeat(149.722622, len(measured_tides_ds.time)), \n",
    "        y=np.repeat(-22.132984, len(measured_tides_ds.time)), \n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"/var/share/tide_models/\",\n",
    "        MODEL=\"TPXO9-atlas-v5-nc\",\n",
    "        EPSG=4326,\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=\"linear\",\n",
    "        CROP=True,\n",
    "        # BOUNDS=[140.002622, 149.722622, -23.132984, -22.132984],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(pytmd_tides_spline.data, pytmd_tides_linear.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_df = phase_tides(\n",
    "    x=[122.14],\n",
    "    y=[-17.91],\n",
    "    time=pd.date_range(\"2020-01-01\", \"2020-01-02\", freq=\"h\"),\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    model=[\"EOT20\"],\n",
    "    delta = \"15 min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.date_range(start=\"2000-01-01\", end=\"2000-01-02\", periods=3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pyTMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"spline\", \"EOT20\"\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\"\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "\n",
    "# # Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    time=measured_tides_ds.time,\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    "    # crop=False,\n",
    ")\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"./tests/data/tide_models\",\n",
    "        MODEL=model,\n",
    "        EPSG=int(crs[-4:]),\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=method,\n",
    "        # CORRECTIONS: str | None = None,\n",
    "        # INFER_MINOR: bool = True,\n",
    "        # MINOR_CONSTITUENTS: list | None = None,\n",
    "        # APPLY_FLEXURE: bool = False,\n",
    "        # FILL_VALUE: float = np.nan\n",
    "        # APPEND_NODE=True,\n",
    "        )\n",
    "\n",
    "np.allclose(modelled_tides_df.tide_height.values, pytmd_tides.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"spline\", \"EOT20\"\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\"\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "\n",
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=\"FES2014\",\n",
    "    time=pd.date_range(\"1980\", \"2020\", freq=\"9h\"),\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"/var/share/tide_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df2 = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=\"FES2014\",\n",
    "    time=pd.date_range(\"1980\", \"2020\", freq=\"9h\"),\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"/var/share/tide_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df.tide_height.plot(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df2.tide_height - modelled_tides_df.tide_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error for out of bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y = 180, -50\n",
    "\n",
    "\n",
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    time=measured_tides_ds.time,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import list_models\n",
    "list_models(directory=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stats import pixel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EOT20\"]\n",
    "resample = False\n",
    "\n",
    "stats_ds = pixel_stats(\n",
    "    ds=satellite_ds,\n",
    "    model=models,\n",
    "    resample=resample,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling ebb and flow tidal phases\n",
    "The `tag_tides` function also allows us to determine whether each satellite observation was taken while the tide was rising/incoming (flow tide) or falling/outgoing (ebb tide) by setting `ebb_flow=True`. This is achieved by comparing tide heights 15 minutes before and after the observed satellite observation.\n",
    "\n",
    "Ebb and flow data can provide valuable contextual information for interpreting satellite imagery, particularly in tidal flat or mangrove forest environments where water may remain in the landscape for considerable time after the tidal peak.\n",
    "\n",
    "Once you run the cell below, our data will now also contain a new `ebb_flow` variable under **Data variables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "ds = dc.load(product=\"ga_s2ls_intertidal_cyear_3\", limit=1, measurements=\"elevation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.geo.geobox import GeoBox\n",
    "import xarray as xr\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def _standardise_time(\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Accept a datetime64 ndarray, pandas.DatetimeIndex\n",
    "    or pandas.Timestamp, and return a datetime64 ndarray.\n",
    "    \"\"\"\n",
    "    # Return time as-is if none\n",
    "    if time is None:\n",
    "        return time\n",
    "\n",
    "    # Convert to a 1D datetime64 array\n",
    "    time = np.atleast_1d(time).astype(\"datetime64[ns]\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "def _standardise_inputs(\n",
    "    ds: xr.DataArray | xr.Dataset | GeoBox,\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> (GeoBox, np.ndarray):\n",
    "    \"\"\"\n",
    "    Takes an xarray or GeoBox input and an optional custom times,\n",
    "    and returns a standardised GeoBox and  \n",
    "    \"\"\"\n",
    "\n",
    "    # If `ds` is an xarray object, extract its GeoBox and time\n",
    "    if isinstance(ds, (xr.DataArray, xr.Dataset)):\n",
    "\n",
    "        # Try to extract GeoBox\n",
    "        try:\n",
    "            gbox = ds.odc.geobox\n",
    "        except AttributeError:\n",
    "            error_msg = \"\"\"\n",
    "            Cannot extract a valid GeoBox for `ds`. This is required for\n",
    "            extracting details about `ds`'s CRS and spatial location.\n",
    "            \n",
    "            Import `odc.geo.xr` then run `ds = ds.odc.assign_crs(crs=...)`\n",
    "            to prepare your data before passing it to this function.\n",
    "            \"\"\"\n",
    "            raise Exception(textwrap.dedent(error_msg).strip())\n",
    "\n",
    "        # Use custom time by default if provided; otherwise try and extract from `ds`\n",
    "        if time is not None:\n",
    "            time = _standardise_time(time)\n",
    "        elif \"time\" in ds.coords:\n",
    "            time = ds.coords[\"time\"].values\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`ds` does not have a time dimension, and no custom times were provided via `time`.\"\n",
    "            )\n",
    "\n",
    "    # If `ds` is a GeoBox, use it directly; raise an error if no time was provided\n",
    "    elif isinstance(ds, GeoBox):\n",
    "        gbox = ds\n",
    "        if time is not None:\n",
    "            time = _standardise_time(time)\n",
    "        else:\n",
    "            raise ValueError(\"If `ds` is a GeoBox, `time` must be provided.\")\n",
    "\n",
    "    # Raise error if no valid inputs were provided\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"`ds` must be an xarray.DataArray, xarray.Dataset, or odc.geo.geobox.GeoBox.\"\n",
    "        )\n",
    "\n",
    "    return gbox, time\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "time = pd.date_range(\"2021\", \"2022\")\n",
    "time = pd.Timestamp(\"2022-02-01\")\n",
    "# time = satellite_ds.time\n",
    "# time = [\"a\", \"b\"]\n",
    "\n",
    "\n",
    "gbox, time = _standardise_inputs(ds=ds.drop_dims(\"time\").odc.geobox, time=time)\n",
    "gbox, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds.chunks[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "# time = pd.date_range(\"2021\", \"2022\")\n",
    "# time = pd.Timestamp(\"2022-02-01\")\n",
    "time = satellite_ds.time\n",
    "\n",
    "\n",
    "def _standardise_time(\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Accept a datetime64 ndarray, pandas.DatetimeIndex\n",
    "    or pandas.Timestamp, and return a datetime64 ndarray.\n",
    "    \"\"\"\n",
    "    # Return time as-is if none\n",
    "    if time is None:\n",
    "        return time\n",
    "\n",
    "    # Convert to a 1D datetime64 array\n",
    "    time = np.atleast_1d(time).astype(\"datetime64[ns]\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "# time = pd.date_range(\"2021\", \"2022\")\n",
    "# time = pd.Timestamp(\"2022-02-01\")\n",
    "# time = satellite_ds.time\n",
    "# time = [pd.Timestamp(\"2022-02-01\"), pd.Timestamp(\"2022-02-01\")]\n",
    "# time = None\n",
    "_standardise_time(time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.atleast_1d(time).astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.odc.assign_crs(\"EPSG:3577\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = satellite_ds.nbart_red.drop_attrs(deep=True).drop_vars(\"spatial_ref\").odc.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  #odc.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tide heights\n",
    "ds = tag_tides(\n",
    "    ds, \n",
    "    ebb_flow=True,     \n",
    "    directory=\"../../tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Print output data\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have data giving us the both the tide height and tidal phase (\"ebb\" or \"flow\") for every satellite image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[[\"time\", \"tide_height\", \"ebb_flow\"]].drop_vars(\"spatial_ref\").to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could for example use this data to filter our observations to keep ebbing phase observations only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ebb = ds.where(ds.ebb_flow == \"Ebb\", drop=True)\n",
    "print(ds_ebb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odc.stac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "# Connect to STAC catalog\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "# Set cloud access defaults\n",
    "odc.stac.configure_rio(\n",
    "    cloud_defaults=True,\n",
    "    aws={\"aws_unsigned\": True},\n",
    ")\n",
    "\n",
    "# Build a query and search the STAC catalog for all matching items\n",
    "bbox = [122.160, -18.05, 122.260, -17.95]\n",
    "query = catalog.search(\n",
    "    bbox=bbox,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    datetime=\"2021/2023\",\n",
    ")\n",
    "\n",
    "# Load data into xarray format\n",
    "ds_s2 = odc.stac.load(\n",
    "    items=list(query.items()),\n",
    "    bands=[\"red\"],\n",
    "    crs=\"utm\",\n",
    "    resolution=30,\n",
    "    groupby=\"solar_day\",\n",
    "    bbox=bbox,\n",
    "    fail_on_error=False,\n",
    "    chunks={},\n",
    ")\n",
    "\n",
    "print(ds_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stats_ds.data_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stats import pixel_stats\n",
    "\n",
    "models = [\"EOT20\"]\n",
    "resample = True\n",
    "\n",
    "stats_ds = pixel_stats(\n",
    "    ds=satellite_ds,\n",
    "    model=models,\n",
    "    resample=resample,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Verify dims are correct\n",
    "assert stats_ds.odc.spatial_dims == satellite_ds.odc.spatial_dims\n",
    "\n",
    "# Verify vars are as expected\n",
    "expected_vars = ['hat',  'hot',  'lat',  'lot',  'otr',  'tr',  'spread',  'offset_low',  'offset_high']\n",
    "assert set(expected_vars) == set(stats_ds.data_vars)\n",
    "\n",
    "# Verify tide models are correct\n",
    "assert all(stats_ds[\"tide_model\"].values == models)\n",
    "if len(models) > 1:\n",
    "    assert \"tide_model\" in stats_ds.dims\n",
    "\n",
    "# If resample, assert that statistics have the same shape and dims\n",
    "# as `satellite_ds`\n",
    "if resample:\n",
    "    assert satellite_ds.odc.geobox.shape == stats_ds.odc.geobox.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify values are roughly expected\n",
    "assert np.allclose(stats_ds.offset_high.mean().item, 0.30, atol=0.02)\n",
    "assert np.allclose(stats_ds.offset_low.mean().item, 0.27, atol=0.02)\n",
    "assert np.allclose(stats_ds.spread.mean().item, 0.43, atol=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.offset_high.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.spread.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds[\"tide_model\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds[\"tide_model\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(['hat',  'hot',  'lat',  'lot',  'otr',  'tr',  'spread',  'offset_low',  'offset_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stats_ds.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import pixel_tides\n",
    "\n",
    "pixel_tides(\n",
    "    ds=satellite_ds,\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    directory=\"../tests/data/tide_models\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
