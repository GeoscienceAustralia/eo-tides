{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv==0.5.0\n",
    "!pip install -e ..   #--quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyTMD==2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e /home/jovyan/Robbi/pyTMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pystac_client\n",
    "\n",
    "from pyTMD.compute import tide_elevations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]  # simplified for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Robbi/eo-tides\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_satellite_ds():\n",
    "    \"\"\"\n",
    "    Load a sample timeseries of Landsat 8 data using odc-stac\n",
    "    \"\"\"\n",
    "    # Connect to stac catalogue\n",
    "    catalog = pystac_client.Client.open(\"https://explorer.dea.ga.gov.au/stac\")\n",
    "\n",
    "    # Set cloud defaults\n",
    "    odc.stac.configure_rio(\n",
    "        cloud_defaults=True,\n",
    "        aws={\"aws_unsigned\": True},\n",
    "    )\n",
    "\n",
    "    # Build a query with the parameters above\n",
    "    buffer = 0.08\n",
    "    # buffer = 0.5\n",
    "    bbox = [GAUGE_X - buffer, GAUGE_Y - buffer, GAUGE_X + buffer, GAUGE_Y + buffer]\n",
    "    query = catalog.search(\n",
    "        bbox=bbox,\n",
    "        collections=[\"ga_ls8c_ard_3\"],\n",
    "        datetime=\"2020-01/2020-02\",\n",
    "    )\n",
    "\n",
    "    # Search the STAC catalog for all items matching the query\n",
    "    ds = odc.stac.load(\n",
    "        list(query.items()),\n",
    "        bands=[\"nbart_red\"],\n",
    "        crs=\"epsg:3577\",\n",
    "        resolution=30,\n",
    "        groupby=\"solar_day\",\n",
    "        bbox=bbox,\n",
    "        fail_on_error=False,\n",
    "        chunks={\"x\": 100, \"y\": 200},\n",
    "    )\n",
    "\n",
    "    return ds\n",
    "\n",
    "satellite_ds = load_satellite_ds()\n",
    "\n",
    "\n",
    "def load_measured_tides_ds():\n",
    "    \"\"\"\n",
    "    Load measured sea level data from the Broome ABSLMP tidal station:\n",
    "    http://www.bom.gov.au/oceanography/projects/abslmp/data/data.shtml\n",
    "    \"\"\"\n",
    "    # Metadata for Broome ABSLMP tidal station:\n",
    "    # http://www.bom.gov.au/oceanography/projects/abslmp/data/data.shtml\n",
    "    ahd_offset = -5.322\n",
    "\n",
    "    # Load measured tides from ABSLMP tide gauge data\n",
    "    measured_tides_df = pd.read_csv(\n",
    "        \"tests/data/IDO71013_2020.csv\",\n",
    "        index_col=0,\n",
    "        parse_dates=True,\n",
    "        na_values=-9999,\n",
    "    )[[\"Sea Level\"]]\n",
    "\n",
    "    # Update index and column names\n",
    "    measured_tides_df.index.name = \"time\"\n",
    "    measured_tides_df.columns = [\"tide_height\"]\n",
    "\n",
    "    # Apply station AHD offset\n",
    "    measured_tides_df += ahd_offset\n",
    "\n",
    "    # Return as xarray dataset\n",
    "    return measured_tides_df.to_xarray()\n",
    "\n",
    "\n",
    "def create_synthetic_hamtide11(base_dir=\"tests/data/tide_models_synthetic\"):\n",
    "    \"\"\"\n",
    "    Generates and exports synthetic HAMTIDE11 model data\n",
    "    to test clipping functionality.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)  # Ensure base_dir is a Path object\n",
    "\n",
    "    # Create coordinate arrays\n",
    "    lon = np.arange(0, 360.125, 0.125)  # 2881 points\n",
    "    lat = np.arange(-90, 90.125, 0.125)  # 1441 points\n",
    "\n",
    "    # List of HAMTIDE11 tidal constituents\n",
    "    constituents = [\"2n\", \"k1\", \"k2\", \"m2\", \"n2\", \"o1\", \"p1\", \"q1\", \"s2\"]\n",
    "\n",
    "    # Create HAMTIDE11 output directory\n",
    "    hamtide_dir = base_dir / \"hamtide\"\n",
    "    hamtide_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create and save a NetCDF for each constituent\n",
    "    for constituent in constituents:\n",
    "\n",
    "        # Create synthetic HAMTIDE11 dataset with random data\n",
    "        shape = (len(lat), len(lon))  # 1441, 2881\n",
    "        data = np.random.random(shape).astype(np.float32)\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"RE\": ((\"LAT\", \"LON\"), data),\n",
    "                \"IM\": ((\"LAT\", \"LON\"), data),\n",
    "                \"AMPL\": ((\"LAT\", \"LON\"), data),\n",
    "                \"PHAS\": ((\"LAT\", \"LON\"), data),\n",
    "            },\n",
    "            coords={\"LON\": lon, \"LAT\": lat},\n",
    "            attrs={\"title\": f\"HAMTIDE11a: {constituent} ocean tide\"},\n",
    "        )\n",
    "\n",
    "        # Export\n",
    "        filename = hamtide_dir / f\"{constituent}.hamtide11a.nc\"\n",
    "        ds.to_netcdf(filename)\n",
    "\n",
    "\n",
    "def create_synthetic_eot20(base_dir=\"tests/data/tide_models_synthetic\"):\n",
    "    \"\"\"\n",
    "    Generates and exports synthetic EOT20 model data\n",
    "    to test clipping functionality.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)  # Ensure base_dir is a Path object\n",
    "\n",
    "    # Create coordinate arrays\n",
    "    lon = np.arange(0, 360.125, 0.125)  # 2881 points\n",
    "    lat = np.arange(-90, 90.125, 0.125)  # 1441 points\n",
    "\n",
    "    # List of EOT20 tidal constituents\n",
    "    constituents = [\n",
    "        \"2N2\", \"J1\", \"K1\", \"K2\", \"M2\", \"M4\", \"MF\", \"MM\", \"N2\",\n",
    "        \"O1\", \"P1\", \"Q1\", \"S1\", \"S2\", \"SA\", \"SSA\", \"T2\",\n",
    "    ]\n",
    "\n",
    "    # Create EOT20 output directory\n",
    "    eot20_dir = base_dir / \"EOT20/ocean_tides\"\n",
    "    eot20_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create and save a NetCDF for each constituent\n",
    "    for constituent in constituents:\n",
    "\n",
    "        # Create synthetic EOT20 dataset with random data\n",
    "        shape = (len(lat), len(lon))  # 1441, 2881\n",
    "        data = np.random.random(shape).astype(np.float64)\n",
    "\n",
    "        # Add NaN values to match original\n",
    "        mask = np.random.random(shape) < 0.2\n",
    "        data[mask] = np.nan\n",
    "\n",
    "        # Create the dataset\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"amplitude\": ((\"lat\", \"lon\"), data),\n",
    "                \"phase\": ((\"lat\", \"lon\"), data),\n",
    "                \"imag\": ((\"lat\", \"lon\"), data),\n",
    "                \"real\": ((\"lat\", \"lon\"), data),\n",
    "            },\n",
    "            coords={\"lat\": lat, \"lon\": lon},\n",
    "            attrs={\"title\": f\"DGFI-TUM global empirical ocean tide model\"},\n",
    "        )\n",
    "\n",
    "        # Export\n",
    "        filename = eot20_dir / f\"{constituent}_ocean_eot20.nc\"\n",
    "        ds.to_netcdf(filename)\n",
    "\n",
    "\n",
    "satellite_ds = load_satellite_ds()\n",
    "measured_tides_ds = load_measured_tides_ds()\n",
    "# create_synthetic_eot20()\n",
    "# create_synthetic_hamtide11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_model_tides_ensemble_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_parallel_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_eo.py --verbose -k test_tag_tides_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_utils.py --verbose -k test_clip_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check against validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 141kB\n",
       "Dimensions:      (time: 8784)\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 70kB 2020-01-01 ... 2020-12-31T23:00:00\n",
       "Data variables:\n",
       "    tide_height  (time) float64 70kB -3.032 -2.463 -1.295 ... -3.503 -3.049</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-bcab662f-d278-4516-8399-3011a1c92117' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-bcab662f-d278-4516-8399-3011a1c92117' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 8784</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-9259bce3-dfed-4f09-b28c-5b923e9ab187' class='xr-section-summary-in' type='checkbox'  checked><label for='section-9259bce3-dfed-4f09-b28c-5b923e9ab187' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2020-01-01 ... 2020-12-31T23:00:00</div><input id='attrs-dbf3c79e-fd75-42ca-a869-3786cf2df928' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-dbf3c79e-fd75-42ca-a869-3786cf2df928' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a000bda4-29aa-4fb9-82c8-97c85dc6df3d' class='xr-var-data-in' type='checkbox'><label for='data-a000bda4-29aa-4fb9-82c8-97c85dc6df3d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2020-01-01T00:00:00.000000000&#x27;, &#x27;2020-01-01T01:00:00.000000000&#x27;,\n",
       "       &#x27;2020-01-01T02:00:00.000000000&#x27;, ..., &#x27;2020-12-31T21:00:00.000000000&#x27;,\n",
       "       &#x27;2020-12-31T22:00:00.000000000&#x27;, &#x27;2020-12-31T23:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-11ab7eaa-3817-4470-b4e5-414d87d250f4' class='xr-section-summary-in' type='checkbox'  checked><label for='section-11ab7eaa-3817-4470-b4e5-414d87d250f4' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>tide_height</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-3.032 -2.463 ... -3.503 -3.049</div><input id='attrs-3f92e20e-f4af-4f47-a3d9-fbd66d7ccdd9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3f92e20e-f4af-4f47-a3d9-fbd66d7ccdd9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-43bc2761-630a-4b22-b166-634eadb01701' class='xr-var-data-in' type='checkbox'><label for='data-43bc2761-630a-4b22-b166-634eadb01701' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-3.032, -2.463, -1.295, ..., -2.796, -3.503, -3.049])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-2297ecb0-0523-4c4f-9d0a-59a001e9e3a7' class='xr-section-summary-in' type='checkbox'  ><label for='section-2297ecb0-0523-4c4f-9d0a-59a001e9e3a7' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-a6876b4f-74c0-47b0-87bf-73e0a615b79e' class='xr-index-data-in' type='checkbox'/><label for='index-a6876b4f-74c0-47b0-87bf-73e0a615b79e' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2020-01-01 00:00:00&#x27;, &#x27;2020-01-01 01:00:00&#x27;,\n",
       "               &#x27;2020-01-01 02:00:00&#x27;, &#x27;2020-01-01 03:00:00&#x27;,\n",
       "               &#x27;2020-01-01 04:00:00&#x27;, &#x27;2020-01-01 05:00:00&#x27;,\n",
       "               &#x27;2020-01-01 06:00:00&#x27;, &#x27;2020-01-01 07:00:00&#x27;,\n",
       "               &#x27;2020-01-01 08:00:00&#x27;, &#x27;2020-01-01 09:00:00&#x27;,\n",
       "               ...\n",
       "               &#x27;2020-12-31 14:00:00&#x27;, &#x27;2020-12-31 15:00:00&#x27;,\n",
       "               &#x27;2020-12-31 16:00:00&#x27;, &#x27;2020-12-31 17:00:00&#x27;,\n",
       "               &#x27;2020-12-31 18:00:00&#x27;, &#x27;2020-12-31 19:00:00&#x27;,\n",
       "               &#x27;2020-12-31 20:00:00&#x27;, &#x27;2020-12-31 21:00:00&#x27;,\n",
       "               &#x27;2020-12-31 22:00:00&#x27;, &#x27;2020-12-31 23:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=8784, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-e5454ac2-1abc-4d64-b768-ce73a45a18cd' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-e5454ac2-1abc-4d64-b768-ce73a45a18cd' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 141kB\n",
       "Dimensions:      (time: 8784)\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 70kB 2020-01-01 ... 2020-12-31T23:00:00\n",
       "Data variables:\n",
       "    tide_height  (time) float64 70kB -3.032 -2.463 -1.295 ... -3.503 -3.049"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_tides_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "from eo_tides.validation import eval_metrics\n",
    "\n",
    "modelled_df = model_tides(\n",
    "    time=measured_tides_ds.time,\n",
    "    x=GAUGE_X,\n",
    "    y=GAUGE_Y,\n",
    "    model=[\n",
    "        \"EOT20\",\n",
    "        # \"FES2012\",\n",
    "        # \"FES2014_extrapolated\",\n",
    "        # \"FES2022_extrapolated\",\n",
    "        # \"GOT5.6_extrapolated\",\n",
    "        # \"HAMTIDE11\",\n",
    "        # \"TPXO10-atlas-v2-nc\",\n",
    "        # \"TPXO8-atlas-nc\",\n",
    "        # \"TPXO9-atlas-v5-nc\",\n",
    "    ],\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    output_format=\"wide\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.0008"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAUGE_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'pow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyTMD\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tide_elevations\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Run equivalent pyTMD code to verify same results\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pytmd_tides \u001b[38;5;241m=\u001b[39m \u001b[43mtide_elevations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m122.2183\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m18.0008\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelta_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeasured_tides_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDIRECTORY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/var/share/tide_models/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEOT20\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEPSG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEPSG:4326\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTIME\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEXTRAPOLATE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCUTOFF\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pyTMD/compute.py:409\u001b[0m, in \u001b[0;36mtide_elevations\u001b[0;34m(x, y, delta_time, DIRECTORY, MODEL, GZIP, DEFINITION_FILE, CROP, BOUNDS, BUFFER, EPSG, EPOCH, TYPE, TIME, METHOD, EXTRAPOLATE, CUTOFF, CORRECTIONS, INFER_MINOR, MINOR_CONSTITUENTS, APPEND_NODE, APPLY_FLEXURE, FILL_VALUE, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m tide \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mzeros((nt), fill_value\u001b[38;5;241m=\u001b[39mFILL_VALUE)\n\u001b[1;32m    408\u001b[0m tide\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39many(hc\u001b[38;5;241m.\u001b[39mmask,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 409\u001b[0m tide\u001b[38;5;241m.\u001b[39mdata[:] \u001b[38;5;241m=\u001b[39m \u001b[43mpyTMD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeltat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeltat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodal_corrections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# calculate values for minor constituents by inferrence\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m INFER_MINOR:\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pyTMD/predict.py:200\u001b[0m, in \u001b[0;36mdrift\u001b[0;34m(t, hc, constituents, deltat, corrections)\u001b[0m\n\u001b[1;32m    197\u001b[0m hc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39matleast_2d(hc)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# load the nodal corrections\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# convert time to Modified Julian Days (MJD)\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m pu, pf, G \u001b[38;5;241m=\u001b[39m \u001b[43mpyTMD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_mjd_tide\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstituents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeltat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeltat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorrections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorrections\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# allocate for output time series\u001b[39;00m\n\u001b[1;32m    206\u001b[0m ht \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mzeros((nt))\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pyTMD/arguments.py:191\u001b[0m, in \u001b[0;36marguments\u001b[0;34m(MJD, constituents, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m G \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(fargs, coefficients_table(constituents, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# set nodal corrections\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# determine nodal corrections f and u for each model type\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m pu, pf \u001b[38;5;241m=\u001b[39m \u001b[43mnodal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstituents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# return values as tuple\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (pu, pf, G)\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pyTMD/arguments.py:562\u001b[0m, in \u001b[0;36mnodal\u001b[0;34m(n, p, constituents, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# compute additional angles for FES models\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m FES_TYPE:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# additional astronomical terms for FES models\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     II, xi, nu, Qa, Qu, Ra, Ru, nu_prime, nu_sec \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 562\u001b[0m         \u001b[43mpyTMD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschureman_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# set constituents to be iterable\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(constituents, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/pyTMD/astro.py:455\u001b[0m, in \u001b[0;36mschureman_arguments\u001b[0;34m(P, N)\u001b[0m\n\u001b[1;32m    453\u001b[0m Q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marctan((\u001b[38;5;241m5.0\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mcos(I) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mtan(p)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m7.0\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mcos(I) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m))\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# Schureman (page 41) equation 197\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m Qa \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m(\u001b[38;5;241m2.31\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.435\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;241m2.0\u001b[39m\u001b[38;5;241m*\u001b[39mp), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# Schureman (page 42) equation 204\u001b[39;00m\n\u001b[1;32m    457\u001b[0m Qu \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m-\u001b[39m Q\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/numpy/__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'pow'"
     ]
    }
   ],
   "source": [
    "from pyTMD.compute import tide_elevations\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=GAUGE_X,\n",
    "        y=GAUGE_Y,\n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"/var/share/tide_models/\",\n",
    "        MODEL=\"EOT20\",\n",
    "        EPSG=\"EPSG:4326\",\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_df.apply(lambda x: eval_metrics(x=measured_tides_ds.tide_height, y=x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_df.apply(lambda x: eval_metrics(x=measured_tides_ds.tide_height, y=x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "from eo_tides.model import ensemble_tides\n",
    "\n",
    "# Set modelling location based on bbox centroid\n",
    "time = pd.date_range(start=\"2000-01\", end=\"2001-03\", freq=\"5h\")\n",
    "\n",
    "# Model using unclipped vs clipped files\n",
    "tide_df = model_tides(\n",
    "    x=GAUGE_X,\n",
    "    y=GAUGE_Y,\n",
    "    time=time,\n",
    "    model=\"all\",\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# tide_df[\"tide_height\"] = tide_df.tide_height.astype(\"float64\")\n",
    "# ensemble_df = ensemble_tides(tide_df, ensemble_models=[\"EOT20\", \"HAMTIDE11\"], crs=\"EPSG:4326\")\n",
    "\n",
    "# print(ensemble_df)\n",
    "# print(ensemble_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tide_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create data with a cross product approach\n",
    "data = pd.DataFrame({\n",
    "    'time': pd.date_range(start='2000-01-01', periods=5, freq='5h').repeat(2),\n",
    "    'x': 122.2183,\n",
    "    'y': -18.0008,\n",
    "    'tide_model': ['EOT20', 'HAMTIDE11'] * 5,\n",
    "    'tide_height': np.random.uniform(-4, 3, 10).astype(\"float32\")\n",
    "})\n",
    "\n",
    "# Set multi-index\n",
    "data = data.set_index(['time', 'x', 'y'])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import clip_models\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "# @pytest.mark.parametrize(\"bbox, name\", [\n",
    "#     ((-166, 14, -151, 29), \"hawaii\"),\n",
    "#     ((-123.530273, 36.949892, -121.376953, 38.479395), \"sanfran\"),\n",
    "#     ((-17.753906, -36.031332, 60.996094, 37.857507), \"africa\"),\n",
    "#     ((-13, 49, 6, 60), \"uk\"),\n",
    "#     ((105.292969, -47.872144, 160.312500, -5.266008), \"aus\"),\n",
    "#     ((-256.640625, 7.013668, -119.794922, 63.391522), \"pacific\"),\n",
    "# ])\n",
    "\n",
    "bbox, name = (105.292969, -47.872144, 160.312500, -5.266008), \"aus\"\n",
    "\n",
    "def test_clip_models_bboxes(bbox, name):\n",
    "\n",
    "    # Set input and output paths\n",
    "    in_dir = \"tests/data/tide_models_synthetic/\"\n",
    "    out_dir = f\"tests/data/tide_models_synthetic_{name}/\"\n",
    "\n",
    "    # Clip models to input bbox\n",
    "    clip_models(\n",
    "        input_directory=in_dir,\n",
    "        output_directory=out_dir,\n",
    "        bbox=bbox,\n",
    "        model=\"HAMTIDE11\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Set modelling location based on bbox centroid\n",
    "    x, y = odc.geo.geom.BoundingBox(*bbox, crs=\"EPSG:4326\").polygon.centroid.xy\n",
    "    time = pd.date_range(start=\"2000-01\", end=\"2001-03\", freq=\"5h\")\n",
    "\n",
    "    # Model using unclipped vs clipped files\n",
    "    df_unclipped = model_tides(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        time=time,\n",
    "        model=\"HAMTIDE11\",\n",
    "        directory=in_dir,\n",
    "        crop=False,\n",
    "    )\n",
    "    df_clipped = model_tides(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        time=time,\n",
    "        model=\"HAMTIDE11\",\n",
    "        directory=out_dir,\n",
    "        crop=False,\n",
    "    )\n",
    "\n",
    "    # Verify both produce the same results\n",
    "    assert np.allclose(df_unclipped.tide_height, df_clipped.tide_height)\n",
    "\n",
    "test_clip_models_bboxes(bbox, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add tide phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.eo import tag_tides\n",
    "import xarray as xr\n",
    "\n",
    "# Use tag_tides to model both phases and tide heights\n",
    "tagged_tides_ds = tag_tides(\n",
    "    satellite_ds,\n",
    "    return_phases=True,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Verify output is an xarray.Dataset\n",
    "assert isinstance(tagged_tides_ds, xr.Dataset)\n",
    "\n",
    "# Verify vars are as expected\n",
    "expected_vars = [\"tide_height\", \"tide_phase\"]\n",
    "assert set(expected_vars) == set(tagged_tides_ds.data_vars)\n",
    "\n",
    "# Verify tide_phase values\n",
    "expected_phases = [\"low-flow\", \"high-flow\", \"low-ebb\", \"low-flow\", \"low-ebb\", \"low-flow\", \"high-flow\"]\n",
    "assert tagged_tides_ds.tide_phase.values.tolist() == expected_phases\n",
    "\n",
    "# Assert tide_model dim has been squeezed out\n",
    "assert \"tide_model\" not in tagged_tides_ds.dims\n",
    "\n",
    "# Model two models at once\n",
    "tagged_tides_ds = tag_tides(\n",
    "    satellite_ds,\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    return_phases=True,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Assert that output now has a tide_model dimension\n",
    "assert \"tide_model\" in tagged_tides_ds.dims\n",
    "assert len(tagged_tides_ds[\"tide_model\"]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update `tide_stats`\n",
    "\n",
    "\n",
    "Aim: internal `_tide_statistics` function that takes a stack of input observed and modelled tides in _both_ pandas and xarray format, and returns statistics in corresponding format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "from eo_tides.stats import pixel_stats, tide_stats\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EOT20\", \"GOT5.5\"]\n",
    "\n",
    "# Calculate tidal stats\n",
    "tidal_stats_df = tide_stats(\n",
    "    satellite_ds,\n",
    "    model=models,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# assert isinstance(tidal_stats_df, pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds = pixel_stats(\n",
    "    satellite_ds,\n",
    "    model=models,\n",
    "    resample=False,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stats_ds.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./tests/data/tide_models\"\n",
    "\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "# Input params\n",
    "good_hamtide11 = -17.58549, 123.59414\n",
    "good_eot20 = -17.1611, 123.3406\n",
    "y = [good_eot20[0], good_hamtide11[0]]\n",
    "x = [good_eot20[1], good_hamtide11[1]]\n",
    "\n",
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]\n",
    "\n",
    "# times = pd.date_range(\"2020\", \"2021\", periods=2)\n",
    "\n",
    "# # Default, only ensemble requested\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=\"ensemble\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert all(modelled_tides_df.tide_model == \"ensemble\")\n",
    "\n",
    "# Default, ensemble + other models requested\n",
    "models = [\"EOT20\", \"HAMTIDE11\", \"ensemble\"]\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert set(modelled_tides_df.tide_model) == set(models)\n",
    "# assert np.allclose(\n",
    "#     modelled_tides_df.tide_height.values,\n",
    "#     [\n",
    "#         0.094,\n",
    "#         -3.202,\n",
    "#         0.409,\n",
    "#         -3.098,\n",
    "#         0.803,\n",
    "#         0.664,\n",
    "#         0.989,\n",
    "#         1.011,\n",
    "#         0.449,\n",
    "#         -1.269,\n",
    "#         0.699,\n",
    "#         -1.043,\n",
    "#     ],\n",
    "#     atol=0.02,\n",
    "# )\n",
    "\n",
    "# # One-to-one mode\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     mode=\"one-to-one\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert set(modelled_tides_df.tide_model) == set(models)\n",
    "\n",
    "# # Wide mode, default\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist, and that ensemble is approx average\n",
    "# # of other two models\n",
    "# assert set(modelled_tides_df.columns) == set(models)\n",
    "# assert np.allclose(\n",
    "#     0.5 * (modelled_tides_df.EOT20 + modelled_tides_df.HAMTIDE11),\n",
    "#     modelled_tides_df.ensemble,\n",
    "# )\n",
    "\n",
    "# # Wide mode, top n == 1\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     ensemble_top_n=1,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# Check that expected models exist, and that ensemble is equal to at\n",
    "# least one of the other models\n",
    "assert set(modelled_tides_df.columns) == set(models)\n",
    "assert all(\n",
    "    (modelled_tides_df.EOT20 == modelled_tides_df.ensemble)\n",
    "    | (modelled_tides_df.HAMTIDE11 == modelled_tides_df.ensemble)\n",
    ")\n",
    "\n",
    "# Check that correct model is the closest at each row\n",
    "closer_model = modelled_tides_df.apply(\n",
    "    lambda row: (\n",
    "        \"EOT20\" if abs(row[\"ensemble\"] - row[\"EOT20\"]) < abs(row[\"ensemble\"] - row[\"HAMTIDE11\"]) else \"HAMTIDE11\"\n",
    "    ),\n",
    "    axis=1,\n",
    ").tolist()\n",
    "assert closer_model == [\"EOT20\", \"HAMTIDE11\", \"EOT20\", \"HAMTIDE11\"]\n",
    "\n",
    "# # Check values are expected\n",
    "# assert np.allclose(modelled_tides_df.ensemble, [0.09, 0.98, -3.20, 1.01], atol=0.02)\n",
    "\n",
    "# # Wide mode, custom functions\n",
    "# ensemble_funcs = {\n",
    "#     \"ensemble-best\": lambda x: x[\"rank\"] == 1,\n",
    "#     \"ensemble-worst\": lambda x: x[\"rank\"] == 2,\n",
    "#     \"ensemble-mean-top2\": lambda x: x[\"rank\"].isin([1, 2]),\n",
    "#     \"ensemble-mean-weighted\": lambda x: 3 - x[\"rank\"],\n",
    "#     \"ensemble-mean\": lambda x: x[\"rank\"] <= 2,\n",
    "# }\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     ensemble_func=ensemble_funcs,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist, and that valid data is produced\n",
    "# assert set(modelled_tides_df.columns) == set([\n",
    "#     \"EOT20\",\n",
    "#     \"HAMTIDE11\",\n",
    "#     \"ensemble-best\",\n",
    "#     \"ensemble-worst\",\n",
    "#     \"ensemble-mean-top2\",\n",
    "#     \"ensemble-mean-weighted\",\n",
    "#     \"ensemble-mean\",\n",
    "# ])\n",
    "# assert all(modelled_tides_df.notnull())\n",
    "\n",
    "# # Long mode, custom functions\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"long\",\n",
    "#     ensemble_func=ensemble_funcs,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist in \"tide_model\" column\n",
    "# assert set(modelled_tides_df.tide_model) == set([\n",
    "#     \"EOT20\",\n",
    "#     \"HAMTIDE11\",\n",
    "#     \"ensemble-best\",\n",
    "#     \"ensemble-worst\",\n",
    "#     \"ensemble-mean-top2\",\n",
    "#     \"ensemble-mean-weighted\",\n",
    "#     \"ensemble-mean\",\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]\n",
    "ensemble_models = ENSEMBLE_MODELS\n",
    "\n",
    "x = tide_df.index.get_level_values(level=\"x\")\n",
    "y = tide_df.index.get_level_values(level=\"y\")\n",
    "model_ranking_cols = [f\"rank_{m}\" for m in ensemble_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranks_gdf.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "ranking_points=\"https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/derivative/dea_intertidal/supplementary/rankings_ensemble_2017-2019.fgb\"\n",
    "crs = \"EPSG:4326\"\n",
    "ranking_valid_perc=0.02\n",
    "\n",
    "try:\n",
    "    model_ranks_gdf = (\n",
    "        gpd.read_file(ranking_points, engine=\"pyogrio\")\n",
    "        .to_crs(crs)\n",
    "        .query(f\"valid_perc > {ranking_valid_perc}\")\n",
    "        .dropna(how=\"all\")[model_ranking_cols + [\"geometry\"]]\n",
    "    )\n",
    "except KeyError:\n",
    "    error_msg = f\"\"\"\n",
    "    Not all of the expected \"rank_\" columns {model_ranking_cols} were\n",
    "    found in the columns of the ranking points file ({ranking_points}).\n",
    "    Consider passing a custom list of models using `ensemble_models`.\n",
    "    \"\"\"\n",
    "    raise Exception(textwrap.dedent(error_msg).strip()) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import idw\n",
    "\n",
    "idw_kwargs = {}\n",
    "\n",
    "# Use points to interpolate model rankings into requested x and y\n",
    "id_kwargs_str = \"\" if idw_kwargs == {} else idw_kwargs\n",
    "print(f\"Interpolating model rankings using IDW interpolation {id_kwargs_str}\")\n",
    "ensemble_ranks_df = (\n",
    "    # Run IDW interpolation on subset of ranking columns\n",
    "    pd.DataFrame(\n",
    "        idw(\n",
    "            input_z=model_ranks_gdf[model_ranking_cols],\n",
    "            input_x=model_ranks_gdf.geometry.x,\n",
    "            input_y=model_ranks_gdf.geometry.y,\n",
    "            output_x=x,\n",
    "            output_y=y,\n",
    "            **idw_kwargs,\n",
    "        ),\n",
    "        columns=model_ranking_cols,\n",
    "    )\n",
    "    .assign(x=x, y=y)\n",
    "    # Drop any duplicates then melt columns into long format\n",
    "    .drop_duplicates()\n",
    "    .melt(id_vars=[\"x\", \"y\"], var_name=\"tide_model\", value_name=\"rank\")\n",
    "    # Remore \"rank_\" prefix to get plain model names\n",
    "    .replace({\"^rank_\": \"\"}, regex=True)\n",
    "    # Set index columns and rank across groups\n",
    "    .set_index([\"tide_model\", \"x\", \"y\"])\n",
    "    .groupby([\"x\", \"y\"])\n",
    "    .rank()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranks_gdf[model_ranking_cols].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_ranks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "df = model_tides(x= 123.73412090186251, \n",
    "            y=-16.997767837915056, \n",
    "            model=\"ensemble\",\n",
    "            time=pd.date_range(start=\"2000\", end=\"2001\", freq=\"5h\"),\n",
    "            ranking_points=\"/home/jovyan/Robbi/dea-intertidal/data/raw/tide_correlation_points_test.geojson\",\n",
    "            k=5,\n",
    "            output_format=\"wide\",\n",
    "            directory=\"/var/share/tide_models/\")\n",
    "\n",
    "with pd.option_context('display.max_rows', 5, 'display.max_columns', None): \n",
    "    display(df)\n",
    "\n",
    "# u, c = np.unique(a, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "df = model_tides(\n",
    "    x=145.372051,\n",
    "    y=-38.260667,\n",
    "    model=[\n",
    "        \"EOT20\",\n",
    "        \"FES2012\",\n",
    "        \"FES2014_extrapolated\",\n",
    "        \"FES2022_extrapolated\",\n",
    "        \"HAMTIDE11\",\n",
    "        \"GOT4.10\",\n",
    "        \"GOT5.6_extrapolated\",\n",
    "        \"TPXO10-atlas-v2-nc\",\n",
    "        \"TPXO8-atlas-nc\",\n",
    "        \"TPXO9-atlas-v5-nc\",\n",
    "        \"ensemble\",\n",
    "    ],\n",
    "    time=pd.date_range(start=\"2018-01-01\", end=\"2020-12-31\", freq=\"1h\"),\n",
    "    output_format=\"wide\",\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    ensemble_models=[\n",
    "        \"EOT20\",\n",
    "        \"FES2012\",\n",
    "        \"FES2014_extrapolated\",\n",
    "        \"FES2022_extrapolated\",\n",
    "        # \"HAMTIDE11\",\n",
    "        # \"GOT4.10\",\n",
    "        \"GOT5.6_extrapolated\",\n",
    "        \"TPXO10-atlas-v2-nc\",\n",
    "        # \"TPXO8-atlas-nc\",\n",
    "        \"TPXO9-atlas-v5-nc\",\n",
    "    ]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.droplevel([\"x\", \"y\"]).head(50).drop(\"ensemble\", axis=1).plot(linewidth=0.8, figsize=(10, 6))\n",
    "df.droplevel([\"x\", \"y\"]).head(50).ensemble.plot(linewidth=3, c=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.droplevel([\"x\", \"y\"]).head(50).drop(\"ensemble\", axis=1).plot(linewidth=0.8, figsize=(10, 6))\n",
    "df.droplevel([\"x\", \"y\"]).head(50).ensemble.plot(linewidth=3, c=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_standardise_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import _set_directory, list_models\n",
    "\n",
    "directory = \"/home/jovyan/Robbi/eo-tides/tests/data/tide_models/\"\n",
    "directory = _set_directory(directory)\n",
    "\n",
    "\n",
    "# def _standardise_models(model, directory, ensemble_models=None):\n",
    "\n",
    "#     # Turn inputs into arrays for consistent handling\n",
    "#     models_requested = list(np.atleast_1d(model))\n",
    "\n",
    "#     # Get full list of supported models from pyTMD database\n",
    "#     available_models, valid_models = list_models(\n",
    "#         directory, show_available=False, show_supported=False, raise_error=True\n",
    "#     )\n",
    "#     custom_options = [\"ensemble\", \"all\"]\n",
    "\n",
    "#     # Error if any models are not supported\n",
    "#     if not all(m in valid_models + custom_options for m in models_requested):\n",
    "#         error_text = (\n",
    "#             f\"One or more of the requested models are not valid:\\n\"\n",
    "#             f\"{models_requested}\\n\\n\"\n",
    "#             \"The following models are supported:\\n\"\n",
    "#             f\"{valid_models}\"\n",
    "#         )\n",
    "#         raise ValueError(error_text)\n",
    "\n",
    "#     # Error if any models are not available in `directory`\n",
    "#     if not all(m in available_models + custom_options for m in models_requested):\n",
    "#         error_text = (\n",
    "#             f\"One or more of the requested models are valid, but not available in `{directory}`:\\n\"\n",
    "#             f\"{models_requested}\\n\\n\"\n",
    "#             f\"The following models are available in `{directory}`:\\n\"\n",
    "#             f\"{available_models}\"\n",
    "#         )\n",
    "#         raise ValueError(error_text)\n",
    "\n",
    "#     # If \"all\" models are requested, update requested list to include available models\n",
    "#     if \"all\" in models_requested:\n",
    "#         models_requested = available_models + [\n",
    "#             m for m in models_requested if m != \"all\"\n",
    "#         ]\n",
    "\n",
    "#     # If \"ensemble\" modeling is requested, use custom list of ensemble models\n",
    "#     if \"ensemble\" in models_requested:\n",
    "#         print(\"Running ensemble tide modelling\")\n",
    "#         ensemble_models = (\n",
    "#             ensemble_models\n",
    "#             if ensemble_models is not None\n",
    "#             else [\n",
    "#                 \"FES2014\",\n",
    "#                 \"TPXO9-atlas-v5\",\n",
    "#                 \"EOT20\",\n",
    "#                 \"HAMTIDE11\",\n",
    "#                 \"GOT4.10\",\n",
    "#                 \"FES2012\",\n",
    "#                 \"TPXO8-atlas-v1\",\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         # Error if any ensemble models are not available in `directory`\n",
    "#         if not all(m in available_models for m in ensemble_models):\n",
    "#             error_text = (\n",
    "#                 f\"One or more of the requested ensemble models are not available in `{directory}`:\\n\"\n",
    "#                 f\"{ensemble_models}\\n\\n\"\n",
    "#                 f\"The following models are available in `{directory}`:\\n\"\n",
    "#                 f\"{available_models}\"\n",
    "#             )\n",
    "#             raise ValueError(error_text)\n",
    "\n",
    "#         # Return set of all ensemble plus any other requested models\n",
    "#         models_to_process = ensemble_models + [\n",
    "#             m for m in models_requested if m != \"ensemble\"\n",
    "#         ]\n",
    "\n",
    "#     # Otherwise, models to process are the same as those requested\n",
    "#     else:\n",
    "#         models_to_process = models_requested\n",
    "\n",
    "#     # Remove duplicates\n",
    "#     models_to_process = list(set(models_to_process))\n",
    "#     models_requested = list(set(models_requested))\n",
    "\n",
    "#     return models_to_process, models_requested, ensemble_models\n",
    "\n",
    "\n",
    "# model = \"EOT20\"\n",
    "# # model = [\"EOT20\", \"HAMTIDE11\"]  # = [\"EOT20\", \"FES2014\"]\n",
    "# # model = \"all\"  # = [list all available]\n",
    "# # model = \"ensemble\" # = [list all ensemble]\n",
    "# # model = [\"ensemble\", \"GOT5.5\"]  # = [list all ensemble]\n",
    "# # model = [\"all\", \"ensemble\"]\n",
    "\n",
    "\n",
    "from eo_tides.utils import _standardise_models\n",
    "\n",
    "\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    "    [\"EOT20\"],\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"EOT20\",\n",
    "    None,\n",
    "    [\"EOT20\"],\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"all\",\n",
    "    None,\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"all\"],\n",
    "    None,\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"ensemble\",\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"ensemble\", \"GOT5.5\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"],\n",
    "    [\"GOT5.5\", \"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "# model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "#     [\"all\", \"ensemble\"],\n",
    "#     [\"EOT20\", \"HAMTIDE11\"],\n",
    "#     [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"],\n",
    "#     [\"GOT5.5\", \"HAMTIDE11\", \"ensemble\", \"EOT20\"],\n",
    "#     [\"EOT20\", \"HAMTIDE11\"],\n",
    "# )\n",
    "\n",
    "\n",
    "models_to_process, models_requested, ensemble_models = _standardise_models(\n",
    "    model=model,\n",
    "    directory=directory,\n",
    "    ensemble_models=ensemble_models,\n",
    ")\n",
    "\n",
    "print(\"Models to process: \", models_to_process)\n",
    "print(\"Models requested: \", models_requested)\n",
    "print(\"Ensemble models: \", ensemble_models)\n",
    "\n",
    "assert models_to_process == exp_process\n",
    "assert models_requested == exp_request\n",
    "assert ensemble_models == exp_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(models_requested + ensemble_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models\n",
    "\n",
    "models_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate interpolation functions\n",
    "\n",
    "crop=True, bounds=None: \n",
    "crop=False, bounds=None:\n",
    "crop=True, bounds="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "x=np.linspace(122.2183, 122.219, 10)\n",
    "y=np.linspace(-18.0008, -18.01, 10)\n",
    "time=pd.date_range(\"2020\", \"2021\", periods=10)\n",
    "crs=\"EPSG:4326\"\n",
    "method=\"spline\"\n",
    "model=\"FES2022\"\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        delta_time=time,\n",
    "        DIRECTORY=\"/gdata1/data/tide_models/\",\n",
    "        MODEL=model,\n",
    "        EPSG=int(crs[-4:]),\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=method,\n",
    "        CROP=True,\n",
    "        # CROP=False,\n",
    "        # BOUNDS=bounds,\n",
    "        )\n",
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"spline\", CROP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"linear\", CROP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"spline\", CROP=True, BOUNDS=[121.218, 123.218, -19.000, -17.000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function, annotations\n",
    "\n",
    "import logging\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from io import IOBase\n",
    "import scipy.interpolate\n",
    "import pyTMD.crs\n",
    "import pyTMD.io\n",
    "import pyTMD.io.model\n",
    "import pyTMD.predict\n",
    "import pyTMD.spatial\n",
    "import pyTMD.utilities\n",
    "import timescale.eop\n",
    "import timescale.time\n",
    "# attempt imports\n",
    "pyproj = pyTMD.utilities.import_dependency('pyproj')\n",
    "\n",
    "\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "x=x\n",
    "y=y\n",
    "delta_time=measured_tides_ds.time\n",
    "DIRECTORY=\"/var/share/tide_models/\"\n",
    "MODEL=model\n",
    "EPSG=int(crs[-4:])\n",
    "TIME=\"datetime\"\n",
    "EXTRAPOLATE=True\n",
    "CUTOFF=np.inf\n",
    "CROP=True\n",
    "METHOD=method\n",
    "\n",
    "GZIP=False\n",
    "DEFINITION_FILE=None\n",
    "BOUNDS=None\n",
    "EPOCH=(2000, 1, 1, 0, 0, 0)\n",
    "TYPE='drift'\n",
    "CORRECTIONS = None\n",
    "INFER_MINOR = True\n",
    "MINOR_CONSTITUENTS = None\n",
    "APPEND_NODE = False\n",
    "APPLY_FLEXURE= False\n",
    "FILL_VALUE=np.nan\n",
    "\n",
    "\n",
    "\n",
    "# check that tide directory is accessible\n",
    "if DIRECTORY is not None:\n",
    "    DIRECTORY = pathlib.Path(DIRECTORY).expanduser()\n",
    "    if not DIRECTORY.exists():\n",
    "        raise FileNotFoundError(\"Invalid tide directory\")\n",
    "\n",
    "# validate input arguments\n",
    "assert TIME.lower() in ('gps', 'loran', 'tai', 'utc', 'datetime')\n",
    "assert METHOD.lower() in ('bilinear', 'spline', 'linear', 'nearest')\n",
    "\n",
    "# get parameters for tide model\n",
    "if DEFINITION_FILE is not None:\n",
    "    model = pyTMD.io.model(DIRECTORY).from_file(DEFINITION_FILE)\n",
    "else:\n",
    "    model = pyTMD.io.model(DIRECTORY, compressed=GZIP).elevation(MODEL)\n",
    "\n",
    "# determine input data type based on variable dimensions\n",
    "if not TYPE:\n",
    "    TYPE = pyTMD.spatial.data_type(x, y, delta_time)\n",
    "assert TYPE.lower() in ('grid', 'drift', 'time series')\n",
    "# reform coordinate dimensions for input grids\n",
    "# or verify coordinate dimension shapes\n",
    "if (TYPE.lower() == 'grid') and (np.size(x) != np.size(y)):\n",
    "    x,y = np.meshgrid(np.copy(x),np.copy(y))\n",
    "elif (TYPE.lower() == 'grid'):\n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "elif TYPE.lower() in ('time series', 'drift'):\n",
    "    x = np.atleast_1d(x)\n",
    "    y = np.atleast_1d(y)\n",
    "\n",
    "# converting x,y from EPSG to latitude/longitude\n",
    "crs1 = pyTMD.crs().from_input(EPSG)\n",
    "crs2 = pyproj.CRS.from_epsg(4326)\n",
    "transformer = pyproj.Transformer.from_crs(crs1, crs2, always_xy=True)\n",
    "lon, lat = transformer.transform(x.flatten(), y.flatten())\n",
    "\n",
    "# verify that delta time is an array\n",
    "delta_time = np.atleast_1d(delta_time)\n",
    "# convert delta times or datetimes objects to timescale\n",
    "if (TIME.lower() == 'datetime'):\n",
    "    ts = timescale.time.Timescale().from_datetime(\n",
    "        delta_time.flatten())\n",
    "else:\n",
    "    ts = timescale.time.Timescale().from_deltatime(delta_time,\n",
    "        epoch=EPOCH, standard=TIME)\n",
    "# number of time points\n",
    "nt = len(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tidal constants and interpolate to grid points\n",
    "amp, ph, c = model.extract_constants(lon, lat, type=model.type,\n",
    "    crop=CROP, bounds=BOUNDS, method=METHOD,\n",
    "    extrapolate=EXTRAPOLATE, cutoff=CUTOFF,\n",
    "    append_node=APPEND_NODE, apply_flexure=APPLY_FLEXURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust dimensions of input coordinates to be iterable\n",
    "ilon = np.atleast_1d(np.copy(lon))\n",
    "ilat = np.atleast_1d(np.copy(lat))\n",
    "# set default bounds if cropping\n",
    "xmin, xmax = np.min(ilon), np.max(ilon)\n",
    "ymin, ymax = np.min(ilat), np.max(ilat)\n",
    "bounds=[xmin-1, xmax+1, ymin-1, ymax+1]\n",
    "\n",
    "\n",
    "# read tidal constants and interpolate to grid points\n",
    "c = model.read_constants(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.read_constants(crop=False, bounds=bounds)\n",
    "plt.imshow(c.m2.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.read_constants(crop=True, bounds=bounds)\n",
    "plt.imshow(c.m2.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c.m2.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate complex phase in radians for Euler's\n",
    "cph = -1j*ph*np.pi/180.0\n",
    "# calculate constituent oscillation\n",
    "hc = amp*np.exp(cph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "n = 2000\n",
    "x = np.random.uniform(112.715430, 154.727149, n)\n",
    "y = np.random.uniform(-44.199061, -10.035282, n)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "model = \"FES2014\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models/\"\n",
    "\n",
    "# Time the spline method\n",
    "start_time = time.time()\n",
    "modelled_tides_df_spline = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"spline\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=False, \n",
    ")\n",
    "spline_time = time.time() - start_time\n",
    "\n",
    "# Time the linear method  \n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"linear\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=False,\n",
    ")\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "print(f\"Spline method time: {spline_time:.6f} seconds\")\n",
    "print(f\"Linear method time: {linear_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "numpy.pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "n = 2000\n",
    "x = np.random.uniform(112.715430, 154.727149, n)\n",
    "y = np.random.uniform(-44.199061, -10.035282, n)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "model = \"FES2014\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models/\"\n",
    "\n",
    "# # Time the spline method\n",
    "# start_time = time.time()\n",
    "# modelled_tides_df_spline = model_tides(\n",
    "#    x=x,\n",
    "#    y=y,\n",
    "#    time=times,\n",
    "#    model=model,\n",
    "#    method=\"spline\",\n",
    "#    directory=directory,\n",
    "#    parallel=False,\n",
    "#    crop=True, \n",
    "# )\n",
    "# spline_time = time.time() - start_time\n",
    "\n",
    "# Time the linear method  \n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"linear\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=True,\n",
    ")\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "# print(f\"Spline method time: {spline_time:.6f} seconds\")\n",
    "print(f\"Linear method time: {linear_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "x = np.random.uniform(112.715430, 154.727149, 100000)\n",
    "y = np.random.uniform(-44.199061, -10.035282, 100000)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "# model = \"EOT20\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models_clipped/\"\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for model in [[\"EOT20\", \"GOT5.5\"], \"EOT20\"]:\n",
    "\n",
    "    for n in [100, 1000, 10000, 100000]:\n",
    "    \n",
    "        # Select a subset of x and y\n",
    "        x_sub = x[0:n]\n",
    "        y_sub = y[0:n]\n",
    "    \n",
    "        for parallel_max in [2, 4, 8, 16]:\n",
    "        \n",
    "            for parallel_split in [1, 2, 3, 4, 5, 6, 8, 10, 12, 16, 20]:\n",
    "        \n",
    "                # Time the linear method\n",
    "                start_time = time.time()\n",
    "                modelled_tides_df_linear = model_tides(\n",
    "                    x=x_sub,\n",
    "                    y=y_sub,\n",
    "                    time=times,\n",
    "                    model=model,\n",
    "                    method=\"linear\",\n",
    "                    directory=directory,\n",
    "                    parallel=True,\n",
    "                    parallel_splits=parallel_split,\n",
    "                    parallel_max=parallel_max,\n",
    "                    crop=True,\n",
    "                )\n",
    "                split_time = time.time() - start_time\n",
    "        \n",
    "                output_dict = {\n",
    "                    \"split\": parallel_split,\n",
    "                    \"parallel_max\": parallel_max,\n",
    "                    \"time\": split_time,\n",
    "                    \"points\": n,\n",
    "                    \"points_per_split\": int(n / parallel_split),\n",
    "                    \"split_per_parallel\": parallel_split / parallel_max,\n",
    "                    \"directory\": directory,\n",
    "                    \"model\": model,\n",
    "                }\n",
    "                output_list.append(output_dict)\n",
    "                print(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and export\n",
    "data = pd.DataFrame(output_list)\n",
    "data[\"time_per_point\"] = data[\"time\"] / data[\"points\"]\n",
    "data[\"model_multiple\"] = data[\"model\"].apply(lambda x: x == ['EOT20', 'GOT5.5'])\n",
    "data.to_csv(\"test_timings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"test_timings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='points_per_split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[1], linewidth=3)\n",
    "lineplot.invert_xaxis()\n",
    "axes[1].set_title('Time by Points per split')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model_multiple\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='points_per_split', y='time', hue='parallel_max', data=data.query(\"model_multiple\"), ax=axes[1], linewidth=3)\n",
    "lineplot.invert_xaxis()\n",
    "axes[1].set_title('Time by Points per split')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"split_per_parallel\"] = data[\"split\"] / data[\"parallel_max\"]\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='split_per_parallel', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[1], linewidth=3)\n",
    "axes[1].set_title('Time by Splits per parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"model == 'EOT20'\").query(\"parallel_max == 2\").query(\"points == 10000\").set_index(\"points_per_split\").time_per_point.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parallel_max = 16\n",
    "parallel_split=\"auto\"\n",
    "\n",
    "n = 200000\n",
    "models = [\"EOT20\"]  # [\"EOT20\", \"GOT5.5\"]\n",
    "# models = [\"EOT20\", \"GOT5.5\"]\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.process_cpu_count()\n",
    "\n",
    "parallel_split = int(max(1, min(n / 1000, parallel_max) / len(models)))\n",
    "print(parallel_split, n/parallel_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parallel_splits(\n",
    "    total_points,\n",
    "    model_count,\n",
    "    parallel_max=None,\n",
    "    min_points_per_split=1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the optimal number of parallel splits for data\n",
    "    processing based on system resources and processing constraints.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    total_points : int\n",
    "        Total number of data points to process\n",
    "    model_count : int\n",
    "        Number of models that will be run in parallel\n",
    "    parallel_max : int, optional\n",
    "        Maximum number of parallel processes to use. If None, uses CPU core count\n",
    "    min_points_per_split : int, default=1000\n",
    "        Minimum number of points that should be processed in each split\n",
    "    \"\"\"\n",
    "    # Available CPUs\n",
    "    if parallel_max is None:\n",
    "        try:\n",
    "            import psutil\n",
    "\n",
    "            parallel_max = psutil.cpu_count(logical=False)\n",
    "        except ImportError:\n",
    "            parallel_max = os.cpu_count()\n",
    "\n",
    "    # Calculate optimal number of splits based on constraints\n",
    "    splits_by_size = total_points / min_points_per_split\n",
    "    splits_by_cpu = parallel_max / model_count\n",
    "    optimal_splits = min(splits_by_size, splits_by_cpu)\n",
    "\n",
    "    # Convert to integer and ensure at least 1 split\n",
    "    final_split_count = int(max(1, optimal_splits))\n",
    "    return final_split_count\n",
    "\n",
    "\n",
    "_parallel_splits(total_points=1, model_count=1, parallel_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(10.6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count(affinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.cpu_count()\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=None) as executor:\n",
    "    executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "n = 10000\n",
    "directory = \"/gdata1/data/tide_models_clipped/\"\n",
    "directory = \"./tests/data/tide_models/\"\n",
    "# models = [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"]\n",
    "models = [\"EOT20\"]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "    x = np.random.uniform(112.715430, 154.727149, n),\n",
    "    y = np.random.uniform(-44.199061, -10.035282, n),\n",
    "    time = pd.date_range(\"2020\", \"2021\", periods=100),\n",
    "    model=models,\n",
    "    method=\"linear\",\n",
    "    directory=directory,\n",
    "    parallel=True,\n",
    "    parallel_splits=\"auto\",\n",
    "    parallel_max=16,\n",
    "    crop=False,\n",
    ")\n",
    "split_time = time.time() - start_time\n",
    "print(split_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 10000\n",
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (~model_multiple)\").style.background_gradient(cmap=\"YlOrRd\", subset=\"time_per_point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pivot(columns=\"model_multiple\", values=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (model_multiple)\").time.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (~model_multiple)\").time.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(modelled_tides_df_spline.droplevel([\"x\", \"y\"]).tide_height, modelled_tides_df_linear.droplevel([\"x\", \"y\"]).tide_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run equivalent pyTMD code to verify same results\n",
    "# pytmd_tides_spline = tide_elevations(\n",
    "#         x=np.repeat(149.722622, len(measured_tides_ds.time)), \n",
    "#         y=np.repeat(-22.132984, len(measured_tides_ds.time)), \n",
    "#         delta_time=measured_tides_ds.time,\n",
    "#         DIRECTORY=\"/var/share/tide_models/\",\n",
    "#         MODEL=\"FES2012\",\n",
    "#         EPSG=4326,\n",
    "#         TIME=\"datetime\",\n",
    "#         EXTRAPOLATE=True,\n",
    "#         CUTOFF=np.inf,\n",
    "#         METHOD=\"spline\",\n",
    "#         CROP=True,\n",
    "#         # BOUNDS=[148.722622, 149.722622, -22.132984, -23.132984],\n",
    "#         )\n",
    "\n",
    "pytmd_tides_linear = tide_elevations(\n",
    "        x=np.repeat(149.722622, len(measured_tides_ds.time)), \n",
    "        y=np.repeat(-22.132984, len(measured_tides_ds.time)), \n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"/var/share/tide_models/\",\n",
    "        MODEL=\"TPXO9-atlas-v5-nc\",\n",
    "        EPSG=4326,\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=\"linear\",\n",
    "        CROP=True,\n",
    "        # BOUNDS=[140.002622, 149.722622, -23.132984, -22.132984],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(pytmd_tides_spline.data, pytmd_tides_linear.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_df = phase_tides(\n",
    "    x=[122.14],\n",
    "    y=[-17.91],\n",
    "    time=pd.date_range(\"2020-01-01\", \"2020-01-02\", freq=\"h\"),\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    model=[\"EOT20\"],\n",
    "    delta = \"15 min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.date_range(start=\"2000-01-01\", end=\"2000-01-02\", periods=3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pyTMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"spline\", \"EOT20\"\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\"\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "\n",
    "# # Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    time=measured_tides_ds.time,\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    "    # crop=False,\n",
    ")\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"./tests/data/tide_models\",\n",
    "        MODEL=model,\n",
    "        EPSG=int(crs[-4:]),\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=method,\n",
    "        # CORRECTIONS: str | None = None,\n",
    "        # INFER_MINOR: bool = True,\n",
    "        # MINOR_CONSTITUENTS: list | None = None,\n",
    "        # APPLY_FLEXURE: bool = False,\n",
    "        # FILL_VALUE: float = np.nan\n",
    "        # APPEND_NODE=True,\n",
    "        )\n",
    "\n",
    "np.allclose(modelled_tides_df.tide_height.values, pytmd_tides.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"spline\", \"EOT20\"\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\"\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "\n",
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=\"FES2014\",\n",
    "    time=pd.date_range(\"1980\", \"2020\", freq=\"9h\"),\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"/var/share/tide_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df2 = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=\"FES2014\",\n",
    "    time=pd.date_range(\"1980\", \"2020\", freq=\"9h\"),\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"/var/share/tide_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df.tide_height.plot(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df2.tide_height - modelled_tides_df.tide_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error for out of bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y = 180, -50\n",
    "\n",
    "\n",
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    time=measured_tides_ds.time,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import list_models\n",
    "list_models(directory=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stats import pixel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EOT20\"]\n",
    "resample = False\n",
    "\n",
    "stats_ds = pixel_stats(\n",
    "    ds=satellite_ds,\n",
    "    model=models,\n",
    "    resample=resample,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling ebb and flow tidal phases\n",
    "The `tag_tides` function also allows us to determine whether each satellite observation was taken while the tide was rising/incoming (flow tide) or falling/outgoing (ebb tide) by setting `ebb_flow=True`. This is achieved by comparing tide heights 15 minutes before and after the observed satellite observation.\n",
    "\n",
    "Ebb and flow data can provide valuable contextual information for interpreting satellite imagery, particularly in tidal flat or mangrove forest environments where water may remain in the landscape for considerable time after the tidal peak.\n",
    "\n",
    "Once you run the cell below, our data will now also contain a new `ebb_flow` variable under **Data variables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "ds = dc.load(product=\"ga_s2ls_intertidal_cyear_3\", limit=1, measurements=\"elevation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.geo.geobox import GeoBox\n",
    "import xarray as xr\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def _standardise_time(\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Accept a datetime64 ndarray, pandas.DatetimeIndex\n",
    "    or pandas.Timestamp, and return a datetime64 ndarray.\n",
    "    \"\"\"\n",
    "    # Return time as-is if none\n",
    "    if time is None:\n",
    "        return time\n",
    "\n",
    "    # Convert to a 1D datetime64 array\n",
    "    time = np.atleast_1d(time).astype(\"datetime64[ns]\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "def _standardise_inputs(\n",
    "    ds: xr.DataArray | xr.Dataset | GeoBox,\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> (GeoBox, np.ndarray):\n",
    "    \"\"\"\n",
    "    Takes an xarray or GeoBox input and an optional custom times,\n",
    "    and returns a standardised GeoBox and  \n",
    "    \"\"\"\n",
    "\n",
    "    # If `ds` is an xarray object, extract its GeoBox and time\n",
    "    if isinstance(ds, (xr.DataArray, xr.Dataset)):\n",
    "\n",
    "        # Try to extract GeoBox\n",
    "        try:\n",
    "            gbox = ds.odc.geobox\n",
    "        except AttributeError:\n",
    "            error_msg = \"\"\"\n",
    "            Cannot extract a valid GeoBox for `ds`. This is required for\n",
    "            extracting details about `ds`'s CRS and spatial location.\n",
    "            \n",
    "            Import `odc.geo.xr` then run `ds = ds.odc.assign_crs(crs=...)`\n",
    "            to prepare your data before passing it to this function.\n",
    "            \"\"\"\n",
    "            raise Exception(textwrap.dedent(error_msg).strip())\n",
    "\n",
    "        # Use custom time by default if provided; otherwise try and extract from `ds`\n",
    "        if time is not None:\n",
    "            time = _standardise_time(time)\n",
    "        elif \"time\" in ds.coords:\n",
    "            time = ds.coords[\"time\"].values\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`ds` does not have a time dimension, and no custom times were provided via `time`.\"\n",
    "            )\n",
    "\n",
    "    # If `ds` is a GeoBox, use it directly; raise an error if no time was provided\n",
    "    elif isinstance(ds, GeoBox):\n",
    "        gbox = ds\n",
    "        if time is not None:\n",
    "            time = _standardise_time(time)\n",
    "        else:\n",
    "            raise ValueError(\"If `ds` is a GeoBox, `time` must be provided.\")\n",
    "\n",
    "    # Raise error if no valid inputs were provided\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"`ds` must be an xarray.DataArray, xarray.Dataset, or odc.geo.geobox.GeoBox.\"\n",
    "        )\n",
    "\n",
    "    return gbox, time\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "time = pd.date_range(\"2021\", \"2022\")\n",
    "time = pd.Timestamp(\"2022-02-01\")\n",
    "# time = satellite_ds.time\n",
    "# time = [\"a\", \"b\"]\n",
    "\n",
    "\n",
    "gbox, time = _standardise_inputs(ds=ds.drop_dims(\"time\").odc.geobox, time=time)\n",
    "gbox, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds.chunks[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "# time = pd.date_range(\"2021\", \"2022\")\n",
    "# time = pd.Timestamp(\"2022-02-01\")\n",
    "time = satellite_ds.time\n",
    "\n",
    "\n",
    "def _standardise_time(\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Accept a datetime64 ndarray, pandas.DatetimeIndex\n",
    "    or pandas.Timestamp, and return a datetime64 ndarray.\n",
    "    \"\"\"\n",
    "    # Return time as-is if none\n",
    "    if time is None:\n",
    "        return time\n",
    "\n",
    "    # Convert to a 1D datetime64 array\n",
    "    time = np.atleast_1d(time).astype(\"datetime64[ns]\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "# time = pd.date_range(\"2021\", \"2022\")\n",
    "# time = pd.Timestamp(\"2022-02-01\")\n",
    "# time = satellite_ds.time\n",
    "# time = [pd.Timestamp(\"2022-02-01\"), pd.Timestamp(\"2022-02-01\")]\n",
    "# time = None\n",
    "_standardise_time(time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.atleast_1d(time).astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.odc.assign_crs(\"EPSG:3577\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = satellite_ds.nbart_red.drop_attrs(deep=True).drop_vars(\"spatial_ref\").odc.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  #odc.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tide heights\n",
    "ds = tag_tides(\n",
    "    ds, \n",
    "    ebb_flow=True,     \n",
    "    directory=\"../../tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Print output data\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have data giving us the both the tide height and tidal phase (\"ebb\" or \"flow\") for every satellite image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[[\"time\", \"tide_height\", \"ebb_flow\"]].drop_vars(\"spatial_ref\").to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could for example use this data to filter our observations to keep ebbing phase observations only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ebb = ds.where(ds.ebb_flow == \"Ebb\", drop=True)\n",
    "print(ds_ebb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odc.stac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "# Connect to STAC catalog\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "# Set cloud access defaults\n",
    "odc.stac.configure_rio(\n",
    "    cloud_defaults=True,\n",
    "    aws={\"aws_unsigned\": True},\n",
    ")\n",
    "\n",
    "# Build a query and search the STAC catalog for all matching items\n",
    "bbox = [122.160, -18.05, 122.260, -17.95]\n",
    "query = catalog.search(\n",
    "    bbox=bbox,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    datetime=\"2021/2023\",\n",
    ")\n",
    "\n",
    "# Load data into xarray format\n",
    "ds_s2 = odc.stac.load(\n",
    "    items=list(query.items()),\n",
    "    bands=[\"red\"],\n",
    "    crs=\"utm\",\n",
    "    resolution=30,\n",
    "    groupby=\"solar_day\",\n",
    "    bbox=bbox,\n",
    "    fail_on_error=False,\n",
    "    chunks={},\n",
    ")\n",
    "\n",
    "print(ds_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stats_ds.data_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stats import pixel_stats\n",
    "\n",
    "models = [\"EOT20\"]\n",
    "resample = True\n",
    "\n",
    "stats_ds = pixel_stats(\n",
    "    ds=satellite_ds,\n",
    "    model=models,\n",
    "    resample=resample,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Verify dims are correct\n",
    "assert stats_ds.odc.spatial_dims == satellite_ds.odc.spatial_dims\n",
    "\n",
    "# Verify vars are as expected\n",
    "expected_vars = ['hat',  'hot',  'lat',  'lot',  'otr',  'tr',  'spread',  'offset_low',  'offset_high']\n",
    "assert set(expected_vars) == set(stats_ds.data_vars)\n",
    "\n",
    "# Verify tide models are correct\n",
    "assert all(stats_ds[\"tide_model\"].values == models)\n",
    "if len(models) > 1:\n",
    "    assert \"tide_model\" in stats_ds.dims\n",
    "\n",
    "# If resample, assert that statistics have the same shape and dims\n",
    "# as `satellite_ds`\n",
    "if resample:\n",
    "    assert satellite_ds.odc.geobox.shape == stats_ds.odc.geobox.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify values are roughly expected\n",
    "assert np.allclose(stats_ds.offset_high.mean().item, 0.30, atol=0.02)\n",
    "assert np.allclose(stats_ds.offset_low.mean().item, 0.27, atol=0.02)\n",
    "assert np.allclose(stats_ds.spread.mean().item, 0.43, atol=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.offset_high.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.spread.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds[\"tide_model\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds[\"tide_model\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(['hat',  'hot',  'lat',  'lot',  'otr',  'tr',  'spread',  'offset_low',  'offset_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stats_ds.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import pixel_tides\n",
    "\n",
    "pixel_tides(\n",
    "    ds=satellite_ds,\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    directory=\"../tests/data/tide_models\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
