{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install uv==0.5.0\n",
    "!pip install -e .. --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyTMD==2.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e /home/jovyan/Robbi/pyTMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pystac_client\n",
    "\n",
    "from pyTMD.compute import tide_elevations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]  # simplified for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_satellite_ds():\n",
    "    \"\"\"\n",
    "    Load a sample timeseries of Landsat 8 data using odc-stac\n",
    "    \"\"\"\n",
    "    # Connect to stac catalogue\n",
    "    catalog = pystac_client.Client.open(\"https://explorer.dea.ga.gov.au/stac\")\n",
    "\n",
    "    # Set cloud defaults\n",
    "    odc.stac.configure_rio(\n",
    "        cloud_defaults=True,\n",
    "        aws={\"aws_unsigned\": True},\n",
    "    )\n",
    "\n",
    "    # Build a query with the parameters above\n",
    "    buffer = 0.08\n",
    "    # buffer = 0.5\n",
    "    bbox = [GAUGE_X - buffer, GAUGE_Y - buffer, GAUGE_X + buffer, GAUGE_Y + buffer]\n",
    "    query = catalog.search(\n",
    "        bbox=bbox,\n",
    "        collections=[\"ga_ls8c_ard_3\"],\n",
    "        datetime=\"2020-01/2020-02\",\n",
    "    )\n",
    "\n",
    "    # Search the STAC catalog for all items matching the query\n",
    "    ds = odc.stac.load(\n",
    "        list(query.items()),\n",
    "        bands=[\"nbart_red\"],\n",
    "        crs=\"epsg:3577\",\n",
    "        resolution=30,\n",
    "        groupby=\"solar_day\",\n",
    "        bbox=bbox,\n",
    "        fail_on_error=False,\n",
    "        chunks={\"x\": 100, \"y\": 200},\n",
    "    )\n",
    "\n",
    "    return ds\n",
    "\n",
    "satellite_ds = load_satellite_ds()\n",
    "\n",
    "\n",
    "def load_measured_tides_ds():\n",
    "    \"\"\"\n",
    "    Load measured sea level data from the Broome ABSLMP tidal station:\n",
    "    http://www.bom.gov.au/oceanography/projects/abslmp/data/data.shtml\n",
    "    \"\"\"\n",
    "    # Metadata for Broome ABSLMP tidal station:\n",
    "    # http://www.bom.gov.au/oceanography/projects/abslmp/data/data.shtml\n",
    "    ahd_offset = -5.322\n",
    "\n",
    "    # Load measured tides from ABSLMP tide gauge data\n",
    "    measured_tides_df = pd.read_csv(\n",
    "        \"tests/data/IDO71013_2020.csv\",\n",
    "        index_col=0,\n",
    "        parse_dates=True,\n",
    "        na_values=-9999,\n",
    "    )[[\"Sea Level\"]]\n",
    "\n",
    "    # Update index and column names\n",
    "    measured_tides_df.index.name = \"time\"\n",
    "    measured_tides_df.columns = [\"tide_height\"]\n",
    "\n",
    "    # Apply station AHD offset\n",
    "    measured_tides_df += ahd_offset\n",
    "\n",
    "    # Return as xarray dataset\n",
    "    return measured_tides_df.to_xarray()\n",
    "\n",
    "\n",
    "def create_synthetic_hamtide11(base_dir=\"tests/data/tide_models_synthetic\"):\n",
    "    \"\"\"\n",
    "    Generates and exports synthetic HAMTIDE11 model data\n",
    "    to test clipping functionality.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)  # Ensure base_dir is a Path object\n",
    "\n",
    "    # Create coordinate arrays\n",
    "    lon = np.arange(0, 360.125, 0.125)  # 2881 points\n",
    "    lat = np.arange(-90, 90.125, 0.125)  # 1441 points\n",
    "\n",
    "    # List of HAMTIDE11 tidal constituents\n",
    "    constituents = [\"2n\", \"k1\", \"k2\", \"m2\", \"n2\", \"o1\", \"p1\", \"q1\", \"s2\"]\n",
    "\n",
    "    # Create HAMTIDE11 output directory\n",
    "    hamtide_dir = base_dir / \"hamtide\"\n",
    "    hamtide_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create and save a NetCDF for each constituent\n",
    "    for constituent in constituents:\n",
    "\n",
    "        # Create synthetic HAMTIDE11 dataset with random data\n",
    "        shape = (len(lat), len(lon))  # 1441, 2881\n",
    "        data = np.random.random(shape).astype(np.float32)\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"RE\": ((\"LAT\", \"LON\"), data),\n",
    "                \"IM\": ((\"LAT\", \"LON\"), data),\n",
    "                \"AMPL\": ((\"LAT\", \"LON\"), data),\n",
    "                \"PHAS\": ((\"LAT\", \"LON\"), data),\n",
    "            },\n",
    "            coords={\"LON\": lon, \"LAT\": lat},\n",
    "            attrs={\"title\": f\"HAMTIDE11a: {constituent} ocean tide\"},\n",
    "        )\n",
    "\n",
    "        # Export\n",
    "        filename = hamtide_dir / f\"{constituent}.hamtide11a.nc\"\n",
    "        ds.to_netcdf(filename)\n",
    "\n",
    "\n",
    "def create_synthetic_eot20(base_dir=\"tests/data/tide_models_synthetic\"):\n",
    "    \"\"\"\n",
    "    Generates and exports synthetic EOT20 model data\n",
    "    to test clipping functionality.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)  # Ensure base_dir is a Path object\n",
    "\n",
    "    # Create coordinate arrays\n",
    "    lon = np.arange(0, 360.125, 0.125)  # 2881 points\n",
    "    lat = np.arange(-90, 90.125, 0.125)  # 1441 points\n",
    "\n",
    "    # List of EOT20 tidal constituents\n",
    "    constituents = [\n",
    "        \"2N2\", \"J1\", \"K1\", \"K2\", \"M2\", \"M4\", \"MF\", \"MM\", \"N2\",\n",
    "        \"O1\", \"P1\", \"Q1\", \"S1\", \"S2\", \"SA\", \"SSA\", \"T2\",\n",
    "    ]\n",
    "\n",
    "    # Create EOT20 output directory\n",
    "    eot20_dir = base_dir / \"EOT20/ocean_tides\"\n",
    "    eot20_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create and save a NetCDF for each constituent\n",
    "    for constituent in constituents:\n",
    "\n",
    "        # Create synthetic EOT20 dataset with random data\n",
    "        shape = (len(lat), len(lon))  # 1441, 2881\n",
    "        data = np.random.random(shape).astype(np.float64)\n",
    "\n",
    "        # Add NaN values to match original\n",
    "        mask = np.random.random(shape) < 0.2\n",
    "        data[mask] = np.nan\n",
    "\n",
    "        # Create the dataset\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"amplitude\": ((\"lat\", \"lon\"), data),\n",
    "                \"phase\": ((\"lat\", \"lon\"), data),\n",
    "                \"imag\": ((\"lat\", \"lon\"), data),\n",
    "                \"real\": ((\"lat\", \"lon\"), data),\n",
    "            },\n",
    "            coords={\"lat\": lat, \"lon\": lon},\n",
    "            attrs={\"title\": f\"DGFI-TUM global empirical ocean tide model\"},\n",
    "        )\n",
    "\n",
    "        # Export\n",
    "        filename = eot20_dir / f\"{constituent}_ocean_eot20.nc\"\n",
    "        ds.to_netcdf(filename)\n",
    "\n",
    "\n",
    "satellite_ds = load_satellite_ds()\n",
    "measured_tides_ds = load_measured_tides_ds()\n",
    "# create_synthetic_eot20()\n",
    "# create_synthetic_hamtide11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_model_tides_ensemble_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_model_tides_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_model.py --verbose -k test_model_tides_constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_eo.py --verbose -k test_tag_tides_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_stats.py --verbose -k test_tide_aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_utils.py --verbose -k test_clip_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export EO_TIDES_TIDE_MODELS=./tests/data/tide_models && pytest tests/test_utils.py --verbose -k test_list_models_extra_databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constituents bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eo_tides\n",
    "\n",
    "eo_tides.model.model_tides(\n",
    "    x=122.2183,\n",
    "    y=-18.0008,\n",
    "    time=pd.date_range(\"2020-01-01\", \"2020-01-07\", freq=\"1h\"),\n",
    "    constituents=['m2', 's2'],   # works with `None`\n",
    "    model=\"EOT20\",  # also fails with `FES2022`\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ").tide_height.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import pandas as pd\n",
    "from eo_tides.stats import tide_aliasing \n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"satellites, c, units, style, expect_error\",\n",
    "    [\n",
    "        ([\"landsat\"], [\"m2\", \"k1\"], \"days\", False, None),\n",
    "        ([\"sentinel-2\"], None, \"hours\", True, None),\n",
    "        ([\"swot\", \"landsat\"], [\"k1\"], \"years\", False, None),\n",
    "        ([\"landsat\"], [\"mm\"], \"days\", False, None),\n",
    "        ([\"invalid-sat\"], [\"m2\"], \"days\", False, ValueError),\n",
    "        ([\"landsat\"], [\"m2\"], \"centuries\", False, ValueError),\n",
    "    ],\n",
    ")\n",
    "def test_tide_aliasing(satellites, c, units, style, expect_error):\n",
    "    if expect_error:\n",
    "        with pytest.raises(expect_error):\n",
    "            tide_aliasing(satellites, c=c, units=units, style=style)\n",
    "    else:\n",
    "        result = tide_aliasing(satellites, c=c, units=units, style=style)\n",
    "\n",
    "        # Verify output is a dataframe\n",
    "        if style:\n",
    "            assert isinstance(result, pd.io.formats.style.Styler)\n",
    "        else:\n",
    "            assert isinstance(result, pd.DataFrame)\n",
    "\n",
    "        # Verify\n",
    "        assert \"name\" in result.columns\n",
    "        assert \"type\" in result.columns\n",
    "        assert \"period\" in result.columns\n",
    "\n",
    "        for sat in satellites:\n",
    "            assert (\"aliasing_period\", sat) in result.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellites, c, units, style, expect_error = {\"custom-sat1\": 6, \"custom-sat2\": 10}, None, \"hours\", True, None\n",
    "test_tide_aliasing(satellites, c, units, style, expect_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tide_aliasing(satellites={\"boo\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"bad_args, expected_exception\",\n",
    "    [\n",
    "        ({\"time\": None}, ValueError),\n",
    "        ({\"method\": \"cubic\"}, ValueError),\n",
    "        ({\"output_units\": \"feet\"}, ValueError),\n",
    "        ({\"output_format\": \"stacked\"}, ValueError),\n",
    "        ({\"x\": np.array([\"a\", \"b\", \"c\"])}, TypeError),\n",
    "        ({\"y\": np.array([\"a\", \"b\", \"c\"])}, TypeError),\n",
    "        ({\"x\": np.array([1, 2])}, ValueError),\n",
    "        (\n",
    "            {\"mode\": \"one-to-one\", \"time\": np.array([\"2025-01-01\", \"2025-01-02\"])},\n",
    "            ValueError,\n",
    "        ),\n",
    "    ],\n",
    "    ids=[\n",
    "        \"missing_time\",\n",
    "        \"invalid_method\",\n",
    "        \"invalid_units\",\n",
    "        \"invalid_format\",\n",
    "        \"non_numeric_x\",\n",
    "        \"non_numeric_y\",\n",
    "        \"x_y_length_mismatch\",\n",
    "        \"time_length_mismatch\",\n",
    "    ],\n",
    ")\n",
    "def test_model_tides_validation(bad_args, expected_exception):\n",
    "\n",
    "    # Dummy valid inputs\n",
    "    args = {\n",
    "        \"x\": GAUGE_X,\n",
    "        \"y\": GAUGE_Y,\n",
    "        \"time\": np.array(\n",
    "            [\"2025-01-01\", \"2025-01-02\", \"2025-01-03\"], dtype=\"datetime64[ns]\"\n",
    "        ),\n",
    "        \"directory\": \"/var/share/tide_models/\",\n",
    "    }\n",
    "\n",
    "    # Update with bad kwargs\n",
    "    args.update(bad_args)\n",
    "\n",
    "    # Verify error is raised\n",
    "    with pytest.raises(expected_exception):\n",
    "        model_tides(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pytest\n",
    "\n",
    "from eo_tides.utils import _set_directory  # Replace with actual import\n",
    "\n",
    "\n",
    "\n",
    "# Use monkeypatch to test setting and unsetting environment var\n",
    "@pytest.mark.parametrize(\n",
    "    \"directory,env_var,expected_exception\",\n",
    "    [\n",
    "        # Case 1: No directory, no env var → Exception\n",
    "        (None, None, Exception),\n",
    "        \n",
    "        # Case 2: Directory set, but path doesn't exist → FileNotFoundError\n",
    "        (\"/some/nonexistent/path\", None, FileNotFoundError),\n",
    "\n",
    "        # Case 3: Env var set, but path doesn't exist → FileNotFoundError\n",
    "        (None, \"/some/nonexistent/path\", FileNotFoundError),\n",
    "    ],\n",
    "    ids=[\"no_directory_or_env\", \"invalid_dir\", \"invalid_env_var\"]\n",
    ")\n",
    "def test_set_directory_errors(monkeypatch, directory, env_var, expected_exception):\n",
    "    # Ensure env var is unset unless explicitly requested\n",
    "    if env_var is None:\n",
    "        monkeypatch.delenv(\"EO_TIDES_TIDE_MODELS\", raising=False)\n",
    "    else:\n",
    "        monkeypatch.setenv(\"EO_TIDES_TIDE_MODELS\", env_var)\n",
    "\n",
    "    # with pytest.raises(expected_exception):\n",
    "    _set_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from unittest.mock import patch\n",
    "\n",
    "from eo_tides.utils import _standardise_models  # Replace with actual import\n",
    "\n",
    "\n",
    "# Test expected failures during model standardisation\n",
    "@pytest.mark.parametrize(\n",
    "    \"model, ensemble_models, err_msg\",\n",
    "    [\n",
    "        # Case 1: Duplicate models\n",
    "        ([\"EOT20\", \"EOT20\"], None, \"duplicate values\"),\n",
    "\n",
    "        # Case 2: Unsupported model\n",
    "        ([\"bad_model\"], None, \"not valid\"),\n",
    "\n",
    "        # Case 3: Model valid but not available\n",
    "        ([\"FES2012\"], None, \"not available\"),\n",
    "\n",
    "        # Case 4: Ensemble requested but ensemble model not available\n",
    "        ([\"ensemble\"], [\"EOT20\", \"FES2012\"], \"ensemble models are not available\"),\n",
    "    ],\n",
    "    ids=[\"duplicate_model\", \"invalid_model\", \"unavailable_model\", \"unavailable_ensemble\"],\n",
    ")\n",
    "def test_standardise_models_errors(model, ensemble_models, err_msg):\n",
    "\n",
    "    with pytest.raises(ValueError, match=err_msg):\n",
    "        _standardise_models(\n",
    "            model=model,\n",
    "            directory=\"../tests/data/tide_models\",\n",
    "            ensemble_models=ensemble_models,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_standardise_models_validation([\"ensemble\"], [\"EOT20\", \"FES2012\"], \"ensemble models are not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTMD\n",
    "\n",
    "custom_dict = {\n",
    "    \"format\": \"FES-netcdf\",\n",
    "    \"model_file\": [\n",
    "        \"EOT20/ocean_tides/2N2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/J1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/K1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/K2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/M2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/M4_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/MF_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/MM_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/N2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/O1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/P1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/Q1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/S1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/S2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/SA_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/SSA_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/T2_ocean_eot20.nc\"\n",
    "    ],\n",
    "    \"name\": \"EOT20_custom\",\n",
    "    \"reference\": \"https://doi.org/10.17882/79489\",\n",
    "    \"scale\": 0.01,\n",
    "    \"type\": \"z\",\n",
    "    \"variable\": \"tide_ocean\",\n",
    "    \"version\": \"EOT20\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "pyTMD.io.model(\"/gdata1/data/tide_models\").from_dict(custom_dict).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model def from dict\n",
    "model = pyTMD.io.model(directory=\"/var/share/tide_models/\").from_dict(custom_dict)\n",
    "assert model.verify\n",
    "\n",
    "# Read tidal constants and interpolate to grid points\n",
    "amp, ph, c = model.extract_constants(155, -32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model def from file\n",
    "model = pyTMD.io.model(directory=\"/var/share/tide_models/\").from_file(\"tests/data/model_EOT20custom.json\")\n",
    "assert model.verify\n",
    "\n",
    "# Read tidal constants and interpolate to grid points\n",
    "amp, ph, c = model.extract_constants(155, -32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyTMD.io.model(\"/gdata1/data/tide_models\").from_file(\"/gdata1/data/tide_models/INATIDES/model_INATIDES.json\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTMD\n",
    "import pandas as pd\n",
    "from eo_tides.utils import _custom_model_definitions, list_models\n",
    "from eo_tides.model import model_tides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models, supported_models = list_models(\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    custom_models=[custom_dict],\n",
    "    show_supported=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_dict = {\n",
    "    \"format\": \"FES-netcdf\",\n",
    "    \"model_file\": [\n",
    "        \"EOT20/ocean_tides/2N2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/J1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/K1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/K2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/M2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/M4_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/MF_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/MM_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/N2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/O1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/P1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/Q1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/S1_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/S2_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/SA_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/SSA_ocean_eot20.nc\",\n",
    "        \"EOT20/ocean_tides/T2_ocean_eot20.nc\"\n",
    "    ],\n",
    "    \"name\": \"EOT20_custom\",\n",
    "    \"reference\": \"https://doi.org/10.17882/79489\",\n",
    "    \"scale\": 0.01,\n",
    "    \"type\": \"z\",\n",
    "    \"variable\": \"tide_ocean\",\n",
    "    \"version\": \"EOT20\"\n",
    "}\n",
    "\n",
    "\n",
    "model_tides(\n",
    "    x=115.313154,\n",
    "    y=-8.668534,\n",
    "    time=pd.date_range(\"2022-01-01\", \"2022-01-31\", freq=\"1h\"),\n",
    "    model=\"EOT20_custom\",\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    custom_models=[custom_dict],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_tides(\n",
    "    x=115.313154,\n",
    "    y=-8.668534,\n",
    "    time=pd.date_range(\"2022-01-01\", \"2022-01-31\", freq=\"1h\"),\n",
    "    model=[\"INATIDES\", \"EOT20\", \"HAMTIDE11\"],\n",
    "    directory=\"/gdata1/data/tide_models\",\n",
    "    custom_models=[\"/gdata1/data/tide_models/INATIDES/model_INATIDES.json\"],\n",
    "    output_format=\"wide\",\n",
    "    parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test available tide models\n",
    "def test_list_models_custom():\n",
    "    # Verify that custom models are added to lists of\n",
    "    # available and supported models\n",
    "    available_models, supported_models = list_models(\n",
    "        directory=\"./tests/data/tide_models\", \n",
    "        custom_models=[\"./tests/data/model_EOT20custom.json\"],\n",
    "    )\n",
    "    assert \"EOT20_custom\" in available_models\n",
    "    assert \"EOT20_custom\" in supported_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new PyTMD version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "from eo_tides.validation import eval_metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"/var/share/tide_models/\"\n",
    "\n",
    "# Time the spline method\n",
    "modelled_tides_df = model_tides(\n",
    "   x=GAUGE_X,\n",
    "   y=GAUGE_Y,\n",
    "   time=measured_tides_ds.time,\n",
    "   model=\"all\",\n",
    "   directory=directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df.groupby(\"tide_model\").apply(lambda z: eval_metrics(x=measured_tides_ds.tide_height, y=z.tide_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df.groupby(\"tide_model\").apply(lambda z: eval_metrics(x=measured_tides_ds.tide_height, y=z.tide_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "from eo_tides.model import ensemble_tides\n",
    "\n",
    "# Set modelling location based on bbox centroid\n",
    "time = pd.date_range(start=\"2000-01\", end=\"2001-03\", freq=\"5h\")\n",
    "\n",
    "# Model using unclipped vs clipped files\n",
    "tide_df = model_tides(\n",
    "    x=GAUGE_X,\n",
    "    y=GAUGE_Y,\n",
    "    time=time,\n",
    "    model=\"all\",\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# tide_df[\"tide_height\"] = tide_df.tide_height.astype(\"float64\")\n",
    "# ensemble_df = ensemble_tides(tide_df, ensemble_models=[\"EOT20\", \"HAMTIDE11\"], crs=\"EPSG:4326\")\n",
    "\n",
    "# print(ensemble_df)\n",
    "# print(ensemble_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tide_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create data with a cross product approach\n",
    "data = pd.DataFrame({\n",
    "    'time': pd.date_range(start='2000-01-01', periods=5, freq='5h').repeat(2),\n",
    "    'x': 122.2183,\n",
    "    'y': -18.0008,\n",
    "    'tide_model': ['EOT20', 'HAMTIDE11'] * 5,\n",
    "    'tide_height': np.random.uniform(-4, 3, 10).astype(\"float32\")\n",
    "})\n",
    "\n",
    "# Set multi-index\n",
    "data = data.set_index(['time', 'x', 'y'])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import clip_models\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "# @pytest.mark.parametrize(\"bbox, name\", [\n",
    "#     ((-166, 14, -151, 29), \"hawaii\"),\n",
    "#     ((-123.530273, 36.949892, -121.376953, 38.479395), \"sanfran\"),\n",
    "#     ((-17.753906, -36.031332, 60.996094, 37.857507), \"africa\"),\n",
    "#     ((-13, 49, 6, 60), \"uk\"),\n",
    "#     ((105.292969, -47.872144, 160.312500, -5.266008), \"aus\"),\n",
    "#     ((-256.640625, 7.013668, -119.794922, 63.391522), \"pacific\"),\n",
    "# ])\n",
    "\n",
    "bbox, name = (105.292969, -47.872144, 160.312500, -5.266008), \"aus\"\n",
    "\n",
    "def test_clip_models_bboxes(bbox, name):\n",
    "\n",
    "    # Set input and output paths\n",
    "    in_dir = \"tests/data/tide_models_synthetic/\"\n",
    "    out_dir = f\"tests/data/tide_models_synthetic_{name}/\"\n",
    "\n",
    "    # Clip models to input bbox\n",
    "    clip_models(\n",
    "        input_directory=in_dir,\n",
    "        output_directory=out_dir,\n",
    "        bbox=bbox,\n",
    "        model=\"HAMTIDE11\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Set modelling location based on bbox centroid\n",
    "    x, y = odc.geo.geom.BoundingBox(*bbox, crs=\"EPSG:4326\").polygon.centroid.xy\n",
    "    time = pd.date_range(start=\"2000-01\", end=\"2001-03\", freq=\"5h\")\n",
    "\n",
    "    # Model using unclipped vs clipped files\n",
    "    df_unclipped = model_tides(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        time=time,\n",
    "        model=\"HAMTIDE11\",\n",
    "        directory=in_dir,\n",
    "        crop=False,\n",
    "    )\n",
    "    df_clipped = model_tides(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        time=time,\n",
    "        model=\"HAMTIDE11\",\n",
    "        directory=out_dir,\n",
    "        crop=False,\n",
    "    )\n",
    "\n",
    "    # Verify both produce the same results\n",
    "    assert np.allclose(df_unclipped.tide_height, df_clipped.tide_height)\n",
    "\n",
    "test_clip_models_bboxes(bbox, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add tide phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.eo import tag_tides\n",
    "import xarray as xr\n",
    "\n",
    "# Use tag_tides to model both phases and tide heights\n",
    "tagged_tides_ds = tag_tides(\n",
    "    satellite_ds,\n",
    "    return_phases=True,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Verify output is an xarray.Dataset\n",
    "assert isinstance(tagged_tides_ds, xr.Dataset)\n",
    "\n",
    "# Verify vars are as expected\n",
    "expected_vars = [\"tide_height\", \"tide_phase\"]\n",
    "assert set(expected_vars) == set(tagged_tides_ds.data_vars)\n",
    "\n",
    "# Verify tide_phase values\n",
    "expected_phases = [\"low-flow\", \"high-flow\", \"low-ebb\", \"low-flow\", \"low-ebb\", \"low-flow\", \"high-flow\"]\n",
    "assert tagged_tides_ds.tide_phase.values.tolist() == expected_phases\n",
    "\n",
    "# Assert tide_model dim has been squeezed out\n",
    "assert \"tide_model\" not in tagged_tides_ds.dims\n",
    "\n",
    "# Model two models at once\n",
    "tagged_tides_ds = tag_tides(\n",
    "    satellite_ds,\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    return_phases=True,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Assert that output now has a tide_model dimension\n",
    "assert \"tide_model\" in tagged_tides_ds.dims\n",
    "assert len(tagged_tides_ds[\"tide_model\"]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update `tide_stats`\n",
    "\n",
    "\n",
    "Aim: internal `_tide_statistics` function that takes a stack of input observed and modelled tides in _both_ pandas and xarray format, and returns statistics in corresponding format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "from eo_tides.stats import pixel_stats, tide_stats\n",
    "\n",
    "GAUGE_X = 122.2183\n",
    "GAUGE_Y = -18.0008\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EOT20\", \"GOT5.5\"]\n",
    "\n",
    "# Calculate tidal stats\n",
    "tidal_stats_df = tide_stats(\n",
    "    satellite_ds,\n",
    "    model=models,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# assert isinstance(tidal_stats_df, pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds = pixel_stats(\n",
    "    satellite_ds,\n",
    "    model=models,\n",
    "    resample=False,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stats_ds.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./tests/data/tide_models\"\n",
    "\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "# Input params\n",
    "good_hamtide11 = -17.58549, 123.59414\n",
    "good_eot20 = -17.1611, 123.3406\n",
    "y = [good_eot20[0], good_hamtide11[0]]\n",
    "x = [good_eot20[1], good_hamtide11[1]]\n",
    "\n",
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]\n",
    "\n",
    "# times = pd.date_range(\"2020\", \"2021\", periods=2)\n",
    "\n",
    "# # Default, only ensemble requested\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=\"ensemble\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert all(modelled_tides_df.tide_model == \"ensemble\")\n",
    "\n",
    "# Default, ensemble + other models requested\n",
    "models = [\"EOT20\", \"HAMTIDE11\", \"ensemble\"]\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert set(modelled_tides_df.tide_model) == set(models)\n",
    "# assert np.allclose(\n",
    "#     modelled_tides_df.tide_height.values,\n",
    "#     [\n",
    "#         0.094,\n",
    "#         -3.202,\n",
    "#         0.409,\n",
    "#         -3.098,\n",
    "#         0.803,\n",
    "#         0.664,\n",
    "#         0.989,\n",
    "#         1.011,\n",
    "#         0.449,\n",
    "#         -1.269,\n",
    "#         0.699,\n",
    "#         -1.043,\n",
    "#     ],\n",
    "#     atol=0.02,\n",
    "# )\n",
    "\n",
    "# # One-to-one mode\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     mode=\"one-to-one\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# assert modelled_tides_df.index.names == [\"time\", \"x\", \"y\"]\n",
    "# assert modelled_tides_df.columns.tolist() == [\"tide_model\", \"tide_height\"]\n",
    "# assert set(modelled_tides_df.tide_model) == set(models)\n",
    "\n",
    "# # Wide mode, default\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist, and that ensemble is approx average\n",
    "# # of other two models\n",
    "# assert set(modelled_tides_df.columns) == set(models)\n",
    "# assert np.allclose(\n",
    "#     0.5 * (modelled_tides_df.EOT20 + modelled_tides_df.HAMTIDE11),\n",
    "#     modelled_tides_df.ensemble,\n",
    "# )\n",
    "\n",
    "# # Wide mode, top n == 1\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     ensemble_top_n=1,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# Check that expected models exist, and that ensemble is equal to at\n",
    "# least one of the other models\n",
    "assert set(modelled_tides_df.columns) == set(models)\n",
    "assert all(\n",
    "    (modelled_tides_df.EOT20 == modelled_tides_df.ensemble)\n",
    "    | (modelled_tides_df.HAMTIDE11 == modelled_tides_df.ensemble)\n",
    ")\n",
    "\n",
    "# Check that correct model is the closest at each row\n",
    "closer_model = modelled_tides_df.apply(\n",
    "    lambda row: (\n",
    "        \"EOT20\" if abs(row[\"ensemble\"] - row[\"EOT20\"]) < abs(row[\"ensemble\"] - row[\"HAMTIDE11\"]) else \"HAMTIDE11\"\n",
    "    ),\n",
    "    axis=1,\n",
    ").tolist()\n",
    "assert closer_model == [\"EOT20\", \"HAMTIDE11\", \"EOT20\", \"HAMTIDE11\"]\n",
    "\n",
    "# # Check values are expected\n",
    "# assert np.allclose(modelled_tides_df.ensemble, [0.09, 0.98, -3.20, 1.01], atol=0.02)\n",
    "\n",
    "# # Wide mode, custom functions\n",
    "# ensemble_funcs = {\n",
    "#     \"ensemble-best\": lambda x: x[\"rank\"] == 1,\n",
    "#     \"ensemble-worst\": lambda x: x[\"rank\"] == 2,\n",
    "#     \"ensemble-mean-top2\": lambda x: x[\"rank\"].isin([1, 2]),\n",
    "#     \"ensemble-mean-weighted\": lambda x: 3 - x[\"rank\"],\n",
    "#     \"ensemble-mean\": lambda x: x[\"rank\"] <= 2,\n",
    "# }\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"wide\",\n",
    "#     ensemble_func=ensemble_funcs,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist, and that valid data is produced\n",
    "# assert set(modelled_tides_df.columns) == set([\n",
    "#     \"EOT20\",\n",
    "#     \"HAMTIDE11\",\n",
    "#     \"ensemble-best\",\n",
    "#     \"ensemble-worst\",\n",
    "#     \"ensemble-mean-top2\",\n",
    "#     \"ensemble-mean-weighted\",\n",
    "#     \"ensemble-mean\",\n",
    "# ])\n",
    "# assert all(modelled_tides_df.notnull())\n",
    "\n",
    "# # Long mode, custom functions\n",
    "# modelled_tides_df = model_tides(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     time=times,\n",
    "#     model=models,\n",
    "#     output_format=\"long\",\n",
    "#     ensemble_func=ensemble_funcs,\n",
    "#     directory=dir_path,\n",
    "#     ensemble_models=ENSEMBLE_MODELS,\n",
    "# )\n",
    "\n",
    "# # Check that expected models exist in \"tide_model\" column\n",
    "# assert set(modelled_tides_df.tide_model) == set([\n",
    "#     \"EOT20\",\n",
    "#     \"HAMTIDE11\",\n",
    "#     \"ensemble-best\",\n",
    "#     \"ensemble-worst\",\n",
    "#     \"ensemble-mean-top2\",\n",
    "#     \"ensemble-mean-weighted\",\n",
    "#     \"ensemble-mean\",\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_MODELS = [\"EOT20\", \"HAMTIDE11\"]\n",
    "ensemble_models = ENSEMBLE_MODELS\n",
    "\n",
    "x = tide_df.index.get_level_values(level=\"x\")\n",
    "y = tide_df.index.get_level_values(level=\"y\")\n",
    "model_ranking_cols = [f\"rank_{m}\" for m in ensemble_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranks_gdf.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "ranking_points=\"https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/derivative/dea_intertidal/supplementary/rankings_ensemble_2017-2019.fgb\"\n",
    "crs = \"EPSG:4326\"\n",
    "ranking_valid_perc=0.02\n",
    "\n",
    "try:\n",
    "    model_ranks_gdf = (\n",
    "        gpd.read_file(ranking_points, engine=\"pyogrio\")\n",
    "        .to_crs(crs)\n",
    "        .query(f\"valid_perc > {ranking_valid_perc}\")\n",
    "        .dropna(how=\"all\")[model_ranking_cols + [\"geometry\"]]\n",
    "    )\n",
    "except KeyError:\n",
    "    error_msg = f\"\"\"\n",
    "    Not all of the expected \"rank_\" columns {model_ranking_cols} were\n",
    "    found in the columns of the ranking points file ({ranking_points}).\n",
    "    Consider passing a custom list of models using `ensemble_models`.\n",
    "    \"\"\"\n",
    "    raise Exception(textwrap.dedent(error_msg).strip()) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import idw\n",
    "\n",
    "idw_kwargs = {}\n",
    "\n",
    "# Use points to interpolate model rankings into requested x and y\n",
    "id_kwargs_str = \"\" if idw_kwargs == {} else idw_kwargs\n",
    "print(f\"Interpolating model rankings using IDW interpolation {id_kwargs_str}\")\n",
    "ensemble_ranks_df = (\n",
    "    # Run IDW interpolation on subset of ranking columns\n",
    "    pd.DataFrame(\n",
    "        idw(\n",
    "            input_z=model_ranks_gdf[model_ranking_cols],\n",
    "            input_x=model_ranks_gdf.geometry.x,\n",
    "            input_y=model_ranks_gdf.geometry.y,\n",
    "            output_x=x,\n",
    "            output_y=y,\n",
    "            **idw_kwargs,\n",
    "        ),\n",
    "        columns=model_ranking_cols,\n",
    "    )\n",
    "    .assign(x=x, y=y)\n",
    "    # Drop any duplicates then melt columns into long format\n",
    "    .drop_duplicates()\n",
    "    .melt(id_vars=[\"x\", \"y\"], var_name=\"tide_model\", value_name=\"rank\")\n",
    "    # Remove \"rank_\" prefix to get plain model names\n",
    "    .replace({\"^rank_\": \"\"}, regex=True)\n",
    "    # Set index columns and rank across groups\n",
    "    .set_index([\"tide_model\", \"x\", \"y\"])\n",
    "    .groupby([\"x\", \"y\"])\n",
    "    .rank()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranks_gdf[model_ranking_cols].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_ranks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "df = model_tides(x= 123.73412090186251, \n",
    "            y=-16.997767837915056, \n",
    "            model=\"ensemble\",\n",
    "            time=pd.date_range(start=\"2000\", end=\"2001\", freq=\"5h\"),\n",
    "            ranking_points=\"/home/jovyan/Robbi/dea-intertidal/data/raw/tide_correlation_points_test.geojson\",\n",
    "            k=5,\n",
    "            output_format=\"wide\",\n",
    "            directory=\"/var/share/tide_models/\")\n",
    "\n",
    "with pd.option_context('display.max_rows', 5, 'display.max_columns', None): \n",
    "    display(df)\n",
    "\n",
    "# u, c = np.unique(a, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.model import model_tides\n",
    "\n",
    "df = model_tides(\n",
    "    x=145.372051,\n",
    "    y=-38.260667,\n",
    "    model=[\n",
    "        \"EOT20\",\n",
    "        \"FES2012\",\n",
    "        \"FES2014_extrapolated\",\n",
    "        \"FES2022_extrapolated\",\n",
    "        \"HAMTIDE11\",\n",
    "        \"GOT4.10\",\n",
    "        \"GOT5.6_extrapolated\",\n",
    "        \"TPXO10-atlas-v2-nc\",\n",
    "        \"TPXO8-atlas-nc\",\n",
    "        \"TPXO9-atlas-v5-nc\",\n",
    "        \"ensemble\",\n",
    "    ],\n",
    "    time=pd.date_range(start=\"2018-01-01\", end=\"2020-12-31\", freq=\"1h\"),\n",
    "    output_format=\"wide\",\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    ensemble_models=[\n",
    "        \"EOT20\",\n",
    "        \"FES2012\",\n",
    "        \"FES2014_extrapolated\",\n",
    "        \"FES2022_extrapolated\",\n",
    "        # \"HAMTIDE11\",\n",
    "        # \"GOT4.10\",\n",
    "        \"GOT5.6_extrapolated\",\n",
    "        \"TPXO10-atlas-v2-nc\",\n",
    "        # \"TPXO8-atlas-nc\",\n",
    "        \"TPXO9-atlas-v5-nc\",\n",
    "    ]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.droplevel([\"x\", \"y\"]).head(50).drop(\"ensemble\", axis=1).plot(linewidth=0.8, figsize=(10, 6))\n",
    "df.droplevel([\"x\", \"y\"]).head(50).ensemble.plot(linewidth=3, c=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.droplevel([\"x\", \"y\"]).head(50).drop(\"ensemble\", axis=1).plot(linewidth=0.8, figsize=(10, 6))\n",
    "df.droplevel([\"x\", \"y\"]).head(50).ensemble.plot(linewidth=3, c=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_standardise_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.utils import _set_directory, list_models\n",
    "\n",
    "directory = \"/home/jovyan/Robbi/eo-tides/tests/data/tide_models/\"\n",
    "directory = _set_directory(directory)\n",
    "\n",
    "\n",
    "# def _standardise_models(model, directory, ensemble_models=None):\n",
    "\n",
    "#     # Turn inputs into arrays for consistent handling\n",
    "#     models_requested = list(np.atleast_1d(model))\n",
    "\n",
    "#     # Get full list of supported models from pyTMD database\n",
    "#     available_models, valid_models = list_models(\n",
    "#         directory, show_available=False, show_supported=False, raise_error=True\n",
    "#     )\n",
    "#     custom_options = [\"ensemble\", \"all\"]\n",
    "\n",
    "#     # Error if any models are not supported\n",
    "#     if not all(m in valid_models + custom_options for m in models_requested):\n",
    "#         error_text = (\n",
    "#             f\"One or more of the requested models are not valid:\\n\"\n",
    "#             f\"{models_requested}\\n\\n\"\n",
    "#             \"The following models are supported:\\n\"\n",
    "#             f\"{valid_models}\"\n",
    "#         )\n",
    "#         raise ValueError(error_text)\n",
    "\n",
    "#     # Error if any models are not available in `directory`\n",
    "#     if not all(m in available_models + custom_options for m in models_requested):\n",
    "#         error_text = (\n",
    "#             f\"One or more of the requested models are valid, but not available in `{directory}`:\\n\"\n",
    "#             f\"{models_requested}\\n\\n\"\n",
    "#             f\"The following models are available in `{directory}`:\\n\"\n",
    "#             f\"{available_models}\"\n",
    "#         )\n",
    "#         raise ValueError(error_text)\n",
    "\n",
    "#     # If \"all\" models are requested, update requested list to include available models\n",
    "#     if \"all\" in models_requested:\n",
    "#         models_requested = available_models + [\n",
    "#             m for m in models_requested if m != \"all\"\n",
    "#         ]\n",
    "\n",
    "#     # If \"ensemble\" modeling is requested, use custom list of ensemble models\n",
    "#     if \"ensemble\" in models_requested:\n",
    "#         print(\"Running ensemble tide modelling\")\n",
    "#         ensemble_models = (\n",
    "#             ensemble_models\n",
    "#             if ensemble_models is not None\n",
    "#             else [\n",
    "#                 \"FES2014\",\n",
    "#                 \"TPXO9-atlas-v5\",\n",
    "#                 \"EOT20\",\n",
    "#                 \"HAMTIDE11\",\n",
    "#                 \"GOT4.10\",\n",
    "#                 \"FES2012\",\n",
    "#                 \"TPXO8-atlas-v1\",\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         # Error if any ensemble models are not available in `directory`\n",
    "#         if not all(m in available_models for m in ensemble_models):\n",
    "#             error_text = (\n",
    "#                 f\"One or more of the requested ensemble models are not available in `{directory}`:\\n\"\n",
    "#                 f\"{ensemble_models}\\n\\n\"\n",
    "#                 f\"The following models are available in `{directory}`:\\n\"\n",
    "#                 f\"{available_models}\"\n",
    "#             )\n",
    "#             raise ValueError(error_text)\n",
    "\n",
    "#         # Return set of all ensemble plus any other requested models\n",
    "#         models_to_process = ensemble_models + [\n",
    "#             m for m in models_requested if m != \"ensemble\"\n",
    "#         ]\n",
    "\n",
    "#     # Otherwise, models to process are the same as those requested\n",
    "#     else:\n",
    "#         models_to_process = models_requested\n",
    "\n",
    "#     # Remove duplicates\n",
    "#     models_to_process = list(set(models_to_process))\n",
    "#     models_requested = list(set(models_requested))\n",
    "\n",
    "#     return models_to_process, models_requested, ensemble_models\n",
    "\n",
    "\n",
    "# model = \"EOT20\"\n",
    "# # model = [\"EOT20\", \"HAMTIDE11\"]  # = [\"EOT20\", \"FES2014\"]\n",
    "# # model = \"all\"  # = [list all available]\n",
    "# # model = \"ensemble\" # = [list all ensemble]\n",
    "# # model = [\"ensemble\", \"GOT5.5\"]  # = [list all ensemble]\n",
    "# # model = [\"all\", \"ensemble\"]\n",
    "\n",
    "\n",
    "from eo_tides.utils import _standardise_models\n",
    "\n",
    "\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    "    [\"EOT20\"],\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"EOT20\",\n",
    "    None,\n",
    "    [\"EOT20\"],\n",
    "    [\"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"all\",\n",
    "    None,\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"all\"],\n",
    "    None,\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"GOT5.5\", \"HAMTIDE11\", \"EOT20\"],\n",
    "    None,\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    \"ensemble\",\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"HAMTIDE11\", \"EOT20\"],\n",
    "    [\"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "    [\"ensemble\", \"GOT5.5\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    "    [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"],\n",
    "    [\"GOT5.5\", \"ensemble\"],\n",
    "    [\"EOT20\", \"HAMTIDE11\"],\n",
    ")\n",
    "# model, ensemble_models, exp_process, exp_request, exp_ensemble = (\n",
    "#     [\"all\", \"ensemble\"],\n",
    "#     [\"EOT20\", \"HAMTIDE11\"],\n",
    "#     [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"],\n",
    "#     [\"GOT5.5\", \"HAMTIDE11\", \"ensemble\", \"EOT20\"],\n",
    "#     [\"EOT20\", \"HAMTIDE11\"],\n",
    "# )\n",
    "\n",
    "\n",
    "models_to_process, models_requested, ensemble_models = _standardise_models(\n",
    "    model=model,\n",
    "    directory=directory,\n",
    "    ensemble_models=ensemble_models,\n",
    ")\n",
    "\n",
    "print(\"Models to process: \", models_to_process)\n",
    "print(\"Models requested: \", models_requested)\n",
    "print(\"Ensemble models: \", ensemble_models)\n",
    "\n",
    "assert models_to_process == exp_process\n",
    "assert models_requested == exp_request\n",
    "assert ensemble_models == exp_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(models_requested + ensemble_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models\n",
    "\n",
    "models_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate interpolation functions\n",
    "\n",
    "crop=True, bounds=None: \n",
    "crop=False, bounds=None:\n",
    "crop=True, bounds="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "x=np.linspace(122.2183, 122.219, 10)\n",
    "y=np.linspace(-18.0008, -18.01, 10)\n",
    "time=pd.date_range(\"2020\", \"2021\", periods=10)\n",
    "crs=\"EPSG:4326\"\n",
    "method=\"spline\"\n",
    "model=\"FES2022\"\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        delta_time=time,\n",
    "        DIRECTORY=\"/gdata1/data/tide_models/\",\n",
    "        MODEL=model,\n",
    "        EPSG=int(crs[-4:]),\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=method,\n",
    "        CROP=True,\n",
    "        # CROP=False,\n",
    "        # BOUNDS=bounds,\n",
    "        )\n",
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"spline\", CROP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"linear\", CROP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from pyTMD.io.model import model\n",
    "from pyTMD.io import FES\n",
    "%lprun -u 1 -f FES.extract_constants tide_elevations(x=np.linspace(122.2183, 122.219, 2), y=np.linspace(-18.0008, -18.01, 2), delta_time=pd.date_range(\"2020\", \"2021\", periods=2), DIRECTORY=\"/gdata1/data/tide_models/\", MODEL=\"FES2022\", EPSG=4326, TIME=\"datetime\", EXTRAPOLATE=True, CUTOFF=np.inf, METHOD=\"spline\", CROP=True, BOUNDS=[121.218, 123.218, -19.000, -17.000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function, annotations\n",
    "\n",
    "import logging\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from io import IOBase\n",
    "import scipy.interpolate\n",
    "import pyTMD.crs\n",
    "import pyTMD.io\n",
    "import pyTMD.io.model\n",
    "import pyTMD.predict\n",
    "import pyTMD.spatial\n",
    "import pyTMD.utilities\n",
    "import timescale.eop\n",
    "import timescale.time\n",
    "# attempt imports\n",
    "pyproj = pyTMD.utilities.import_dependency('pyproj')\n",
    "\n",
    "\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "x=x\n",
    "y=y\n",
    "delta_time=measured_tides_ds.time\n",
    "DIRECTORY=\"/var/share/tide_models/\"\n",
    "MODEL=model\n",
    "EPSG=int(crs[-4:])\n",
    "TIME=\"datetime\"\n",
    "EXTRAPOLATE=True\n",
    "CUTOFF=np.inf\n",
    "CROP=True\n",
    "METHOD=method\n",
    "\n",
    "GZIP=False\n",
    "DEFINITION_FILE=None\n",
    "BOUNDS=None\n",
    "EPOCH=(2000, 1, 1, 0, 0, 0)\n",
    "TYPE='drift'\n",
    "CORRECTIONS = None\n",
    "INFER_MINOR = True\n",
    "MINOR_CONSTITUENTS = None\n",
    "APPEND_NODE = False\n",
    "APPLY_FLEXURE= False\n",
    "FILL_VALUE=np.nan\n",
    "\n",
    "\n",
    "\n",
    "# check that tide directory is accessible\n",
    "if DIRECTORY is not None:\n",
    "    DIRECTORY = pathlib.Path(DIRECTORY).expanduser()\n",
    "    if not DIRECTORY.exists():\n",
    "        raise FileNotFoundError(\"Invalid tide directory\")\n",
    "\n",
    "# validate input arguments\n",
    "assert TIME.lower() in ('gps', 'loran', 'tai', 'utc', 'datetime')\n",
    "assert METHOD.lower() in ('bilinear', 'spline', 'linear', 'nearest')\n",
    "\n",
    "# get parameters for tide model\n",
    "if DEFINITION_FILE is not None:\n",
    "    model = pyTMD.io.model(DIRECTORY).from_file(DEFINITION_FILE)\n",
    "else:\n",
    "    model = pyTMD.io.model(DIRECTORY, compressed=GZIP).elevation(MODEL)\n",
    "\n",
    "# determine input data type based on variable dimensions\n",
    "if not TYPE:\n",
    "    TYPE = pyTMD.spatial.data_type(x, y, delta_time)\n",
    "assert TYPE.lower() in ('grid', 'drift', 'time series')\n",
    "# reform coordinate dimensions for input grids\n",
    "# or verify coordinate dimension shapes\n",
    "if (TYPE.lower() == 'grid') and (np.size(x) != np.size(y)):\n",
    "    x,y = np.meshgrid(np.copy(x),np.copy(y))\n",
    "elif (TYPE.lower() == 'grid'):\n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "elif TYPE.lower() in ('time series', 'drift'):\n",
    "    x = np.atleast_1d(x)\n",
    "    y = np.atleast_1d(y)\n",
    "\n",
    "# converting x,y from EPSG to latitude/longitude\n",
    "crs1 = pyTMD.crs().from_input(EPSG)\n",
    "crs2 = pyproj.CRS.from_epsg(4326)\n",
    "transformer = pyproj.Transformer.from_crs(crs1, crs2, always_xy=True)\n",
    "lon, lat = transformer.transform(x.flatten(), y.flatten())\n",
    "\n",
    "# verify that delta time is an array\n",
    "delta_time = np.atleast_1d(delta_time)\n",
    "# convert delta times or datetimes objects to timescale\n",
    "if (TIME.lower() == 'datetime'):\n",
    "    ts = timescale.time.Timescale().from_datetime(\n",
    "        delta_time.flatten())\n",
    "else:\n",
    "    ts = timescale.time.Timescale().from_deltatime(delta_time,\n",
    "        epoch=EPOCH, standard=TIME)\n",
    "# number of time points\n",
    "nt = len(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tidal constants and interpolate to grid points\n",
    "amp, ph, c = model.extract_constants(lon, lat, type=model.type,\n",
    "    crop=CROP, bounds=BOUNDS, method=METHOD,\n",
    "    extrapolate=EXTRAPOLATE, cutoff=CUTOFF,\n",
    "    append_node=APPEND_NODE, apply_flexure=APPLY_FLEXURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust dimensions of input coordinates to be iterable\n",
    "ilon = np.atleast_1d(np.copy(lon))\n",
    "ilat = np.atleast_1d(np.copy(lat))\n",
    "# set default bounds if cropping\n",
    "xmin, xmax = np.min(ilon), np.max(ilon)\n",
    "ymin, ymax = np.min(ilat), np.max(ilat)\n",
    "bounds=[xmin-1, xmax+1, ymin-1, ymax+1]\n",
    "\n",
    "\n",
    "# read tidal constants and interpolate to grid points\n",
    "c = model.read_constants(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.read_constants(crop=False, bounds=bounds)\n",
    "plt.imshow(c.m2.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.read_constants(crop=True, bounds=bounds)\n",
    "plt.imshow(c.m2.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c.m2.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate complex phase in radians for Euler's\n",
    "cph = -1j*ph*np.pi/180.0\n",
    "# calculate constituent oscillation\n",
    "hc = amp*np.exp(cph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "n = 2000\n",
    "x = np.random.uniform(112.715430, 154.727149, n)\n",
    "y = np.random.uniform(-44.199061, -10.035282, n)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "model = \"FES2014\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models/\"\n",
    "\n",
    "# Time the spline method\n",
    "start_time = time.time()\n",
    "modelled_tides_df_spline = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"spline\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=False, \n",
    ")\n",
    "spline_time = time.time() - start_time\n",
    "\n",
    "# Time the linear method  \n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"linear\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=False,\n",
    ")\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "print(f\"Spline method time: {spline_time:.6f} seconds\")\n",
    "print(f\"Linear method time: {linear_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "n = 2000\n",
    "x = np.random.uniform(112.715430, 154.727149, n)\n",
    "y = np.random.uniform(-44.199061, -10.035282, n)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "model = \"FES2014\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models/\"\n",
    "\n",
    "# # Time the spline method\n",
    "# start_time = time.time()\n",
    "# modelled_tides_df_spline = model_tides(\n",
    "#    x=x,\n",
    "#    y=y,\n",
    "#    time=times,\n",
    "#    model=model,\n",
    "#    method=\"spline\",\n",
    "#    directory=directory,\n",
    "#    parallel=False,\n",
    "#    crop=True, \n",
    "# )\n",
    "# spline_time = time.time() - start_time\n",
    "\n",
    "# Time the linear method  \n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "   x=x,\n",
    "   y=y,\n",
    "   time=times,\n",
    "   model=model,\n",
    "   method=\"linear\",\n",
    "   directory=directory,\n",
    "   parallel=False,\n",
    "   crop=True,\n",
    ")\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "# print(f\"Spline method time: {spline_time:.6f} seconds\")\n",
    "print(f\"Linear method time: {linear_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from eo_tides.model import model_tides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate random data within input bounds\n",
    "x = np.random.uniform(112.715430, 154.727149, 100000)\n",
    "y = np.random.uniform(-44.199061, -10.035282, 100000)\n",
    "times = pd.date_range(\"2020\", \"2021\", periods=100)\n",
    "# model = \"EOT20\"\n",
    "# directory = \"/var/share/tide_models/\"\n",
    "directory = \"/gdata1/data/tide_models_clipped/\"\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for model in [[\"EOT20\", \"GOT5.5\"], \"EOT20\"]:\n",
    "\n",
    "    for n in [100, 1000, 10000, 100000]:\n",
    "    \n",
    "        # Select a subset of x and y\n",
    "        x_sub = x[0:n]\n",
    "        y_sub = y[0:n]\n",
    "    \n",
    "        for parallel_max in [2, 4, 8, 16]:\n",
    "        \n",
    "            for parallel_split in [1, 2, 3, 4, 5, 6, 8, 10, 12, 16, 20]:\n",
    "        \n",
    "                # Time the linear method\n",
    "                start_time = time.time()\n",
    "                modelled_tides_df_linear = model_tides(\n",
    "                    x=x_sub,\n",
    "                    y=y_sub,\n",
    "                    time=times,\n",
    "                    model=model,\n",
    "                    method=\"linear\",\n",
    "                    directory=directory,\n",
    "                    parallel=True,\n",
    "                    parallel_splits=parallel_split,\n",
    "                    parallel_max=parallel_max,\n",
    "                    crop=True,\n",
    "                )\n",
    "                split_time = time.time() - start_time\n",
    "        \n",
    "                output_dict = {\n",
    "                    \"split\": parallel_split,\n",
    "                    \"parallel_max\": parallel_max,\n",
    "                    \"time\": split_time,\n",
    "                    \"points\": n,\n",
    "                    \"points_per_split\": int(n / parallel_split),\n",
    "                    \"split_per_parallel\": parallel_split / parallel_max,\n",
    "                    \"directory\": directory,\n",
    "                    \"model\": model,\n",
    "                }\n",
    "                output_list.append(output_dict)\n",
    "                print(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and export\n",
    "data = pd.DataFrame(output_list)\n",
    "data[\"time_per_point\"] = data[\"time\"] / data[\"points\"]\n",
    "data[\"model_multiple\"] = data[\"model\"].apply(lambda x: x == ['EOT20', 'GOT5.5'])\n",
    "data.to_csv(\"test_timings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"test_timings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='points_per_split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[1], linewidth=3)\n",
    "lineplot.invert_xaxis()\n",
    "axes[1].set_title('Time by Points per split')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model_multiple\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='points_per_split', y='time', hue='parallel_max', data=data.query(\"model_multiple\"), ax=axes[1], linewidth=3)\n",
    "lineplot.invert_xaxis()\n",
    "axes[1].set_title('Time by Points per split')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"split_per_parallel\"] = data[\"split\"] / data[\"parallel_max\"]\n",
    "\n",
    "# Create the faceted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='split', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[0], linewidth=3)\n",
    "axes[0].set_title('Time by Split')\n",
    "\n",
    "lineplot = sns.lineplot(x='split_per_parallel', y='time', hue='parallel_max', data=data.query(\"model == 'EOT20'\"), ax=axes[1], linewidth=3)\n",
    "axes[1].set_title('Time by Splits per parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"model == 'EOT20'\").query(\"parallel_max == 2\").query(\"points == 10000\").set_index(\"points_per_split\").time_per_point.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parallel_max = 16\n",
    "parallel_split=\"auto\"\n",
    "\n",
    "n = 200000\n",
    "models = [\"EOT20\"]  # [\"EOT20\", \"GOT5.5\"]\n",
    "# models = [\"EOT20\", \"GOT5.5\"]\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.process_cpu_count()\n",
    "\n",
    "parallel_split = int(max(1, min(n / 1000, parallel_max) / len(models)))\n",
    "print(parallel_split, n/parallel_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parallel_splits(\n",
    "    total_points,\n",
    "    model_count,\n",
    "    parallel_max=None,\n",
    "    min_points_per_split=1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the optimal number of parallel splits for data\n",
    "    processing based on system resources and processing constraints.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    total_points : int\n",
    "        Total number of data points to process\n",
    "    model_count : int\n",
    "        Number of models that will be run in parallel\n",
    "    parallel_max : int, optional\n",
    "        Maximum number of parallel processes to use. If None, uses CPU core count\n",
    "    min_points_per_split : int, default=1000\n",
    "        Minimum number of points that should be processed in each split\n",
    "    \"\"\"\n",
    "    # Available CPUs\n",
    "    if parallel_max is None:\n",
    "        try:\n",
    "            import psutil\n",
    "\n",
    "            parallel_max = psutil.cpu_count(logical=False)\n",
    "        except ImportError:\n",
    "            parallel_max = os.cpu_count()\n",
    "\n",
    "    # Calculate optimal number of splits based on constraints\n",
    "    splits_by_size = total_points / min_points_per_split\n",
    "    splits_by_cpu = parallel_max / model_count\n",
    "    optimal_splits = min(splits_by_size, splits_by_cpu)\n",
    "\n",
    "    # Convert to integer and ensure at least 1 split\n",
    "    final_split_count = int(max(1, optimal_splits))\n",
    "    return final_split_count\n",
    "\n",
    "\n",
    "_parallel_splits(total_points=1, model_count=1, parallel_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(10.6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count(affinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.cpu_count()\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=None) as executor:\n",
    "    executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from eo_tides.model import model_tides\n",
    "\n",
    "n = 10000\n",
    "directory = \"/gdata1/data/tide_models_clipped/\"\n",
    "directory = \"./tests/data/tide_models/\"\n",
    "# models = [\"EOT20\", \"GOT5.5\", \"HAMTIDE11\"]\n",
    "models = [\"EOT20\"]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "modelled_tides_df_linear = model_tides(\n",
    "    x = np.random.uniform(112.715430, 154.727149, n),\n",
    "    y = np.random.uniform(-44.199061, -10.035282, n),\n",
    "    time = pd.date_range(\"2020\", \"2021\", periods=100),\n",
    "    model=models,\n",
    "    method=\"linear\",\n",
    "    directory=directory,\n",
    "    parallel=True,\n",
    "    parallel_splits=\"auto\",\n",
    "    parallel_max=16,\n",
    "    crop=False,\n",
    ")\n",
    "split_time = time.time() - start_time\n",
    "print(split_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 10000\n",
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (~model_multiple)\").style.background_gradient(cmap=\"YlOrRd\", subset=\"time_per_point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pivot(columns=\"model_multiple\", values=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (model_multiple)\").time.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"(points == @n) & (parallel_max == @parallel_max) & (~model_multiple)\").time.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(modelled_tides_df_spline.droplevel([\"x\", \"y\"]).tide_height, modelled_tides_df_linear.droplevel([\"x\", \"y\"]).tide_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run equivalent pyTMD code to verify same results\n",
    "# pytmd_tides_spline = tide_elevations(\n",
    "#         x=np.repeat(149.722622, len(measured_tides_ds.time)), \n",
    "#         y=np.repeat(-22.132984, len(measured_tides_ds.time)), \n",
    "#         delta_time=measured_tides_ds.time,\n",
    "#         DIRECTORY=\"/var/share/tide_models/\",\n",
    "#         MODEL=\"FES2012\",\n",
    "#         EPSG=4326,\n",
    "#         TIME=\"datetime\",\n",
    "#         EXTRAPOLATE=True,\n",
    "#         CUTOFF=np.inf,\n",
    "#         METHOD=\"spline\",\n",
    "#         CROP=True,\n",
    "#         # BOUNDS=[148.722622, 149.722622, -22.132984, -23.132984],\n",
    "#         )\n",
    "\n",
    "pytmd_tides_linear = tide_elevations(\n",
    "        x=np.repeat(149.722622, len(measured_tides_ds.time)), \n",
    "        y=np.repeat(-22.132984, len(measured_tides_ds.time)), \n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"/var/share/tide_models/\",\n",
    "        MODEL=\"TPXO9-atlas-v5-nc\",\n",
    "        EPSG=4326,\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=\"linear\",\n",
    "        CROP=True,\n",
    "        # BOUNDS=[140.002622, 149.722622, -23.132984, -22.132984],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(pytmd_tides_spline.data, pytmd_tides_linear.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_df = phase_tides(\n",
    "    x=[122.14],\n",
    "    y=[-17.91],\n",
    "    time=pd.date_range(\"2020-01-01\", \"2020-01-02\", freq=\"h\"),\n",
    "    directory=\"/var/share/tide_models/\",\n",
    "    model=[\"EOT20\"],\n",
    "    delta = \"15 min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.date_range(start=\"2000-01-01\", end=\"2000-01-02\", periods=3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pyTMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"spline\", \"EOT20\"\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\"\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "\n",
    "# # Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    time=measured_tides_ds.time,\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"./tests/data/tide_models\",\n",
    "    # crop=False,\n",
    ")\n",
    "\n",
    "# Run equivalent pyTMD code to verify same results\n",
    "pytmd_tides = tide_elevations(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        delta_time=measured_tides_ds.time,\n",
    "        DIRECTORY=\"./tests/data/tide_models\",\n",
    "        MODEL=model,\n",
    "        EPSG=int(crs[-4:]),\n",
    "        TIME=\"datetime\",\n",
    "        EXTRAPOLATE=True,\n",
    "        CUTOFF=np.inf,\n",
    "        METHOD=method,\n",
    "        # CORRECTIONS: str | None = None,\n",
    "        # INFER_MINOR: bool = True,\n",
    "        # MINOR_CONSTITUENTS: list | None = None,\n",
    "        # APPLY_FLEXURE: bool = False,\n",
    "        # FILL_VALUE: float = np.nan\n",
    "        # APPEND_NODE=True,\n",
    "        )\n",
    "\n",
    "np.allclose(modelled_tides_df.tide_height.values, pytmd_tides.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytmd_tides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"spline\", \"EOT20\"\n",
    "x, y, crs, method, model = GAUGE_X, GAUGE_Y, \"EPSG:4326\", \"bilinear\", \"EOT20\"\n",
    "x, y, crs, method, model = -1034913, -1961916, \"EPSG:3577\", \"bilinear\", \"EOT20\"\n",
    "\n",
    "\n",
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=\"FES2014\",\n",
    "    time=pd.date_range(\"1980\", \"2020\", freq=\"9h\"),\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"/var/share/tide_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df2 = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=\"FES2014\",\n",
    "    time=pd.date_range(\"1980\", \"2020\", freq=\"9h\"),\n",
    "    crs=crs,\n",
    "    method=method,\n",
    "    directory=\"/var/share/tide_models/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df.tide_height.plot(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_tides_df2.tide_height - modelled_tides_df.tide_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error for out of bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import model_tides\n",
    "\n",
    "x, y = 180, -50\n",
    "\n",
    "\n",
    "# Run EOT20 tidal model for locations and timesteps in tide gauge data\n",
    "modelled_tides_df = model_tides(\n",
    "    x=[x],\n",
    "    y=[y],\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    time=measured_tides_ds.time,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import list_models\n",
    "list_models(directory=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stats import pixel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EOT20\"]\n",
    "resample = False\n",
    "\n",
    "stats_ds = pixel_stats(\n",
    "    ds=satellite_ds,\n",
    "    model=models,\n",
    "    resample=resample,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling ebb and flow tidal phases\n",
    "The `tag_tides` function also allows us to determine whether each satellite observation was taken while the tide was rising/incoming (flow tide) or falling/outgoing (ebb tide) by setting `ebb_flow=True`. This is achieved by comparing tide heights 15 minutes before and after the observed satellite observation.\n",
    "\n",
    "Ebb and flow data can provide valuable contextual information for interpreting satellite imagery, particularly in tidal flat or mangrove forest environments where water may remain in the landscape for considerable time after the tidal peak.\n",
    "\n",
    "Once you run the cell below, our data will now also contain a new `ebb_flow` variable under **Data variables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "ds = dc.load(product=\"ga_s2ls_intertidal_cyear_3\", limit=1, measurements=\"elevation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.geo.geobox import GeoBox\n",
    "import xarray as xr\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def _standardise_time(\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Accept a datetime64 ndarray, pandas.DatetimeIndex\n",
    "    or pandas.Timestamp, and return a datetime64 ndarray.\n",
    "    \"\"\"\n",
    "    # Return time as-is if none\n",
    "    if time is None:\n",
    "        return time\n",
    "\n",
    "    # Convert to a 1D datetime64 array\n",
    "    time = np.atleast_1d(time).astype(\"datetime64[ns]\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "def _standardise_inputs(\n",
    "    ds: xr.DataArray | xr.Dataset | GeoBox,\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> (GeoBox, np.ndarray):\n",
    "    \"\"\"\n",
    "    Takes an xarray or GeoBox input and an optional custom times,\n",
    "    and returns a standardised GeoBox and  \n",
    "    \"\"\"\n",
    "\n",
    "    # If `ds` is an xarray object, extract its GeoBox and time\n",
    "    if isinstance(ds, (xr.DataArray, xr.Dataset)):\n",
    "\n",
    "        # Try to extract GeoBox\n",
    "        try:\n",
    "            gbox = ds.odc.geobox\n",
    "        except AttributeError:\n",
    "            error_msg = \"\"\"\n",
    "            Cannot extract a valid GeoBox for `ds`. This is required for\n",
    "            extracting details about `ds`'s CRS and spatial location.\n",
    "            \n",
    "            Import `odc.geo.xr` then run `ds = ds.odc.assign_crs(crs=...)`\n",
    "            to prepare your data before passing it to this function.\n",
    "            \"\"\"\n",
    "            raise Exception(textwrap.dedent(error_msg).strip())\n",
    "\n",
    "        # Use custom time by default if provided; otherwise try and extract from `ds`\n",
    "        if time is not None:\n",
    "            time = _standardise_time(time)\n",
    "        elif \"time\" in ds.coords:\n",
    "            time = ds.coords[\"time\"].values\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`ds` does not have a time dimension, and no custom times were provided via `time`.\"\n",
    "            )\n",
    "\n",
    "    # If `ds` is a GeoBox, use it directly; raise an error if no time was provided\n",
    "    elif isinstance(ds, GeoBox):\n",
    "        gbox = ds\n",
    "        if time is not None:\n",
    "            time = _standardise_time(time)\n",
    "        else:\n",
    "            raise ValueError(\"If `ds` is a GeoBox, `time` must be provided.\")\n",
    "\n",
    "    # Raise error if no valid inputs were provided\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"`ds` must be an xarray.DataArray, xarray.Dataset, or odc.geo.geobox.GeoBox.\"\n",
    "        )\n",
    "\n",
    "    return gbox, time\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "time = pd.date_range(\"2021\", \"2022\")\n",
    "time = pd.Timestamp(\"2022-02-01\")\n",
    "# time = satellite_ds.time\n",
    "# time = [\"a\", \"b\"]\n",
    "\n",
    "\n",
    "gbox, time = _standardise_inputs(ds=ds.drop_dims(\"time\").odc.geobox, time=time)\n",
    "gbox, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds.chunks[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "# time = pd.date_range(\"2021\", \"2022\")\n",
    "# time = pd.Timestamp(\"2022-02-01\")\n",
    "time = satellite_ds.time\n",
    "\n",
    "\n",
    "def _standardise_time(\n",
    "    time: np.ndarray | pd.DatetimeIndex | pd.Timestamp | None,\n",
    ") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Accept a datetime64 ndarray, pandas.DatetimeIndex\n",
    "    or pandas.Timestamp, and return a datetime64 ndarray.\n",
    "    \"\"\"\n",
    "    # Return time as-is if none\n",
    "    if time is None:\n",
    "        return time\n",
    "\n",
    "    # Convert to a 1D datetime64 array\n",
    "    time = np.atleast_1d(time).astype(\"datetime64[ns]\")\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2021\", \"2022\").values\n",
    "# time = pd.date_range(\"2021\", \"2022\")\n",
    "# time = pd.Timestamp(\"2022-02-01\")\n",
    "# time = satellite_ds.time\n",
    "# time = [pd.Timestamp(\"2022-02-01\"), pd.Timestamp(\"2022-02-01\")]\n",
    "# time = None\n",
    "_standardise_time(time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.atleast_1d(time).astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.odc.assign_crs(\"EPSG:3577\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = satellite_ds.nbart_red.drop_attrs(deep=True).drop_vars(\"spatial_ref\").odc.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  #odc.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tide heights\n",
    "ds = tag_tides(\n",
    "    ds, \n",
    "    ebb_flow=True,     \n",
    "    directory=\"../../tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Print output data\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have data giving us the both the tide height and tidal phase (\"ebb\" or \"flow\") for every satellite image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[[\"time\", \"tide_height\", \"ebb_flow\"]].drop_vars(\"spatial_ref\").to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could for example use this data to filter our observations to keep ebbing phase observations only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ebb = ds.where(ds.ebb_flow == \"Ebb\", drop=True)\n",
    "print(ds_ebb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odc.stac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "# Connect to STAC catalog\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "# Set cloud access defaults\n",
    "odc.stac.configure_rio(\n",
    "    cloud_defaults=True,\n",
    "    aws={\"aws_unsigned\": True},\n",
    ")\n",
    "\n",
    "# Build a query and search the STAC catalog for all matching items\n",
    "bbox = [122.160, -18.05, 122.260, -17.95]\n",
    "query = catalog.search(\n",
    "    bbox=bbox,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    datetime=\"2021/2023\",\n",
    ")\n",
    "\n",
    "# Load data into xarray format\n",
    "ds_s2 = odc.stac.load(\n",
    "    items=list(query.items()),\n",
    "    bands=[\"red\"],\n",
    "    crs=\"utm\",\n",
    "    resolution=30,\n",
    "    groupby=\"solar_day\",\n",
    "    bbox=bbox,\n",
    "    fail_on_error=False,\n",
    "    chunks={},\n",
    ")\n",
    "\n",
    "print(ds_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stats_ds.data_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides.stats import pixel_stats\n",
    "\n",
    "models = [\"EOT20\"]\n",
    "resample = True\n",
    "\n",
    "stats_ds = pixel_stats(\n",
    "    ds=satellite_ds,\n",
    "    model=models,\n",
    "    resample=resample,\n",
    "    directory=\"../tests/data/tide_models\",\n",
    ")\n",
    "\n",
    "# Verify dims are correct\n",
    "assert stats_ds.odc.spatial_dims == satellite_ds.odc.spatial_dims\n",
    "\n",
    "# Verify vars are as expected\n",
    "expected_vars = ['hat',  'hot',  'lat',  'lot',  'otr',  'tr',  'spread',  'offset_low',  'offset_high']\n",
    "assert set(expected_vars) == set(stats_ds.data_vars)\n",
    "\n",
    "# Verify tide models are correct\n",
    "assert all(stats_ds[\"tide_model\"].values == models)\n",
    "if len(models) > 1:\n",
    "    assert \"tide_model\" in stats_ds.dims\n",
    "\n",
    "# If resample, assert that statistics have the same shape and dims\n",
    "# as `satellite_ds`\n",
    "if resample:\n",
    "    assert satellite_ds.odc.geobox.shape == stats_ds.odc.geobox.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify values are roughly expected\n",
    "assert np.allclose(stats_ds.offset_high.mean().item, 0.30, atol=0.02)\n",
    "assert np.allclose(stats_ds.offset_low.mean().item, 0.27, atol=0.02)\n",
    "assert np.allclose(stats_ds.spread.mean().item, 0.43, atol=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.offset_high.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.spread.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds[\"tide_model\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds[\"tide_model\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(['hat',  'hot',  'lat',  'lot',  'otr',  'tr',  'spread',  'offset_low',  'offset_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stats_ds.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_tides import pixel_tides\n",
    "\n",
    "pixel_tides(\n",
    "    ds=satellite_ds,\n",
    "    model=[\"EOT20\", \"GOT5.5\"],\n",
    "    directory=\"../tests/data/tide_models\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_ds.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
